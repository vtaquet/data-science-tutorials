{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2091ce86-79cf-45e5-bea2-89fd8cb405d7",
   "metadata": {},
   "source": [
    "# 4. Application de régression sur le Boston dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-stevens",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous cherchons à déterminer les incertitudes sur un jeu de données multi-varié simple: le Boston dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-projector",
   "metadata": {
    "incorrectly_encoded_metadata": "heading_collapsed=\"true\" toc-hr-collapsed=true toc-nb-collapsed=true"
   },
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entitled-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-pitch",
   "metadata": {},
   "source": [
    "# Boston dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-married",
   "metadata": {},
   "source": [
    "### Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protective-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frozen-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dict_boston['data'], columns=dict_boston['feature_names'])\n",
    "y = pd.DataFrame(dict_boston['target'], columns=['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grateful-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recognized-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_ids, cat_col_ids = [], []\n",
    "for icol, col in enumerate(X.columns):\n",
    "    if len(X[col].unique()) < 10:\n",
    "        cat_col_ids.append(icol)\n",
    "    else:\n",
    "        num_col_ids.append(icol)\n",
    "num_cols = X.columns[num_col_ids]\n",
    "cat_cols = X.columns[cat_col_ids]\n",
    "target_col = 'MEDV'\n",
    "X_cat = X.loc[:, cat_cols]\n",
    "unique_cat = [np.unique(X_cat.iloc[:, i]) for i in range(X_cat.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-diploma",
   "metadata": {},
   "source": [
    "Les données contiennent 13 variables indépendantes de type `float`, 11 d'entre elles sont numériques, et 2 sont catégorielles:\n",
    "- CRIM per capita crime rate by town\n",
    "- ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS proportion of non-retail business acres per town\n",
    "- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) categorical\n",
    "- NOX nitric oxides concentration (parts per 10 million)\n",
    "- RM average number of rooms per dwelling\n",
    "- AGE proportion of owner-occupied units built prior to 1940\n",
    "- DIS weighted distances to five Boston employment centres\n",
    "- RAD index of accessibility to radial highways categorical\n",
    "- TAX full-value property-tax rate per \\$10,000\n",
    "- PTRATIO pupil-teacher ratio by town\n",
    "- B $1000(Bk - 0.63)^2$ where Bk is the proportion of blacks by town\n",
    "- LSTAT \\% lower status of the population\n",
    "\n",
    "Target variable:\n",
    "- MEDV Median value of owner-occupied homes in \\$1000’s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ethical-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-ireland",
   "metadata": {},
   "source": [
    "### Pré-traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970bdb19-606d-468f-a8ae-ac0a1dea5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "        (\"encoder\", OneHotEncoder(\n",
    "            categories=unique_cat,\n",
    "            drop=None,\n",
    "            sparse=False,\n",
    "            handle_unknown=\"ignore\"\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical\", numerical_transformer, num_cols),\n",
    "        (\"categorical\", categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "functional-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73099796-0717-4fd1-a2b2-954d136c66cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 22), (102, 22))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep.shape, X_test_prep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-nirvana",
   "metadata": {},
   "source": [
    "### Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44868de5-2859-4c26-86f3-b97bffad1be3",
   "metadata": {},
   "source": [
    "#### Première approche par un MLP déterministe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05de3d29-bc1d-49ee-991f-77025a825b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilistic_mlp(\n",
    "    shape,\n",
    "    hidden_type= \"dense\",\n",
    "    output_type = \"deterministic\",\n",
    "    hidden_units = [1],\n",
    "    activations = [\"relu\"],\n",
    "    mcdropout = 0.,\n",
    "    prior = None,\n",
    "    posterior = None,\n",
    "    loss = \"mean_squared_error\",\n",
    "    optimizer = \"adam\",\n",
    "    verbose = 1\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Define a probabilistic MultiLayer Perceptron architecture from specified hidden\n",
    "    units and activation functions, type of hidden and output layers, and functions\n",
    "    for prior and posterior distributions, and compile the network.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(shape[1],))\n",
    "    x = inputs\n",
    "    for i, units in enumerate(hidden_units):\n",
    "        if hidden_type == \"variationaldense\":\n",
    "            x = tfpl.DenseVariational(\n",
    "                units=units,\n",
    "                make_prior_fn=prior,\n",
    "                make_posterior_fn=posterior,\n",
    "                kl_weight=1/shape[0],\n",
    "                activation=activations[i]\n",
    "            )(x)\n",
    "        else:\n",
    "            x = Dense(units, activation=activations[i])(x)\n",
    "            if mcdropout > 0:\n",
    "                x = Dropout(mcdropout)(x, training=True)\n",
    "    if output_type == \"probabilistic\":\n",
    "        x = Dense(tfpl.IndependentNormal.params_size(event_shape=1))(x)\n",
    "        outputs = tfpl.IndependentNormal(event_shape=1)(x)\n",
    "    else:\n",
    "        outputs = Dense(units=1)(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    if output_type == 'probabilistic':\n",
    "        loss = negative_log_likelihood\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43c093-1ce9-4ddd-a43c-fc860b327b72",
   "metadata": {},
   "source": [
    "#### Estimation de l'incertitude résiduelle par un MLP probabiliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5b4717-2cb2-461d-a834-9cad7b2538ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(y_true, y_pred):\n",
    "    \"\"\"Negative log likelihood.\"\"\"\n",
    "    return -y_pred.log_prob(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af306063-1d32-49ca-8797-2f2384a49c22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "12/12 [==============================] - 1s 35ms/step - loss: 464.4050 - val_loss: 346.8454\n",
      "Epoch 2/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 327.2701 - val_loss: 243.5020\n",
      "Epoch 3/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 231.7307 - val_loss: 176.3623\n",
      "Epoch 4/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 170.2636 - val_loss: 130.3848\n",
      "Epoch 5/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 131.1795 - val_loss: 101.6012\n",
      "Epoch 6/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 103.5085 - val_loss: 82.2103\n",
      "Epoch 7/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 93.9056 - val_loss: 71.5942\n",
      "Epoch 8/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 73.4254 - val_loss: 64.9859\n",
      "Epoch 9/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 61.6057 - val_loss: 61.4223\n",
      "Epoch 10/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 58.5709 - val_loss: 58.9917\n",
      "Epoch 11/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 55.9254 - val_loss: 56.2035\n",
      "Epoch 12/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 57.0407 - val_loss: 53.3196\n",
      "Epoch 13/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 64.5686 - val_loss: 51.9317\n",
      "Epoch 14/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 50.6934 - val_loss: 49.4661\n",
      "Epoch 15/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 52.8374 - val_loss: 47.7745\n",
      "Epoch 16/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 41.9193 - val_loss: 46.2579\n",
      "Epoch 17/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 51.9079 - val_loss: 44.0700\n",
      "Epoch 18/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 42.2683 - val_loss: 42.0343\n",
      "Epoch 19/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 43.4112 - val_loss: 39.2495\n",
      "Epoch 20/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 46.6742 - val_loss: 36.8077\n",
      "Epoch 21/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8750 - val_loss: 34.6097\n",
      "Epoch 22/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9750 - val_loss: 33.3721\n",
      "Epoch 23/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 25.4068 - val_loss: 32.8300\n",
      "Epoch 24/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.0817 - val_loss: 31.3975\n",
      "Epoch 25/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9632 - val_loss: 29.9400\n",
      "Epoch 26/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.4015 - val_loss: 29.0511\n",
      "Epoch 27/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1921 - val_loss: 28.0302\n",
      "Epoch 28/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9821 - val_loss: 26.9346\n",
      "Epoch 29/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 21.0806 - val_loss: 25.6061\n",
      "Epoch 30/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 16.5870 - val_loss: 25.4473\n",
      "Epoch 31/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.1864 - val_loss: 23.9484\n",
      "Epoch 32/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.0342 - val_loss: 23.3742\n",
      "Epoch 33/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 16.1603 - val_loss: 22.1251\n",
      "Epoch 34/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.2624 - val_loss: 22.4414\n",
      "Epoch 35/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.7446 - val_loss: 21.1261\n",
      "Epoch 36/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.8461 - val_loss: 20.5740\n",
      "Epoch 37/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 13.2234 - val_loss: 19.8404\n",
      "Epoch 38/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.0703 - val_loss: 19.6454\n",
      "Epoch 39/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.9933 - val_loss: 18.6914\n",
      "Epoch 40/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.7207 - val_loss: 18.0921\n",
      "Epoch 41/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.2010 - val_loss: 18.5103\n",
      "Epoch 42/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.2004 - val_loss: 17.7416\n",
      "Epoch 43/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.3582 - val_loss: 17.8009\n",
      "Epoch 44/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.4848 - val_loss: 18.2572\n",
      "Epoch 45/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.8044 - val_loss: 16.5420\n",
      "Epoch 46/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.0448 - val_loss: 17.9107\n",
      "Epoch 47/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.7704 - val_loss: 17.0053\n",
      "Epoch 48/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.0767 - val_loss: 16.5850\n",
      "Epoch 49/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.4916 - val_loss: 17.1023\n",
      "Epoch 50/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.4464 - val_loss: 16.4250\n",
      "Epoch 51/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.4122 - val_loss: 16.0323\n",
      "Epoch 52/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.5719 - val_loss: 14.9579\n",
      "Epoch 53/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.2698 - val_loss: 16.4313\n",
      "Epoch 54/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.4047 - val_loss: 16.0592\n",
      "Epoch 55/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.2682 - val_loss: 14.7528\n",
      "Epoch 56/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.9495 - val_loss: 15.5753\n",
      "Epoch 57/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.1808 - val_loss: 14.9186\n",
      "Epoch 58/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.3745 - val_loss: 14.7042\n",
      "Epoch 59/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3276 - val_loss: 15.3078\n",
      "Epoch 60/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.1708 - val_loss: 14.4967\n",
      "Epoch 61/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.4558 - val_loss: 14.4761\n",
      "Epoch 62/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.4196 - val_loss: 14.1643\n",
      "Epoch 63/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5845 - val_loss: 14.9631\n",
      "Epoch 64/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.3707 - val_loss: 13.7237\n",
      "Epoch 65/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.2412 - val_loss: 14.0809\n",
      "Epoch 66/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.2745 - val_loss: 14.3115\n",
      "Epoch 67/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.6135 - val_loss: 13.4207\n",
      "Epoch 68/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.2773 - val_loss: 14.3453\n",
      "Epoch 69/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3187 - val_loss: 13.5779\n",
      "Epoch 70/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5092 - val_loss: 13.5373\n",
      "Epoch 71/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.2394 - val_loss: 13.1919\n",
      "Epoch 72/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.9617 - val_loss: 13.1600\n",
      "Epoch 73/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.6316 - val_loss: 13.6853\n",
      "Epoch 74/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.1607 - val_loss: 13.1704\n",
      "Epoch 75/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.9220 - val_loss: 13.7337\n",
      "Epoch 76/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5799 - val_loss: 14.8837\n",
      "Epoch 77/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7207 - val_loss: 14.0270\n",
      "Epoch 78/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.4484 - val_loss: 15.0298\n",
      "Epoch 79/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2217 - val_loss: 13.1940\n",
      "Epoch 80/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.3840 - val_loss: 13.6840\n",
      "Epoch 81/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.2842 - val_loss: 14.0056\n",
      "Epoch 82/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.5580 - val_loss: 14.4295\n",
      "Epoch 83/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.9046 - val_loss: 14.2956\n",
      "Epoch 84/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.4586 - val_loss: 13.3411\n",
      "Epoch 85/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.4918 - val_loss: 14.5187\n",
      "Epoch 86/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.4549 - val_loss: 13.4850\n",
      "Epoch 87/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.0812 - val_loss: 13.0639\n",
      "Epoch 88/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2026 - val_loss: 13.8467\n",
      "Epoch 89/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8398 - val_loss: 13.1902\n",
      "Epoch 90/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.6885 - val_loss: 12.9343\n",
      "Epoch 91/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9088 - val_loss: 13.7065\n",
      "Epoch 92/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2333 - val_loss: 13.5995\n",
      "Epoch 93/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0709 - val_loss: 12.7678\n",
      "Epoch 94/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4520 - val_loss: 13.6151\n",
      "Epoch 95/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6848 - val_loss: 12.3303\n",
      "Epoch 96/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5446 - val_loss: 13.0560\n",
      "Epoch 97/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2825 - val_loss: 13.3525\n",
      "Epoch 98/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.2890 - val_loss: 12.7797\n",
      "Epoch 99/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.9755 - val_loss: 13.1741\n",
      "Epoch 100/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.9718 - val_loss: 13.0194\n",
      "Epoch 101/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8967 - val_loss: 13.0416\n",
      "Epoch 102/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4917 - val_loss: 12.4963\n",
      "Epoch 103/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2991 - val_loss: 12.8804\n",
      "Epoch 104/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6950 - val_loss: 12.4891\n",
      "Epoch 105/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9974 - val_loss: 13.3546\n",
      "Epoch 106/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6631 - val_loss: 13.3186\n",
      "Epoch 107/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5344 - val_loss: 12.5500\n",
      "Epoch 108/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9079 - val_loss: 13.1917\n",
      "Epoch 109/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2482 - val_loss: 12.4661\n",
      "Epoch 110/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4437 - val_loss: 13.8420\n",
      "Epoch 111/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9171 - val_loss: 13.3528\n",
      "Epoch 112/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9447 - val_loss: 12.9840\n",
      "Epoch 113/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9687 - val_loss: 12.5271\n",
      "Epoch 114/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2086 - val_loss: 13.0822\n",
      "Epoch 115/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5676 - val_loss: 12.6967\n",
      "Epoch 116/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0142 - val_loss: 12.6881\n",
      "Epoch 117/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2966 - val_loss: 13.0990\n",
      "Epoch 118/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0566 - val_loss: 12.9899\n",
      "Epoch 119/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8082 - val_loss: 12.9313\n",
      "Epoch 120/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8418 - val_loss: 13.3688\n",
      "Epoch 121/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6028 - val_loss: 13.6061\n",
      "Epoch 122/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3152 - val_loss: 12.8021\n",
      "Epoch 123/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5426 - val_loss: 12.7457\n",
      "Epoch 124/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4175 - val_loss: 13.0420\n",
      "Epoch 125/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3668 - val_loss: 13.4737\n",
      "Epoch 126/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5332 - val_loss: 12.6786\n",
      "Epoch 127/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3541 - val_loss: 13.1526\n",
      "Epoch 128/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.7227 - val_loss: 12.8976\n",
      "Epoch 129/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6783 - val_loss: 13.1969\n",
      "Epoch 130/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4547 - val_loss: 13.5331\n",
      "Epoch 131/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7781 - val_loss: 13.1019\n",
      "Epoch 132/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0644 - val_loss: 13.2669\n",
      "Epoch 133/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4437 - val_loss: 13.1858\n",
      "Epoch 134/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3331 - val_loss: 13.6718\n",
      "Epoch 135/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5942 - val_loss: 13.2646\n",
      "Epoch 136/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5671 - val_loss: 13.2901\n",
      "Epoch 137/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9237 - val_loss: 13.0005\n",
      "Epoch 138/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9604 - val_loss: 13.4489\n",
      "Epoch 139/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9481 - val_loss: 13.3757\n",
      "Epoch 140/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6029 - val_loss: 13.6341\n",
      "Epoch 141/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3934 - val_loss: 13.1025\n",
      "Epoch 142/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6234 - val_loss: 13.8923\n",
      "Epoch 143/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4453 - val_loss: 13.6818\n",
      "Epoch 144/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6529 - val_loss: 13.0741\n",
      "Epoch 145/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5550 - val_loss: 13.3302\n",
      "CPU times: user 13.9 s, sys: 1.32 s, total: 15.2 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_determ = get_probabilistic_mlp(\n",
    "    shape=X_train_prep.shape, \n",
    "    hidden_type=\"dense\", \n",
    "    output_type=\"deterministic\", \n",
    "    hidden_units=[32, 32], \n",
    "    activations=[\"sigmoid\", \"sigmoid\"],\n",
    "    optimizer=Adam(learning_rate=0.01)\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=50)\n",
    "hist_determ = mlp_determ.fit(\n",
    "    X_train_prep,\n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "y_determ_train = mlp_determ.predict(X_train_prep)\n",
    "y_determ_pred = mlp_determ.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "weekly-revision",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "12/12 [==============================] - 1s 16ms/step - loss: 197.6041 - val_loss: 127.7007\n",
      "Epoch 2/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 112.9749 - val_loss: 85.9750\n",
      "Epoch 3/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 86.1005 - val_loss: 64.2010\n",
      "Epoch 4/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 59.0308 - val_loss: 52.1470\n",
      "Epoch 5/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 50.3061 - val_loss: 44.2061\n",
      "Epoch 6/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 41.2825 - val_loss: 38.6652\n",
      "Epoch 7/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.8196 - val_loss: 34.5182\n",
      "Epoch 8/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.0686 - val_loss: 31.2825\n",
      "Epoch 9/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 28.7248 - val_loss: 28.6748\n",
      "Epoch 10/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.1063 - val_loss: 26.4380\n",
      "Epoch 11/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 26.2673 - val_loss: 24.6129\n",
      "Epoch 12/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9756 - val_loss: 23.0723\n",
      "Epoch 13/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3392 - val_loss: 21.7395\n",
      "Epoch 14/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.0886 - val_loss: 20.6009\n",
      "Epoch 15/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2226 - val_loss: 19.5912\n",
      "Epoch 16/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.2336 - val_loss: 18.6819\n",
      "Epoch 17/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0301 - val_loss: 17.8517\n",
      "Epoch 18/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.4553 - val_loss: 17.1285\n",
      "Epoch 19/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8100 - val_loss: 16.4713\n",
      "Epoch 20/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.5089 - val_loss: 15.8846\n",
      "Epoch 21/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.1454 - val_loss: 15.3165\n",
      "Epoch 22/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.8602 - val_loss: 14.8197\n",
      "Epoch 23/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.0595 - val_loss: 14.3543\n",
      "Epoch 24/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.4085 - val_loss: 13.9243\n",
      "Epoch 25/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.9022 - val_loss: 13.5347\n",
      "Epoch 26/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.6410 - val_loss: 13.1648\n",
      "Epoch 27/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.4878 - val_loss: 12.8260\n",
      "Epoch 28/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.3943 - val_loss: 12.4985\n",
      "Epoch 29/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.1125 - val_loss: 12.1968\n",
      "Epoch 30/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.5916 - val_loss: 11.9039\n",
      "Epoch 31/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.8549 - val_loss: 11.6299\n",
      "Epoch 32/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.2662 - val_loss: 11.3716\n",
      "Epoch 33/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.2061 - val_loss: 11.1224\n",
      "Epoch 34/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.8021 - val_loss: 10.8933\n",
      "Epoch 35/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.5605 - val_loss: 10.6733\n",
      "Epoch 36/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.3603 - val_loss: 10.4684\n",
      "Epoch 37/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.0375 - val_loss: 10.2680\n",
      "Epoch 38/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.1256 - val_loss: 10.0827\n",
      "Epoch 39/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.1357 - val_loss: 9.9018\n",
      "Epoch 40/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.7234 - val_loss: 9.7274\n",
      "Epoch 41/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.4526 - val_loss: 9.5654\n",
      "Epoch 42/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6488 - val_loss: 9.4051\n",
      "Epoch 43/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.9166 - val_loss: 9.2569\n",
      "Epoch 44/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.7787 - val_loss: 9.1101\n",
      "Epoch 45/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6367 - val_loss: 8.9663\n",
      "Epoch 46/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.9920 - val_loss: 8.8297\n",
      "Epoch 47/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.4309 - val_loss: 8.6988\n",
      "Epoch 48/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.3940 - val_loss: 8.5715\n",
      "Epoch 49/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.5002 - val_loss: 8.4502\n",
      "Epoch 50/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.6002 - val_loss: 8.3315\n",
      "Epoch 51/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.6290 - val_loss: 8.2159\n",
      "Epoch 52/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.4042 - val_loss: 8.1066\n",
      "Epoch 53/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.0616 - val_loss: 7.9985\n",
      "Epoch 54/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.0911 - val_loss: 7.8923\n",
      "Epoch 55/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8574 - val_loss: 7.7933\n",
      "Epoch 56/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.6736 - val_loss: 7.6957\n",
      "Epoch 57/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.7536 - val_loss: 7.6007\n",
      "Epoch 58/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8742 - val_loss: 7.5088\n",
      "Epoch 59/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8570 - val_loss: 7.4204\n",
      "Epoch 60/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.2779 - val_loss: 7.3361\n",
      "Epoch 61/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.5733 - val_loss: 7.2535\n",
      "Epoch 62/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.0018 - val_loss: 7.1733\n",
      "Epoch 63/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.9660 - val_loss: 7.0952\n",
      "Epoch 64/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.5521 - val_loss: 7.0170\n",
      "Epoch 65/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7501 - val_loss: 6.9446\n",
      "Epoch 66/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.2177 - val_loss: 6.8706\n",
      "Epoch 67/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5431 - val_loss: 6.8014\n",
      "Epoch 68/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7370 - val_loss: 6.7321\n",
      "Epoch 69/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5762 - val_loss: 6.6649\n",
      "Epoch 70/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.8866 - val_loss: 6.5999\n",
      "Epoch 71/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.3661 - val_loss: 6.5372\n",
      "Epoch 72/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.8916 - val_loss: 6.4741\n",
      "Epoch 73/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.4677 - val_loss: 6.4138\n",
      "Epoch 74/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5880 - val_loss: 6.3532\n",
      "Epoch 75/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.6654 - val_loss: 6.2929\n",
      "Epoch 76/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.1228 - val_loss: 6.2373\n",
      "Epoch 77/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.3391 - val_loss: 6.1816\n",
      "Epoch 78/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.0823 - val_loss: 6.1275\n",
      "Epoch 79/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.3638 - val_loss: 6.0730\n",
      "Epoch 80/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.0296 - val_loss: 6.0219\n",
      "Epoch 81/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.8280 - val_loss: 5.9707\n",
      "Epoch 82/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.3255 - val_loss: 5.9192\n",
      "Epoch 83/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.6788 - val_loss: 5.8718\n",
      "Epoch 84/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.7813 - val_loss: 5.8229\n",
      "Epoch 85/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.8150 - val_loss: 5.7757\n",
      "Epoch 86/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.1204 - val_loss: 5.7283\n",
      "Epoch 87/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.6656 - val_loss: 5.6833\n",
      "Epoch 88/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.8701 - val_loss: 5.6386\n",
      "Epoch 89/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.3941 - val_loss: 5.5964\n",
      "Epoch 90/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.9874 - val_loss: 5.5534\n",
      "Epoch 91/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.5899 - val_loss: 5.5129\n",
      "Epoch 92/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.4884 - val_loss: 5.4727\n",
      "Epoch 93/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.8435 - val_loss: 5.4325\n",
      "Epoch 94/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.3053 - val_loss: 5.3933\n",
      "Epoch 95/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.5783 - val_loss: 5.3541\n",
      "Epoch 96/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.4201 - val_loss: 5.3165\n",
      "Epoch 97/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2529 - val_loss: 5.2800\n",
      "Epoch 98/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2353 - val_loss: 5.2424\n",
      "Epoch 99/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.3928 - val_loss: 5.2060\n",
      "Epoch 100/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.1256 - val_loss: 5.1710\n",
      "Epoch 101/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.5175 - val_loss: 5.1360\n",
      "Epoch 102/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2636 - val_loss: 5.1027\n",
      "Epoch 103/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.1566 - val_loss: 5.0697\n",
      "Epoch 104/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.1942 - val_loss: 5.0378\n",
      "Epoch 105/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9203 - val_loss: 5.0064\n",
      "Epoch 106/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.8538 - val_loss: 4.9761\n",
      "Epoch 107/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2591 - val_loss: 4.9457\n",
      "Epoch 108/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.1135 - val_loss: 4.9168\n",
      "Epoch 109/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2138 - val_loss: 4.8874\n",
      "Epoch 110/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.1111 - val_loss: 4.8591\n",
      "Epoch 111/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.8265 - val_loss: 4.8321\n",
      "Epoch 112/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9145 - val_loss: 4.8042\n",
      "Epoch 113/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.7761 - val_loss: 4.7777\n",
      "Epoch 114/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9485 - val_loss: 4.7514\n",
      "Epoch 115/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6296 - val_loss: 4.7262\n",
      "Epoch 116/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.7225 - val_loss: 4.7009\n",
      "Epoch 117/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.7091 - val_loss: 4.6762\n",
      "Epoch 118/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6447 - val_loss: 4.6521\n",
      "Epoch 119/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5539 - val_loss: 4.6289\n",
      "Epoch 120/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5662 - val_loss: 4.6056\n",
      "Epoch 121/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6934 - val_loss: 4.5824\n",
      "Epoch 122/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6030 - val_loss: 4.5605\n",
      "Epoch 123/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6952 - val_loss: 4.5390\n",
      "Epoch 124/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5370 - val_loss: 4.5178\n",
      "Epoch 125/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.5498 - val_loss: 4.4961\n",
      "Epoch 126/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.3656 - val_loss: 4.4756\n",
      "Epoch 127/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.6864 - val_loss: 4.4543\n",
      "Epoch 128/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4667 - val_loss: 4.4350\n",
      "Epoch 129/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4810 - val_loss: 4.4160\n",
      "Epoch 130/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2953 - val_loss: 4.3977\n",
      "Epoch 131/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4758 - val_loss: 4.3786\n",
      "Epoch 132/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4911 - val_loss: 4.3599\n",
      "Epoch 133/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2861 - val_loss: 4.3422\n",
      "Epoch 134/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.2763 - val_loss: 4.3253\n",
      "Epoch 135/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4508 - val_loss: 4.3080\n",
      "Epoch 136/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4572 - val_loss: 4.2913\n",
      "Epoch 137/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2075 - val_loss: 4.2755\n",
      "Epoch 138/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2429 - val_loss: 4.2591\n",
      "Epoch 139/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4217 - val_loss: 4.2427\n",
      "Epoch 140/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2636 - val_loss: 4.2271\n",
      "Epoch 141/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.4301 - val_loss: 4.2115\n",
      "Epoch 142/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1524 - val_loss: 4.1970\n",
      "Epoch 143/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.3556 - val_loss: 4.1822\n",
      "Epoch 144/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2989 - val_loss: 4.1678\n",
      "Epoch 145/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2987 - val_loss: 4.1538\n",
      "Epoch 146/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1581 - val_loss: 4.1402\n",
      "Epoch 147/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1109 - val_loss: 4.1274\n",
      "Epoch 148/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.2810 - val_loss: 4.1140\n",
      "Epoch 149/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.3504 - val_loss: 4.1010\n",
      "Epoch 150/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0438 - val_loss: 4.0891\n",
      "Epoch 151/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.2507 - val_loss: 4.0760\n",
      "Epoch 152/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.1117 - val_loss: 4.0640\n",
      "Epoch 153/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0642 - val_loss: 4.0520\n",
      "Epoch 154/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1004 - val_loss: 4.0402\n",
      "Epoch 155/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1919 - val_loss: 4.0289\n",
      "Epoch 156/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0902 - val_loss: 4.0180\n",
      "Epoch 157/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1562 - val_loss: 4.0070\n",
      "Epoch 158/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0169 - val_loss: 3.9959\n",
      "Epoch 159/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0879 - val_loss: 3.9853\n",
      "Epoch 160/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0280 - val_loss: 3.9750\n",
      "Epoch 161/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0306 - val_loss: 3.9648\n",
      "Epoch 162/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.1542 - val_loss: 3.9548\n",
      "Epoch 163/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9936 - val_loss: 3.9456\n",
      "Epoch 164/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8865 - val_loss: 3.9361\n",
      "Epoch 165/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8713 - val_loss: 3.9266\n",
      "Epoch 166/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8821 - val_loss: 3.9177\n",
      "Epoch 167/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0490 - val_loss: 3.9088\n",
      "Epoch 168/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8785 - val_loss: 3.9000\n",
      "Epoch 169/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0742 - val_loss: 3.8908\n",
      "Epoch 170/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0130 - val_loss: 3.8823\n",
      "Epoch 171/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8545 - val_loss: 3.8742\n",
      "Epoch 172/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8689 - val_loss: 3.8655\n",
      "Epoch 173/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8753 - val_loss: 3.8570\n",
      "Epoch 174/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8687 - val_loss: 3.8489\n",
      "Epoch 175/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8008 - val_loss: 3.8409\n",
      "Epoch 176/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9153 - val_loss: 3.8334\n",
      "Epoch 177/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.0076 - val_loss: 3.8255\n",
      "Epoch 178/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7767 - val_loss: 3.8185\n",
      "Epoch 179/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9068 - val_loss: 3.8109\n",
      "Epoch 180/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9022 - val_loss: 3.8039\n",
      "Epoch 181/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7481 - val_loss: 3.7972\n",
      "Epoch 182/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8113 - val_loss: 3.7903\n",
      "Epoch 183/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8140 - val_loss: 3.7835\n",
      "Epoch 184/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7585 - val_loss: 3.7770\n",
      "Epoch 185/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8754 - val_loss: 3.7704\n",
      "Epoch 186/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8658 - val_loss: 3.7643\n",
      "Epoch 187/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8326 - val_loss: 3.7581\n",
      "Epoch 188/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6867 - val_loss: 3.7521\n",
      "Epoch 189/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9221 - val_loss: 3.7456\n",
      "Epoch 190/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8676 - val_loss: 3.7397\n",
      "Epoch 191/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5984 - val_loss: 3.7342\n",
      "Epoch 192/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.7024 - val_loss: 3.7285\n",
      "Epoch 193/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.8143 - val_loss: 3.7226\n",
      "Epoch 194/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.8011 - val_loss: 3.7171\n",
      "Epoch 195/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.9143 - val_loss: 3.7116\n",
      "Epoch 196/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7508 - val_loss: 3.7066\n",
      "Epoch 197/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6600 - val_loss: 3.7015\n",
      "Epoch 198/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7234 - val_loss: 3.6964\n",
      "Epoch 199/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6835 - val_loss: 3.6915\n",
      "Epoch 200/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7353 - val_loss: 3.6866\n",
      "Epoch 201/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6491 - val_loss: 3.6822\n",
      "Epoch 202/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.7602 - val_loss: 3.6771\n",
      "Epoch 203/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6350 - val_loss: 3.6724\n",
      "Epoch 204/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7596 - val_loss: 3.6679\n",
      "Epoch 205/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6357 - val_loss: 3.6638\n",
      "Epoch 206/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6791 - val_loss: 3.6597\n",
      "Epoch 207/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7226 - val_loss: 3.6554\n",
      "Epoch 208/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7109 - val_loss: 3.6514\n",
      "Epoch 209/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7902 - val_loss: 3.6473\n",
      "Epoch 210/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6923 - val_loss: 3.6436\n",
      "Epoch 211/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5941 - val_loss: 3.6398\n",
      "Epoch 212/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7022 - val_loss: 3.6358\n",
      "Epoch 213/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6204 - val_loss: 3.6323\n",
      "Epoch 214/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.7855 - val_loss: 3.6285\n",
      "Epoch 215/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6312 - val_loss: 3.6247\n",
      "Epoch 216/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6364 - val_loss: 3.6213\n",
      "Epoch 217/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7302 - val_loss: 3.6178\n",
      "Epoch 218/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6855 - val_loss: 3.6143\n",
      "Epoch 219/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5625 - val_loss: 3.6112\n",
      "Epoch 220/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6086 - val_loss: 3.6079\n",
      "Epoch 221/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6230 - val_loss: 3.6046\n",
      "Epoch 222/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6149 - val_loss: 3.6016\n",
      "Epoch 223/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6628 - val_loss: 3.5984\n",
      "Epoch 224/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5905 - val_loss: 3.5955\n",
      "Epoch 225/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7077 - val_loss: 3.5926\n",
      "Epoch 226/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6217 - val_loss: 3.5900\n",
      "Epoch 227/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5781 - val_loss: 3.5873\n",
      "Epoch 228/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6809 - val_loss: 3.5846\n",
      "Epoch 229/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5281 - val_loss: 3.5820\n",
      "Epoch 230/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6928 - val_loss: 3.5792\n",
      "Epoch 231/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5731 - val_loss: 3.5767\n",
      "Epoch 232/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6978 - val_loss: 3.5742\n",
      "Epoch 233/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6900 - val_loss: 3.5717\n",
      "Epoch 234/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5603 - val_loss: 3.5693\n",
      "Epoch 235/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6071 - val_loss: 3.5674\n",
      "Epoch 236/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5603 - val_loss: 3.5650\n",
      "Epoch 237/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5307 - val_loss: 3.5630\n",
      "Epoch 238/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6770 - val_loss: 3.5607\n",
      "Epoch 239/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6493 - val_loss: 3.5584\n",
      "Epoch 240/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6078 - val_loss: 3.5564\n",
      "Epoch 241/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5571 - val_loss: 3.5546\n",
      "Epoch 242/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6581 - val_loss: 3.5525\n",
      "Epoch 243/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5868 - val_loss: 3.5505\n",
      "Epoch 244/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5564 - val_loss: 3.5486\n",
      "Epoch 245/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4473 - val_loss: 3.5470\n",
      "Epoch 246/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4896 - val_loss: 3.5445\n",
      "Epoch 247/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5273 - val_loss: 3.5425\n",
      "Epoch 248/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5448 - val_loss: 3.5408\n",
      "Epoch 249/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.6001 - val_loss: 3.5390\n",
      "Epoch 250/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5872 - val_loss: 3.5375\n",
      "Epoch 251/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5005 - val_loss: 3.5361\n",
      "Epoch 252/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5249 - val_loss: 3.5345\n",
      "Epoch 253/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5526 - val_loss: 3.5330\n",
      "Epoch 254/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4957 - val_loss: 3.5318\n",
      "Epoch 255/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4745 - val_loss: 3.5304\n",
      "Epoch 256/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5112 - val_loss: 3.5291\n",
      "Epoch 257/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5603 - val_loss: 3.5277\n",
      "Epoch 258/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4669 - val_loss: 3.5266\n",
      "Epoch 259/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.5277 - val_loss: 3.5251\n",
      "Epoch 260/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5309 - val_loss: 3.5241\n",
      "Epoch 261/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5860 - val_loss: 3.5226\n",
      "Epoch 262/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5331 - val_loss: 3.5215\n",
      "Epoch 263/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5536 - val_loss: 3.5202\n",
      "Epoch 264/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5036 - val_loss: 3.5189\n",
      "Epoch 265/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5084 - val_loss: 3.5180\n",
      "Epoch 266/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4839 - val_loss: 3.5170\n",
      "Epoch 267/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4627 - val_loss: 3.5158\n",
      "Epoch 268/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5217 - val_loss: 3.5136\n",
      "Epoch 269/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4516 - val_loss: 3.5124\n",
      "Epoch 270/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4320 - val_loss: 3.5107\n",
      "Epoch 271/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4838 - val_loss: 3.5097\n",
      "Epoch 272/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4104 - val_loss: 3.5089\n",
      "Epoch 273/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4431 - val_loss: 3.5082\n",
      "Epoch 274/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5723 - val_loss: 3.5075\n",
      "Epoch 275/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4456 - val_loss: 3.5069\n",
      "Epoch 276/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5532 - val_loss: 3.5058\n",
      "Epoch 277/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4922 - val_loss: 3.5049\n",
      "Epoch 278/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4810 - val_loss: 3.5041\n",
      "Epoch 279/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4455 - val_loss: 3.5034\n",
      "Epoch 280/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4562 - val_loss: 3.5027\n",
      "Epoch 281/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5446 - val_loss: 3.5015\n",
      "Epoch 282/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5084 - val_loss: 3.5006\n",
      "Epoch 283/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4018 - val_loss: 3.5001\n",
      "Epoch 284/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4297 - val_loss: 3.4998\n",
      "Epoch 285/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4054 - val_loss: 3.4991\n",
      "Epoch 286/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3863 - val_loss: 3.4988\n",
      "Epoch 287/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4826 - val_loss: 3.4980\n",
      "Epoch 288/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5700 - val_loss: 3.4973\n",
      "Epoch 289/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5055 - val_loss: 3.4966\n",
      "Epoch 290/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4447 - val_loss: 3.4964\n",
      "Epoch 291/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3799 - val_loss: 3.4958\n",
      "Epoch 292/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3995 - val_loss: 3.4947\n",
      "Epoch 293/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4826 - val_loss: 3.4940\n",
      "Epoch 294/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4476 - val_loss: 3.4928\n",
      "Epoch 295/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4418 - val_loss: 3.4927\n",
      "Epoch 296/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5474 - val_loss: 3.4918\n",
      "Epoch 297/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.4087 - val_loss: 3.4917\n",
      "Epoch 298/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4580 - val_loss: 3.4910\n",
      "Epoch 299/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3644 - val_loss: 3.4907\n",
      "Epoch 300/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4400 - val_loss: 3.4901\n",
      "Epoch 301/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4409 - val_loss: 3.4897\n",
      "Epoch 302/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4577 - val_loss: 3.4889\n",
      "Epoch 303/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4900 - val_loss: 3.4884\n",
      "Epoch 304/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3899 - val_loss: 3.4880\n",
      "Epoch 305/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4511 - val_loss: 3.4874\n",
      "Epoch 306/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4537 - val_loss: 3.4869\n",
      "Epoch 307/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4336 - val_loss: 3.4864\n",
      "Epoch 308/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4054 - val_loss: 3.4859\n",
      "Epoch 309/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4082 - val_loss: 3.4851\n",
      "Epoch 310/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5287 - val_loss: 3.4844\n",
      "Epoch 311/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3236 - val_loss: 3.4843\n",
      "Epoch 312/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4285 - val_loss: 3.4837\n",
      "Epoch 313/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3202 - val_loss: 3.4832\n",
      "Epoch 314/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3253 - val_loss: 3.4829\n",
      "Epoch 315/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3852 - val_loss: 3.4817\n",
      "Epoch 316/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4104 - val_loss: 3.4811\n",
      "Epoch 317/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4256 - val_loss: 3.4806\n",
      "Epoch 318/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4614 - val_loss: 3.4800\n",
      "Epoch 319/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4223 - val_loss: 3.4798\n",
      "Epoch 320/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4119 - val_loss: 3.4790\n",
      "Epoch 321/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4335 - val_loss: 3.4784\n",
      "Epoch 322/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4017 - val_loss: 3.4781\n",
      "Epoch 323/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3686 - val_loss: 3.4778\n",
      "Epoch 324/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3668 - val_loss: 3.4768\n",
      "Epoch 325/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3512 - val_loss: 3.4760\n",
      "Epoch 326/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3766 - val_loss: 3.4755\n",
      "Epoch 327/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.4124 - val_loss: 3.4747\n",
      "Epoch 328/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3591 - val_loss: 3.4750\n",
      "Epoch 329/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3002 - val_loss: 3.4747\n",
      "Epoch 330/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3141 - val_loss: 3.4742\n",
      "Epoch 331/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3908 - val_loss: 3.4735\n",
      "Epoch 332/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3981 - val_loss: 3.4727\n",
      "Epoch 333/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3878 - val_loss: 3.4722\n",
      "Epoch 334/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4369 - val_loss: 3.4711\n",
      "Epoch 335/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4524 - val_loss: 3.4704\n",
      "Epoch 336/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3496 - val_loss: 3.4700\n",
      "Epoch 337/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3503 - val_loss: 3.4692\n",
      "Epoch 338/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3292 - val_loss: 3.4666\n",
      "Epoch 339/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4105 - val_loss: 3.4645\n",
      "Epoch 340/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4137 - val_loss: 3.4640\n",
      "Epoch 341/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3840 - val_loss: 3.4613\n",
      "Epoch 342/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3580 - val_loss: 3.4602\n",
      "Epoch 343/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3081 - val_loss: 3.4602\n",
      "Epoch 344/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4628 - val_loss: 3.4590\n",
      "Epoch 345/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3681 - val_loss: 3.4584\n",
      "Epoch 346/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3331 - val_loss: 3.4580\n",
      "Epoch 347/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3399 - val_loss: 3.4575\n",
      "Epoch 348/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3503 - val_loss: 3.4561\n",
      "Epoch 349/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3784 - val_loss: 3.4551\n",
      "Epoch 350/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4052 - val_loss: 3.4548\n",
      "Epoch 351/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4049 - val_loss: 3.4539\n",
      "Epoch 352/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3377 - val_loss: 3.4538\n",
      "Epoch 353/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2919 - val_loss: 3.4524\n",
      "Epoch 354/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3559 - val_loss: 3.4507\n",
      "Epoch 355/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4167 - val_loss: 3.4497\n",
      "Epoch 356/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3186 - val_loss: 3.4499\n",
      "Epoch 357/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3737 - val_loss: 3.4485\n",
      "Epoch 358/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3385 - val_loss: 3.4474\n",
      "Epoch 359/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2745 - val_loss: 3.4469\n",
      "Epoch 360/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3730 - val_loss: 3.4458\n",
      "Epoch 361/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3398 - val_loss: 3.4447\n",
      "Epoch 362/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3348 - val_loss: 3.4433\n",
      "Epoch 363/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4061 - val_loss: 3.4415\n",
      "Epoch 364/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3098 - val_loss: 3.4413\n",
      "Epoch 365/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3220 - val_loss: 3.4407\n",
      "Epoch 366/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3018 - val_loss: 3.4370\n",
      "Epoch 367/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4675 - val_loss: 3.4334\n",
      "Epoch 368/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3065 - val_loss: 3.4327\n",
      "Epoch 369/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2808 - val_loss: 3.4296\n",
      "Epoch 370/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3589 - val_loss: 3.4265\n",
      "Epoch 371/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3022 - val_loss: 3.4247\n",
      "Epoch 372/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.3053 - val_loss: 3.4238\n",
      "Epoch 373/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3138 - val_loss: 3.4225\n",
      "Epoch 374/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3123 - val_loss: 3.4219\n",
      "Epoch 375/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2923 - val_loss: 3.4211\n",
      "Epoch 376/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3496 - val_loss: 3.4202\n",
      "Epoch 377/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3230 - val_loss: 3.4202\n",
      "Epoch 378/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3276 - val_loss: 3.4191\n",
      "Epoch 379/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3699 - val_loss: 3.4175\n",
      "Epoch 380/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2874 - val_loss: 3.4158\n",
      "Epoch 381/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4017 - val_loss: 3.4143\n",
      "Epoch 382/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3305 - val_loss: 3.4124\n",
      "Epoch 383/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3916 - val_loss: 3.4108\n",
      "Epoch 384/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3238 - val_loss: 3.4093\n",
      "Epoch 385/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3214 - val_loss: 3.4092\n",
      "Epoch 386/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3218 - val_loss: 3.4063\n",
      "Epoch 387/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3311 - val_loss: 3.4044\n",
      "Epoch 388/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3418 - val_loss: 3.4038\n",
      "Epoch 389/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3765 - val_loss: 3.4021\n",
      "Epoch 390/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2846 - val_loss: 3.4013\n",
      "Epoch 391/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2926 - val_loss: 3.3998\n",
      "Epoch 392/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3375 - val_loss: 3.3964\n",
      "Epoch 393/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3079 - val_loss: 3.3950\n",
      "Epoch 394/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3321 - val_loss: 3.3942\n",
      "Epoch 395/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2594 - val_loss: 3.3928\n",
      "Epoch 396/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2396 - val_loss: 3.3917\n",
      "Epoch 397/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2240 - val_loss: 3.3897\n",
      "Epoch 398/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2959 - val_loss: 3.3858\n",
      "Epoch 399/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3038 - val_loss: 3.3832\n",
      "Epoch 400/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2609 - val_loss: 3.3819\n",
      "Epoch 401/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2786 - val_loss: 3.3786\n",
      "Epoch 402/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2304 - val_loss: 3.3753\n",
      "Epoch 403/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3123 - val_loss: 3.3737\n",
      "Epoch 404/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2305 - val_loss: 3.3729\n",
      "Epoch 405/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3224 - val_loss: 3.3708\n",
      "Epoch 406/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2688 - val_loss: 3.3705\n",
      "Epoch 407/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2363 - val_loss: 3.3686\n",
      "Epoch 408/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2693 - val_loss: 3.3660\n",
      "Epoch 409/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2359 - val_loss: 3.3625\n",
      "Epoch 410/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1951 - val_loss: 3.3608\n",
      "Epoch 411/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2539 - val_loss: 3.3588\n",
      "Epoch 412/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2034 - val_loss: 3.3575\n",
      "Epoch 413/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2820 - val_loss: 3.3554\n",
      "Epoch 414/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3044 - val_loss: 3.3542\n",
      "Epoch 415/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3273 - val_loss: 3.3530\n",
      "Epoch 416/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3519 - val_loss: 3.3519\n",
      "Epoch 417/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2639 - val_loss: 3.3507\n",
      "Epoch 418/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2194 - val_loss: 3.3488\n",
      "Epoch 419/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2256 - val_loss: 3.3460\n",
      "Epoch 420/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.2909 - val_loss: 3.3439\n",
      "Epoch 421/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1943 - val_loss: 3.3435\n",
      "Epoch 422/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2758 - val_loss: 3.3390\n",
      "Epoch 423/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2355 - val_loss: 3.3372\n",
      "Epoch 424/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2449 - val_loss: 3.3355\n",
      "Epoch 425/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1855 - val_loss: 3.3328\n",
      "Epoch 426/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1980 - val_loss: 3.3312\n",
      "Epoch 427/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.3669 - val_loss: 3.3279\n",
      "Epoch 428/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2493 - val_loss: 3.3274\n",
      "Epoch 429/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2085 - val_loss: 3.3276\n",
      "Epoch 430/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1395 - val_loss: 3.3257\n",
      "Epoch 431/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2141 - val_loss: 3.3229\n",
      "Epoch 432/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.2891 - val_loss: 3.3213\n",
      "Epoch 433/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2104 - val_loss: 3.3195\n",
      "Epoch 434/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1624 - val_loss: 3.3189\n",
      "Epoch 435/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2275 - val_loss: 3.3155\n",
      "Epoch 436/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2129 - val_loss: 3.3127\n",
      "Epoch 437/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2786 - val_loss: 3.3098\n",
      "Epoch 438/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1354 - val_loss: 3.3084\n",
      "Epoch 439/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2834 - val_loss: 3.3062\n",
      "Epoch 440/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1941 - val_loss: 3.3037\n",
      "Epoch 441/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1986 - val_loss: 3.3018\n",
      "Epoch 442/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2691 - val_loss: 3.2990\n",
      "Epoch 443/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2485 - val_loss: 3.2973\n",
      "Epoch 444/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2135 - val_loss: 3.2959\n",
      "Epoch 445/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1991 - val_loss: 3.2946\n",
      "Epoch 446/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2745 - val_loss: 3.2922\n",
      "Epoch 447/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2741 - val_loss: 3.2909\n",
      "Epoch 448/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2346 - val_loss: 3.2893\n",
      "Epoch 449/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2166 - val_loss: 3.2865\n",
      "Epoch 450/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1888 - val_loss: 3.2851\n",
      "Epoch 451/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2197 - val_loss: 3.2832\n",
      "Epoch 452/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1697 - val_loss: 3.2815\n",
      "Epoch 453/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1540 - val_loss: 3.2804\n",
      "Epoch 454/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2164 - val_loss: 3.2773\n",
      "Epoch 455/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1767 - val_loss: 3.2730\n",
      "Epoch 456/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2069 - val_loss: 3.2702\n",
      "Epoch 457/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1913 - val_loss: 3.2691\n",
      "Epoch 458/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2325 - val_loss: 3.2679\n",
      "Epoch 459/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1890 - val_loss: 3.2660\n",
      "Epoch 460/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1817 - val_loss: 3.2650\n",
      "Epoch 461/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2133 - val_loss: 3.2610\n",
      "Epoch 462/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1085 - val_loss: 3.2603\n",
      "Epoch 463/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1066 - val_loss: 3.2568\n",
      "Epoch 464/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.2327 - val_loss: 3.2551\n",
      "Epoch 465/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1829 - val_loss: 3.2532\n",
      "Epoch 466/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0659 - val_loss: 3.2538\n",
      "Epoch 467/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1805 - val_loss: 3.2496\n",
      "Epoch 468/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1386 - val_loss: 3.2484\n",
      "Epoch 469/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1160 - val_loss: 3.2468\n",
      "Epoch 470/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1066 - val_loss: 3.2459\n",
      "Epoch 471/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1675 - val_loss: 3.2395\n",
      "Epoch 472/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0885 - val_loss: 3.2385\n",
      "Epoch 473/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1871 - val_loss: 3.2356\n",
      "Epoch 474/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0984 - val_loss: 3.2358\n",
      "Epoch 475/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1404 - val_loss: 3.2324\n",
      "Epoch 476/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1657 - val_loss: 3.2274\n",
      "Epoch 477/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1429 - val_loss: 3.2240\n",
      "Epoch 478/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1875 - val_loss: 3.2219\n",
      "Epoch 479/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.2070 - val_loss: 3.2217\n",
      "Epoch 480/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1642 - val_loss: 3.2214\n",
      "Epoch 481/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1183 - val_loss: 3.2209\n",
      "Epoch 482/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0816 - val_loss: 3.2170\n",
      "Epoch 483/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1596 - val_loss: 3.2153\n",
      "Epoch 484/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1036 - val_loss: 3.2157\n",
      "Epoch 485/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1647 - val_loss: 3.2125\n",
      "Epoch 486/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1278 - val_loss: 3.2114\n",
      "Epoch 487/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1203 - val_loss: 3.2117\n",
      "Epoch 488/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1019 - val_loss: 3.2071\n",
      "Epoch 489/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0997 - val_loss: 3.2022\n",
      "Epoch 490/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0241 - val_loss: 3.1995\n",
      "Epoch 491/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0960 - val_loss: 3.1981\n",
      "Epoch 492/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0749 - val_loss: 3.1961\n",
      "Epoch 493/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0791 - val_loss: 3.1955\n",
      "Epoch 494/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0455 - val_loss: 3.1909\n",
      "Epoch 495/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0285 - val_loss: 3.1887\n",
      "Epoch 496/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0835 - val_loss: 3.1859\n",
      "Epoch 497/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0877 - val_loss: 3.1863\n",
      "Epoch 498/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1059 - val_loss: 3.1867\n",
      "Epoch 499/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0742 - val_loss: 3.1844\n",
      "Epoch 500/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.1421 - val_loss: 3.1824\n",
      "Epoch 501/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0506 - val_loss: 3.1820\n",
      "Epoch 502/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0417 - val_loss: 3.1786\n",
      "Epoch 503/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0090 - val_loss: 3.1783\n",
      "Epoch 504/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9741 - val_loss: 3.1772\n",
      "Epoch 505/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0894 - val_loss: 3.1696\n",
      "Epoch 506/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9617 - val_loss: 3.1673\n",
      "Epoch 507/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9997 - val_loss: 3.1637\n",
      "Epoch 508/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9186 - val_loss: 3.1572\n",
      "Epoch 509/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0489 - val_loss: 3.1530\n",
      "Epoch 510/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9703 - val_loss: 3.1560\n",
      "Epoch 511/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0233 - val_loss: 3.1510\n",
      "Epoch 512/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9850 - val_loss: 3.1527\n",
      "Epoch 513/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9418 - val_loss: 3.1535\n",
      "Epoch 514/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9629 - val_loss: 3.1524\n",
      "Epoch 515/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.0012 - val_loss: 3.1538\n",
      "Epoch 516/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9879 - val_loss: 3.1523\n",
      "Epoch 517/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9731 - val_loss: 3.1526\n",
      "Epoch 518/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9727 - val_loss: 3.1473\n",
      "Epoch 519/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9117 - val_loss: 3.1514\n",
      "Epoch 520/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9835 - val_loss: 3.1496\n",
      "Epoch 521/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9877 - val_loss: 3.1424\n",
      "Epoch 522/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9175 - val_loss: 3.1447\n",
      "Epoch 523/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9470 - val_loss: 3.1443\n",
      "Epoch 524/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9691 - val_loss: 3.1435\n",
      "Epoch 525/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9143 - val_loss: 3.1436\n",
      "Epoch 526/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9986 - val_loss: 3.1352\n",
      "Epoch 527/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8746 - val_loss: 3.1376\n",
      "Epoch 528/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8738 - val_loss: 3.1315\n",
      "Epoch 529/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9136 - val_loss: 3.1301\n",
      "Epoch 530/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8540 - val_loss: 3.1354\n",
      "Epoch 531/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9413 - val_loss: 3.1303\n",
      "Epoch 532/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9266 - val_loss: 3.1322\n",
      "Epoch 533/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9632 - val_loss: 3.1308\n",
      "Epoch 534/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9040 - val_loss: 3.1323\n",
      "Epoch 535/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8589 - val_loss: 3.1282\n",
      "Epoch 536/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.9157 - val_loss: 3.1241\n",
      "Epoch 537/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8836 - val_loss: 3.1187\n",
      "Epoch 538/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8420 - val_loss: 3.1157\n",
      "Epoch 539/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8351 - val_loss: 3.1159\n",
      "Epoch 540/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.8514 - val_loss: 3.1152\n",
      "Epoch 541/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8373 - val_loss: 3.1139\n",
      "Epoch 542/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8957 - val_loss: 3.1086\n",
      "Epoch 543/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8437 - val_loss: 3.1071\n",
      "Epoch 544/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8603 - val_loss: 3.1017\n",
      "Epoch 545/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8938 - val_loss: 3.1006\n",
      "Epoch 546/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8723 - val_loss: 3.0979\n",
      "Epoch 547/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8488 - val_loss: 3.0972\n",
      "Epoch 548/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8552 - val_loss: 3.0988\n",
      "Epoch 549/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7323 - val_loss: 3.1024\n",
      "Epoch 550/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8277 - val_loss: 3.0946\n",
      "Epoch 551/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8497 - val_loss: 3.0915\n",
      "Epoch 552/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8598 - val_loss: 3.0831\n",
      "Epoch 553/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7415 - val_loss: 3.0916\n",
      "Epoch 554/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8982 - val_loss: 3.0838\n",
      "Epoch 555/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7903 - val_loss: 3.0891\n",
      "Epoch 556/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7743 - val_loss: 3.0796\n",
      "Epoch 557/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7568 - val_loss: 3.0848\n",
      "Epoch 558/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8300 - val_loss: 3.0761\n",
      "Epoch 559/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8166 - val_loss: 3.0738\n",
      "Epoch 560/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7481 - val_loss: 3.0731\n",
      "Epoch 561/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8234 - val_loss: 3.0674\n",
      "Epoch 562/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7768 - val_loss: 3.0677\n",
      "Epoch 563/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7912 - val_loss: 3.0648\n",
      "Epoch 564/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8289 - val_loss: 3.0521\n",
      "Epoch 565/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7769 - val_loss: 3.0564\n",
      "Epoch 566/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7672 - val_loss: 3.0525\n",
      "Epoch 567/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7555 - val_loss: 3.0472\n",
      "Epoch 568/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7584 - val_loss: 3.0546\n",
      "Epoch 569/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7584 - val_loss: 3.0541\n",
      "Epoch 570/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7480 - val_loss: 3.0497\n",
      "Epoch 571/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7445 - val_loss: 3.0416\n",
      "Epoch 572/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7492 - val_loss: 3.0391\n",
      "Epoch 573/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7413 - val_loss: 3.0433\n",
      "Epoch 574/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6970 - val_loss: 3.0313\n",
      "Epoch 575/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7635 - val_loss: 3.0256\n",
      "Epoch 576/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7539 - val_loss: 3.0335\n",
      "Epoch 577/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7322 - val_loss: 3.0187\n",
      "Epoch 578/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7011 - val_loss: 3.0224\n",
      "Epoch 579/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6900 - val_loss: 3.0287\n",
      "Epoch 580/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6654 - val_loss: 3.0184\n",
      "Epoch 581/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6112 - val_loss: 3.0253\n",
      "Epoch 582/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6585 - val_loss: 3.0172\n",
      "Epoch 583/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6993 - val_loss: 3.0032\n",
      "Epoch 584/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7108 - val_loss: 3.0044\n",
      "Epoch 585/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7442 - val_loss: 2.9941\n",
      "Epoch 586/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6286 - val_loss: 3.0071\n",
      "Epoch 587/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6685 - val_loss: 2.9840\n",
      "Epoch 588/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.7222 - val_loss: 2.9949\n",
      "Epoch 589/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6403 - val_loss: 3.0035\n",
      "Epoch 590/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5647 - val_loss: 3.0077\n",
      "Epoch 591/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6954 - val_loss: 2.9977\n",
      "Epoch 592/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6728 - val_loss: 2.9703\n",
      "Epoch 593/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6921 - val_loss: 2.9711\n",
      "Epoch 594/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6082 - val_loss: 2.9902\n",
      "Epoch 595/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6839 - val_loss: 2.9713\n",
      "Epoch 596/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6062 - val_loss: 2.9852\n",
      "Epoch 597/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6113 - val_loss: 2.9770\n",
      "Epoch 598/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6813 - val_loss: 2.9679\n",
      "Epoch 599/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6400 - val_loss: 2.9693\n",
      "Epoch 600/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6434 - val_loss: 2.9711\n",
      "Epoch 601/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6569 - val_loss: 2.9451\n",
      "Epoch 602/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6294 - val_loss: 2.9546\n",
      "Epoch 603/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6195 - val_loss: 2.9546\n",
      "Epoch 604/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6822 - val_loss: 2.9452\n",
      "Epoch 605/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6276 - val_loss: 2.9516\n",
      "Epoch 606/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5952 - val_loss: 2.9492\n",
      "Epoch 607/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6095 - val_loss: 2.9233\n",
      "Epoch 608/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6581 - val_loss: 2.9365\n",
      "Epoch 609/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6479 - val_loss: 2.9376\n",
      "Epoch 610/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6346 - val_loss: 2.9445\n",
      "Epoch 611/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5874 - val_loss: 2.9423\n",
      "Epoch 612/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5365 - val_loss: 2.9240\n",
      "Epoch 613/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5724 - val_loss: 2.8736\n",
      "Epoch 614/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5625 - val_loss: 2.8670\n",
      "Epoch 615/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6118 - val_loss: 2.9024\n",
      "Epoch 616/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6051 - val_loss: 2.8996\n",
      "Epoch 617/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5879 - val_loss: 2.9161\n",
      "Epoch 618/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5783 - val_loss: 2.9102\n",
      "Epoch 619/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5399 - val_loss: 2.9105\n",
      "Epoch 620/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5259 - val_loss: 2.8875\n",
      "Epoch 621/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5498 - val_loss: 2.8608\n",
      "Epoch 622/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5241 - val_loss: 2.8705\n",
      "Epoch 623/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6186 - val_loss: 2.8833\n",
      "Epoch 624/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5763 - val_loss: 2.8703\n",
      "Epoch 625/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5146 - val_loss: 2.8628\n",
      "Epoch 626/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5540 - val_loss: 2.8785\n",
      "Epoch 627/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5342 - val_loss: 2.8794\n",
      "Epoch 628/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5716 - val_loss: 2.8652\n",
      "Epoch 629/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.6034 - val_loss: 2.8725\n",
      "Epoch 630/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4979 - val_loss: 2.8706\n",
      "Epoch 631/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5396 - val_loss: 2.8625\n",
      "Epoch 632/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4916 - val_loss: 2.8796\n",
      "Epoch 633/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4803 - val_loss: 2.8972\n",
      "Epoch 634/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5076 - val_loss: 2.8658\n",
      "Epoch 635/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4914 - val_loss: 2.8522\n",
      "Epoch 636/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4786 - val_loss: 2.8586\n",
      "Epoch 637/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5298 - val_loss: 2.8585\n",
      "Epoch 638/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4793 - val_loss: 2.8662\n",
      "Epoch 639/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5197 - val_loss: 2.8625\n",
      "Epoch 640/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4828 - val_loss: 2.8596\n",
      "Epoch 641/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4557 - val_loss: 2.8716\n",
      "Epoch 642/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5737 - val_loss: 2.8767\n",
      "Epoch 643/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5334 - val_loss: 2.8643\n",
      "Epoch 644/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4924 - val_loss: 2.8717\n",
      "Epoch 645/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5295 - val_loss: 2.8414\n",
      "Epoch 646/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4706 - val_loss: 2.8543\n",
      "Epoch 647/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4991 - val_loss: 2.8363\n",
      "Epoch 648/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5030 - val_loss: 2.8460\n",
      "Epoch 649/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4945 - val_loss: 2.8568\n",
      "Epoch 650/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5495 - val_loss: 2.8353\n",
      "Epoch 651/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4323 - val_loss: 2.8326\n",
      "Epoch 652/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4309 - val_loss: 2.8285\n",
      "Epoch 653/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4461 - val_loss: 2.8178\n",
      "Epoch 654/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4747 - val_loss: 2.8130\n",
      "Epoch 655/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4663 - val_loss: 2.8350\n",
      "Epoch 656/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4412 - val_loss: 2.8473\n",
      "Epoch 657/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4197 - val_loss: 2.8311\n",
      "Epoch 658/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4562 - val_loss: 2.8054\n",
      "Epoch 659/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4632 - val_loss: 2.8278\n",
      "Epoch 660/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4722 - val_loss: 2.8209\n",
      "Epoch 661/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4007 - val_loss: 2.8052\n",
      "Epoch 662/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4482 - val_loss: 2.7840\n",
      "Epoch 663/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4334 - val_loss: 2.7938\n",
      "Epoch 664/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3779 - val_loss: 2.8069\n",
      "Epoch 665/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4525 - val_loss: 2.8122\n",
      "Epoch 666/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3968 - val_loss: 2.8000\n",
      "Epoch 667/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5199 - val_loss: 2.7892\n",
      "Epoch 668/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3879 - val_loss: 2.8021\n",
      "Epoch 669/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4408 - val_loss: 2.7888\n",
      "Epoch 670/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4451 - val_loss: 2.7929\n",
      "Epoch 671/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4811 - val_loss: 2.7944\n",
      "Epoch 672/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4510 - val_loss: 2.7895\n",
      "Epoch 673/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3919 - val_loss: 2.7871\n",
      "Epoch 674/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4334 - val_loss: 2.7948\n",
      "Epoch 675/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3783 - val_loss: 2.8000\n",
      "Epoch 676/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4652 - val_loss: 2.7801\n",
      "Epoch 677/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4712 - val_loss: 2.7917\n",
      "Epoch 678/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4405 - val_loss: 2.7883\n",
      "Epoch 679/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4070 - val_loss: 2.7761\n",
      "Epoch 680/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3691 - val_loss: 2.7681\n",
      "Epoch 681/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3554 - val_loss: 2.7724\n",
      "Epoch 682/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3300 - val_loss: 2.7710\n",
      "Epoch 683/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3073 - val_loss: 2.7781\n",
      "Epoch 684/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3195 - val_loss: 2.7560\n",
      "Epoch 685/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4160 - val_loss: 2.7476\n",
      "Epoch 686/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4447 - val_loss: 2.7523\n",
      "Epoch 687/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3919 - val_loss: 2.7613\n",
      "Epoch 688/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4595 - val_loss: 2.7242\n",
      "Epoch 689/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.5113 - val_loss: 2.7298\n",
      "Epoch 690/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4140 - val_loss: 2.7504\n",
      "Epoch 691/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3704 - val_loss: 2.7614\n",
      "Epoch 692/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4090 - val_loss: 2.7484\n",
      "Epoch 693/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3974 - val_loss: 2.7335\n",
      "Epoch 694/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3496 - val_loss: 2.7407\n",
      "Epoch 695/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3059 - val_loss: 2.7541\n",
      "Epoch 696/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4314 - val_loss: 2.7308\n",
      "Epoch 697/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3768 - val_loss: 2.7564\n",
      "Epoch 698/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4002 - val_loss: 2.7462\n",
      "Epoch 699/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3564 - val_loss: 2.7411\n",
      "Epoch 700/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3242 - val_loss: 2.7256\n",
      "Epoch 701/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3493 - val_loss: 2.7294\n",
      "Epoch 702/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3817 - val_loss: 2.7221\n",
      "Epoch 703/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3489 - val_loss: 2.7170\n",
      "Epoch 704/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3616 - val_loss: 2.7222\n",
      "Epoch 705/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3370 - val_loss: 2.7334\n",
      "Epoch 706/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2701 - val_loss: 2.7336\n",
      "Epoch 707/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3276 - val_loss: 2.7074\n",
      "Epoch 708/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.3770 - val_loss: 2.7149\n",
      "Epoch 709/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2963 - val_loss: 2.7235\n",
      "Epoch 710/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3500 - val_loss: 2.7188\n",
      "Epoch 711/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3289 - val_loss: 2.7104\n",
      "Epoch 712/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2659 - val_loss: 2.7175\n",
      "Epoch 713/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3125 - val_loss: 2.7135\n",
      "Epoch 714/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3647 - val_loss: 2.7042\n",
      "Epoch 715/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4111 - val_loss: 2.7117\n",
      "Epoch 716/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2874 - val_loss: 2.7210\n",
      "Epoch 717/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2822 - val_loss: 2.6953\n",
      "Epoch 718/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3818 - val_loss: 2.6911\n",
      "Epoch 719/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2853 - val_loss: 2.7077\n",
      "Epoch 720/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2824 - val_loss: 2.7124\n",
      "Epoch 721/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3815 - val_loss: 2.7011\n",
      "Epoch 722/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3534 - val_loss: 2.7017\n",
      "Epoch 723/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3095 - val_loss: 2.6957\n",
      "Epoch 724/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2678 - val_loss: 2.6960\n",
      "Epoch 725/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3976 - val_loss: 2.6789\n",
      "Epoch 726/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2841 - val_loss: 2.6942\n",
      "Epoch 727/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3821 - val_loss: 2.6821\n",
      "Epoch 728/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2267 - val_loss: 2.6958\n",
      "Epoch 729/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2883 - val_loss: 2.6829\n",
      "Epoch 730/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2647 - val_loss: 2.6773\n",
      "Epoch 731/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3269 - val_loss: 2.6699\n",
      "Epoch 732/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2244 - val_loss: 2.6760\n",
      "Epoch 733/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3120 - val_loss: 2.6621\n",
      "Epoch 734/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3575 - val_loss: 2.6731\n",
      "Epoch 735/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3199 - val_loss: 2.6793\n",
      "Epoch 736/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3076 - val_loss: 2.6731\n",
      "Epoch 737/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3166 - val_loss: 2.6864\n",
      "Epoch 738/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3154 - val_loss: 2.6812\n",
      "Epoch 739/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2498 - val_loss: 2.6753\n",
      "Epoch 740/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2885 - val_loss: 2.6659\n",
      "Epoch 741/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2698 - val_loss: 2.6827\n",
      "Epoch 742/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2132 - val_loss: 2.6605\n",
      "Epoch 743/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3408 - val_loss: 2.6405\n",
      "Epoch 744/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2835 - val_loss: 2.6612\n",
      "Epoch 745/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2597 - val_loss: 2.6632\n",
      "Epoch 746/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2497 - val_loss: 2.6759\n",
      "Epoch 747/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3546 - val_loss: 2.6680\n",
      "Epoch 748/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2663 - val_loss: 2.6711\n",
      "Epoch 749/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2284 - val_loss: 2.6787\n",
      "Epoch 750/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2439 - val_loss: 2.6803\n",
      "Epoch 751/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2620 - val_loss: 2.6785\n",
      "Epoch 752/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2744 - val_loss: 2.6812\n",
      "Epoch 753/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2333 - val_loss: 2.6894\n",
      "Epoch 754/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1815 - val_loss: 2.6782\n",
      "Epoch 755/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1829 - val_loss: 2.6677\n",
      "Epoch 756/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2125 - val_loss: 2.6739\n",
      "Epoch 757/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3754 - val_loss: 2.6632\n",
      "Epoch 758/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2053 - val_loss: 2.6644\n",
      "Epoch 759/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2905 - val_loss: 2.6762\n",
      "Epoch 760/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2489 - val_loss: 2.6692\n",
      "Epoch 761/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1683 - val_loss: 2.6891\n",
      "Epoch 762/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2778 - val_loss: 2.6670\n",
      "Epoch 763/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2101 - val_loss: 2.6732\n",
      "Epoch 764/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1815 - val_loss: 2.6801\n",
      "Epoch 765/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2597 - val_loss: 2.6851\n",
      "Epoch 766/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2115 - val_loss: 2.6839\n",
      "Epoch 767/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2287 - val_loss: 2.6868\n",
      "Epoch 768/5000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2516 - val_loss: 2.6893\n",
      "Epoch 769/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2857 - val_loss: 2.6916\n",
      "Epoch 770/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2731 - val_loss: 2.6823\n",
      "Epoch 771/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2415 - val_loss: 2.6740\n",
      "Epoch 772/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2737 - val_loss: 2.6801\n",
      "Epoch 773/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.3554 - val_loss: 2.7037\n",
      "Epoch 774/5000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1975 - val_loss: 2.7131\n",
      "Epoch 775/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2444 - val_loss: 2.6938\n",
      "Epoch 776/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2189 - val_loss: 2.7055\n",
      "Epoch 777/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2055 - val_loss: 2.7042\n",
      "Epoch 778/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2609 - val_loss: 2.6946\n",
      "Epoch 779/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2347 - val_loss: 2.7123\n",
      "Epoch 780/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1862 - val_loss: 2.7239\n",
      "Epoch 781/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2128 - val_loss: 2.7327\n",
      "Epoch 782/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2279 - val_loss: 2.7062\n",
      "Epoch 783/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2068 - val_loss: 2.7148\n",
      "Epoch 784/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1256 - val_loss: 2.6984\n",
      "Epoch 785/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2189 - val_loss: 2.6972\n",
      "Epoch 786/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1811 - val_loss: 2.7001\n",
      "Epoch 787/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1892 - val_loss: 2.7229\n",
      "Epoch 788/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2151 - val_loss: 2.7089\n",
      "Epoch 789/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1974 - val_loss: 2.7142\n",
      "Epoch 790/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2297 - val_loss: 2.7166\n",
      "Epoch 791/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1846 - val_loss: 2.7370\n",
      "Epoch 792/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1941 - val_loss: 2.7367\n",
      "Epoch 793/5000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.2000 - val_loss: 2.7334\n",
      "CPU times: user 1min 16s, sys: 6.21 s, total: 1min 23s\n",
      "Wall time: 56.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_aleatoric = get_probabilistic_mlp(\n",
    "    shape=X_train_prep.shape, \n",
    "    hidden_type=\"dense\", \n",
    "    output_type=\"probabilistic\", \n",
    "    hidden_units=[32, 32], \n",
    "    activations=[\"sigmoid\", \"sigmoid\"],\n",
    "    optimizer=Adam(learning_rate=0.001)\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=50)\n",
    "hist_aleatoric = mlp_aleatoric.fit(\n",
    "    X_train_prep,\n",
    "    y_train, \n",
    "    epochs=5000, \n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "y_aleatoric_train = mlp_aleatoric(X_train_prep)\n",
    "y_aleatoric_train_sample = y_aleatoric_train.sample()\n",
    "y_aleatoric_train_mean = y_aleatoric_train.mean()\n",
    "y_aleatoric_train_std = y_aleatoric_train.stddev()\n",
    "y_aleatoric = mlp_aleatoric(X_test_prep)\n",
    "y_aleatoric_sample = y_aleatoric.sample()\n",
    "y_aleatoric_mean = y_aleatoric.mean()\n",
    "y_aleatoric_std = y_aleatoric.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-rapid",
   "metadata": {},
   "source": [
    "#### Estimation de l'incertitude épistémique par un MLP bayésien avec couches internes `DenseVariational`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9b32b6-5565-49b6-bd9c-3053ee4a1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(kernel_size, bias_size, dtype = None):\n",
    "    \"\"\"\n",
    "    Multivariate Normal Diagonal non-trainable prior (loc=0, scale=1).\n",
    "    \"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = Sequential([\n",
    "        tfpl.DistributionLambda(\n",
    "            lambda t: tfd.MultivariateNormalDiag(\n",
    "                loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    return prior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1b71025-3918-4fe2-bfd9-70f23d811fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_gaussian_initializer(shape, dtype):\n",
    "    \"\"\"\n",
    "    Random gaussian initializer as defined in\n",
    "    https://stackoverflow.com/questions/66418959/not-able-to-get-reasonable-results-from-densevariational\n",
    "    \"\"\"\n",
    "    n = int(shape / 2)\n",
    "    loc_norm = tf.random_normal_initializer(mean=0., stddev=0.1)\n",
    "    loc = tf.Variable(\n",
    "        initial_value=loc_norm(shape=(n,), dtype=dtype)\n",
    "    )\n",
    "    scale_norm = tf.random_normal_initializer(mean=-3., stddev=0.1)\n",
    "    scale = tf.Variable(\n",
    "        initial_value=scale_norm(shape=(n,), dtype=dtype)\n",
    "    )\n",
    "    return tf.concat([loc, scale], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d823a128-7f06-42c9-8dac-06e23ef6178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_field(kernel_size, bias_size, dtype = None):\n",
    "    \"\"\"\n",
    "    Mean-field posterior.\n",
    "    More information can be found here:\n",
    "    https://bjlkeng.github.io/posts/variational-bayes-and-the-mean-field-approximation/\n",
    "    https://en.wikipedia.org/wiki/Variational_Bayesian_methods#Mean_field_approximation\n",
    "    \"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "    return Sequential([\n",
    "        tfpl.VariableLayer(\n",
    "            2*n,\n",
    "            dtype=dtype,\n",
    "            initializer=lambda shape, dtype: random_gaussian_initializer(shape, dtype),\n",
    "            trainable=True\n",
    "        ),\n",
    "        tfpl.DistributionLambda(\n",
    "            lambda t: tfd.Independent(tfd.Normal(\n",
    "                loc=t[..., :n],\n",
    "                scale=1e-5 + 0.001*tf.nn.softplus(c + t[..., n:])\n",
    "            ), reinterpreted_batch_ndims=1)\n",
    "        ),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "novel-japan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/qbox08/miniconda3/envs/bbl-proba-dl/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:167: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "Epoch 1/50000\n",
      "12/12 [==============================] - 1s 33ms/step - loss: 717.3677 - val_loss: 658.2499\n",
      "Epoch 2/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 667.7823 - val_loss: 631.7546\n",
      "Epoch 3/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 616.2113 - val_loss: 607.0041\n",
      "Epoch 4/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 621.6314 - val_loss: 583.6718\n",
      "Epoch 5/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 601.7395 - val_loss: 562.1334\n",
      "Epoch 6/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 551.0188 - val_loss: 542.3060\n",
      "Epoch 7/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 514.2076 - val_loss: 524.4539\n",
      "Epoch 8/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 548.2997 - val_loss: 508.1932\n",
      "Epoch 9/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 507.3824 - val_loss: 493.3953\n",
      "Epoch 10/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 474.7809 - val_loss: 479.5650\n",
      "Epoch 11/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 487.8368 - val_loss: 466.5672\n",
      "Epoch 12/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 472.8382 - val_loss: 454.5410\n",
      "Epoch 13/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 467.7769 - val_loss: 443.2983\n",
      "Epoch 14/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 453.8864 - val_loss: 432.8189\n",
      "Epoch 15/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 416.7390 - val_loss: 422.9225\n",
      "Epoch 16/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 425.5545 - val_loss: 413.6667\n",
      "Epoch 17/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 412.2142 - val_loss: 404.7294\n",
      "Epoch 18/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 415.4308 - val_loss: 396.3119\n",
      "Epoch 19/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 379.1874 - val_loss: 388.2769\n",
      "Epoch 20/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 368.8963 - val_loss: 380.5990\n",
      "Epoch 21/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 392.4491 - val_loss: 372.8929\n",
      "Epoch 22/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 356.0337 - val_loss: 365.6877\n",
      "Epoch 23/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 385.0850 - val_loss: 358.5385\n",
      "Epoch 24/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 359.2056 - val_loss: 351.4875\n",
      "Epoch 25/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 358.4526 - val_loss: 344.6090\n",
      "Epoch 26/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 344.3367 - val_loss: 337.4963\n",
      "Epoch 27/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 346.5460 - val_loss: 330.5386\n",
      "Epoch 28/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 349.9223 - val_loss: 323.5386\n",
      "Epoch 29/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 331.2598 - val_loss: 316.7081\n",
      "Epoch 30/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 334.1147 - val_loss: 309.6455\n",
      "Epoch 31/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 325.5727 - val_loss: 303.0127\n",
      "Epoch 32/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 303.0305 - val_loss: 296.3332\n",
      "Epoch 33/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 311.9690 - val_loss: 290.3174\n",
      "Epoch 34/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 309.0594 - val_loss: 284.2687\n",
      "Epoch 35/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 303.2032 - val_loss: 278.4414\n",
      "Epoch 36/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 306.9713 - val_loss: 272.2085\n",
      "Epoch 37/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 268.0597 - val_loss: 266.2415\n",
      "Epoch 38/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 276.4974 - val_loss: 260.2854\n",
      "Epoch 39/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 265.3403 - val_loss: 254.4465\n",
      "Epoch 40/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 266.4051 - val_loss: 248.9347\n",
      "Epoch 41/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 263.4694 - val_loss: 243.7207\n",
      "Epoch 42/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 250.6753 - val_loss: 238.7783\n",
      "Epoch 43/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 239.3863 - val_loss: 233.9677\n",
      "Epoch 44/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 240.3939 - val_loss: 229.3447\n",
      "Epoch 45/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 257.8122 - val_loss: 225.0356\n",
      "Epoch 46/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 223.5784 - val_loss: 220.6923\n",
      "Epoch 47/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 228.7458 - val_loss: 216.6093\n",
      "Epoch 48/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 233.7404 - val_loss: 212.5724\n",
      "Epoch 49/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 221.6292 - val_loss: 208.7919\n",
      "Epoch 50/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 222.0096 - val_loss: 205.0814\n",
      "Epoch 51/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 225.3430 - val_loss: 201.4978\n",
      "Epoch 52/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 203.0807 - val_loss: 198.0730\n",
      "Epoch 53/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 215.1975 - val_loss: 194.6771\n",
      "Epoch 54/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 200.1980 - val_loss: 191.3705\n",
      "Epoch 55/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 225.9407 - val_loss: 188.1592\n",
      "Epoch 56/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 179.4208 - val_loss: 185.2556\n",
      "Epoch 57/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 190.5994 - val_loss: 182.3071\n",
      "Epoch 58/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 189.4340 - val_loss: 179.3554\n",
      "Epoch 59/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 193.7880 - val_loss: 176.6768\n",
      "Epoch 60/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 191.4677 - val_loss: 174.0464\n",
      "Epoch 61/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 179.7265 - val_loss: 171.4139\n",
      "Epoch 62/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 184.1225 - val_loss: 168.9021\n",
      "Epoch 63/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 170.9492 - val_loss: 166.4896\n",
      "Epoch 64/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 177.2954 - val_loss: 164.1331\n",
      "Epoch 65/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 171.7965 - val_loss: 161.8307\n",
      "Epoch 66/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 170.7075 - val_loss: 159.6308\n",
      "Epoch 67/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 163.6915 - val_loss: 157.3915\n",
      "Epoch 68/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 154.6213 - val_loss: 155.2785\n",
      "Epoch 69/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 181.1630 - val_loss: 153.1705\n",
      "Epoch 70/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 161.1167 - val_loss: 151.2491\n",
      "Epoch 71/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 169.6267 - val_loss: 149.1179\n",
      "Epoch 72/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 163.9187 - val_loss: 147.3286\n",
      "Epoch 73/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 165.1309 - val_loss: 145.5393\n",
      "Epoch 74/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 157.2230 - val_loss: 143.7478\n",
      "Epoch 75/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 142.6568 - val_loss: 142.2548\n",
      "Epoch 76/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 143.7911 - val_loss: 140.3972\n",
      "Epoch 77/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 142.7229 - val_loss: 138.7241\n",
      "Epoch 78/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 144.1996 - val_loss: 137.1629\n",
      "Epoch 79/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 150.7014 - val_loss: 135.4671\n",
      "Epoch 80/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 132.6957 - val_loss: 133.9738\n",
      "Epoch 81/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 152.8328 - val_loss: 132.5117\n",
      "Epoch 82/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 144.7244 - val_loss: 131.0381\n",
      "Epoch 83/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 136.1622 - val_loss: 129.6520\n",
      "Epoch 84/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 145.9133 - val_loss: 128.4003\n",
      "Epoch 85/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 138.4031 - val_loss: 126.8627\n",
      "Epoch 86/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 127.3820 - val_loss: 125.7162\n",
      "Epoch 87/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 137.4155 - val_loss: 124.1851\n",
      "Epoch 88/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 130.7880 - val_loss: 123.1966\n",
      "Epoch 89/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 146.8011 - val_loss: 122.0725\n",
      "Epoch 90/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 133.8096 - val_loss: 120.8371\n",
      "Epoch 91/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 119.0692 - val_loss: 119.8396\n",
      "Epoch 92/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 121.9033 - val_loss: 118.8026\n",
      "Epoch 93/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 114.4210 - val_loss: 117.7965\n",
      "Epoch 94/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 122.1806 - val_loss: 116.6757\n",
      "Epoch 95/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 119.8093 - val_loss: 115.5625\n",
      "Epoch 96/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 128.0079 - val_loss: 114.6616\n",
      "Epoch 97/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 129.3111 - val_loss: 113.7702\n",
      "Epoch 98/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 108.7928 - val_loss: 112.9036\n",
      "Epoch 99/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 119.6067 - val_loss: 112.0996\n",
      "Epoch 100/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 103.8039 - val_loss: 111.2496\n",
      "Epoch 101/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 124.4080 - val_loss: 110.2214\n",
      "Epoch 102/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 110.3503 - val_loss: 109.4767\n",
      "Epoch 103/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 115.7808 - val_loss: 108.5597\n",
      "Epoch 104/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 109.2820 - val_loss: 107.7784\n",
      "Epoch 105/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 112.6797 - val_loss: 107.0080\n",
      "Epoch 106/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 118.5313 - val_loss: 106.2582\n",
      "Epoch 107/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 107.2282 - val_loss: 105.6365\n",
      "Epoch 108/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 108.3805 - val_loss: 104.8339\n",
      "Epoch 109/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 105.7315 - val_loss: 104.3567\n",
      "Epoch 110/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 112.1334 - val_loss: 103.5204\n",
      "Epoch 111/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 108.6625 - val_loss: 102.8561\n",
      "Epoch 112/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 104.2529 - val_loss: 102.0557\n",
      "Epoch 113/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 97.9461 - val_loss: 101.5523\n",
      "Epoch 114/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 104.2382 - val_loss: 100.7593\n",
      "Epoch 115/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 92.2067 - val_loss: 100.1343\n",
      "Epoch 116/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 110.6100 - val_loss: 99.3254\n",
      "Epoch 117/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 110.6181 - val_loss: 98.6729\n",
      "Epoch 118/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 106.4032 - val_loss: 98.2268\n",
      "Epoch 119/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 104.6682 - val_loss: 97.4982\n",
      "Epoch 120/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 95.9639 - val_loss: 97.0368\n",
      "Epoch 121/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 99.6047 - val_loss: 96.5580\n",
      "Epoch 122/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 97.8296 - val_loss: 95.9255\n",
      "Epoch 123/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.5628 - val_loss: 95.4023\n",
      "Epoch 124/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 101.3754 - val_loss: 94.9930\n",
      "Epoch 125/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 97.1024 - val_loss: 94.4354\n",
      "Epoch 126/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 107.3205 - val_loss: 93.8262\n",
      "Epoch 127/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 97.8233 - val_loss: 93.3679\n",
      "Epoch 128/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 101.8842 - val_loss: 92.8550\n",
      "Epoch 129/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 86.8764 - val_loss: 92.4174\n",
      "Epoch 130/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 91.7744 - val_loss: 92.0103\n",
      "Epoch 131/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 107.5617 - val_loss: 91.4264\n",
      "Epoch 132/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 87.1508 - val_loss: 91.0805\n",
      "Epoch 133/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 95.7398 - val_loss: 90.6501\n",
      "Epoch 134/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 90.7242 - val_loss: 90.2306\n",
      "Epoch 135/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 94.2679 - val_loss: 89.6970\n",
      "Epoch 136/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 93.8117 - val_loss: 89.3154\n",
      "Epoch 137/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 98.4322 - val_loss: 88.9900\n",
      "Epoch 138/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 88.1052 - val_loss: 88.5050\n",
      "Epoch 139/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 92.6576 - val_loss: 88.1586\n",
      "Epoch 140/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 96.2927 - val_loss: 87.7136\n",
      "Epoch 141/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 95.0592 - val_loss: 87.3579\n",
      "Epoch 142/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 90.5357 - val_loss: 86.9700\n",
      "Epoch 143/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 91.6322 - val_loss: 86.6713\n",
      "Epoch 144/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 89.2318 - val_loss: 86.3592\n",
      "Epoch 145/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 92.0901 - val_loss: 86.0723\n",
      "Epoch 146/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.1902 - val_loss: 85.9190\n",
      "Epoch 147/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 79.1062 - val_loss: 85.5935\n",
      "Epoch 148/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 91.6649 - val_loss: 85.1735\n",
      "Epoch 149/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 95.9242 - val_loss: 84.9407\n",
      "Epoch 150/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.6312 - val_loss: 84.5667\n",
      "Epoch 151/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 95.2245 - val_loss: 84.3716\n",
      "Epoch 152/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.0632 - val_loss: 83.9673\n",
      "Epoch 153/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 92.1697 - val_loss: 83.7959\n",
      "Epoch 154/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 83.2265 - val_loss: 83.5351\n",
      "Epoch 155/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 99.6953 - val_loss: 83.2919\n",
      "Epoch 156/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.8721 - val_loss: 82.9583\n",
      "Epoch 157/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 80.4436 - val_loss: 82.8179\n",
      "Epoch 158/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 91.6159 - val_loss: 82.6655\n",
      "Epoch 159/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 88.3298 - val_loss: 82.3797\n",
      "Epoch 160/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 83.3281 - val_loss: 82.3328\n",
      "Epoch 161/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.8530 - val_loss: 81.9815\n",
      "Epoch 162/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 83.9115 - val_loss: 81.8346\n",
      "Epoch 163/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 90.9006 - val_loss: 81.7094\n",
      "Epoch 164/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 79.2587 - val_loss: 81.5947\n",
      "Epoch 165/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 80.7304 - val_loss: 81.3235\n",
      "Epoch 166/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 80.9587 - val_loss: 81.1418\n",
      "Epoch 167/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 82.2545 - val_loss: 81.0834\n",
      "Epoch 168/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 74.2396 - val_loss: 80.9215\n",
      "Epoch 169/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 77.3883 - val_loss: 80.6375\n",
      "Epoch 170/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 94.6135 - val_loss: 80.3571\n",
      "Epoch 171/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 83.8603 - val_loss: 80.2113\n",
      "Epoch 172/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 84.4704 - val_loss: 80.0640\n",
      "Epoch 173/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 81.0681 - val_loss: 79.8007\n",
      "Epoch 174/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 80.0197 - val_loss: 79.6971\n",
      "Epoch 175/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 80.3353 - val_loss: 79.3223\n",
      "Epoch 176/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 87.6611 - val_loss: 79.1659\n",
      "Epoch 177/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85.1418 - val_loss: 78.7755\n",
      "Epoch 178/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76.9681 - val_loss: 78.9496\n",
      "Epoch 179/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 82.8661 - val_loss: 78.7785\n",
      "Epoch 180/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 81.9101 - val_loss: 78.5158\n",
      "Epoch 181/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76.4228 - val_loss: 78.4308\n",
      "Epoch 182/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 77.1442 - val_loss: 78.0013\n",
      "Epoch 183/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76.3989 - val_loss: 77.7548\n",
      "Epoch 184/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 71.7895 - val_loss: 77.7160\n",
      "Epoch 185/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 69.3391 - val_loss: 77.4616\n",
      "Epoch 186/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 75.7527 - val_loss: 77.1419\n",
      "Epoch 187/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 74.7260 - val_loss: 76.9958\n",
      "Epoch 188/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 70.4308 - val_loss: 76.5918\n",
      "Epoch 189/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 81.2950 - val_loss: 76.1231\n",
      "Epoch 190/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 83.3634 - val_loss: 75.9141\n",
      "Epoch 191/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 67.6390 - val_loss: 75.7268\n",
      "Epoch 192/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 73.6425 - val_loss: 75.4669\n",
      "Epoch 193/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 74.0335 - val_loss: 75.1289\n",
      "Epoch 194/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76.8532 - val_loss: 74.6355\n",
      "Epoch 195/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 70.8234 - val_loss: 74.6572\n",
      "Epoch 196/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76.4977 - val_loss: 74.0229\n",
      "Epoch 197/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 73.0284 - val_loss: 73.8281\n",
      "Epoch 198/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 79.0673 - val_loss: 73.5082\n",
      "Epoch 199/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 73.4189 - val_loss: 73.2180\n",
      "Epoch 200/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 73.0214 - val_loss: 72.9012\n",
      "Epoch 201/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 71.7004 - val_loss: 72.4536\n",
      "Epoch 202/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76.1819 - val_loss: 72.0210\n",
      "Epoch 203/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 71.3910 - val_loss: 71.8422\n",
      "Epoch 204/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 79.6922 - val_loss: 71.5014\n",
      "Epoch 205/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 68.8797 - val_loss: 71.2976\n",
      "Epoch 206/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 73.4828 - val_loss: 70.9565\n",
      "Epoch 207/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 77.1558 - val_loss: 70.7682\n",
      "Epoch 208/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 67.5447 - val_loss: 70.4475\n",
      "Epoch 209/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 70.6484 - val_loss: 69.9850\n",
      "Epoch 210/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 64.7729 - val_loss: 69.9855\n",
      "Epoch 211/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 63.2270 - val_loss: 69.6504\n",
      "Epoch 212/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 72.0578 - val_loss: 69.3043\n",
      "Epoch 213/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 61.9437 - val_loss: 69.1545\n",
      "Epoch 214/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 61.6496 - val_loss: 69.0256\n",
      "Epoch 215/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 60.7295 - val_loss: 68.6623\n",
      "Epoch 216/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 68.4641 - val_loss: 68.4987\n",
      "Epoch 217/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 61.6859 - val_loss: 68.1811\n",
      "Epoch 218/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 63.1294 - val_loss: 68.1362\n",
      "Epoch 219/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 69.3058 - val_loss: 67.7409\n",
      "Epoch 220/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 64.2419 - val_loss: 67.4389\n",
      "Epoch 221/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 62.1333 - val_loss: 67.3227\n",
      "Epoch 222/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 66.2547 - val_loss: 67.2155\n",
      "Epoch 223/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 67.1170 - val_loss: 66.8139\n",
      "Epoch 224/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 68.6195 - val_loss: 66.5028\n",
      "Epoch 225/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 66.6362 - val_loss: 66.2861\n",
      "Epoch 226/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 62.1000 - val_loss: 66.1532\n",
      "Epoch 227/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 61.3270 - val_loss: 65.9830\n",
      "Epoch 228/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 62.1456 - val_loss: 65.7436\n",
      "Epoch 229/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.5000 - val_loss: 65.5350\n",
      "Epoch 230/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 63.9589 - val_loss: 65.2166\n",
      "Epoch 231/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.8918 - val_loss: 65.0090\n",
      "Epoch 232/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 56.5161 - val_loss: 64.5997\n",
      "Epoch 233/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 63.0755 - val_loss: 64.3576\n",
      "Epoch 234/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 63.0056 - val_loss: 64.2308\n",
      "Epoch 235/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.9292 - val_loss: 63.8787\n",
      "Epoch 236/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 58.8059 - val_loss: 63.4365\n",
      "Epoch 237/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 54.8906 - val_loss: 63.4613\n",
      "Epoch 238/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 58.9728 - val_loss: 63.3862\n",
      "Epoch 239/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 56.9159 - val_loss: 63.2003\n",
      "Epoch 240/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 60.7510 - val_loss: 62.9276\n",
      "Epoch 241/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.7441 - val_loss: 62.7866\n",
      "Epoch 242/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 61.0479 - val_loss: 62.4260\n",
      "Epoch 243/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 57.9236 - val_loss: 62.2531\n",
      "Epoch 244/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 55.3632 - val_loss: 62.2834\n",
      "Epoch 245/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 56.2149 - val_loss: 61.9767\n",
      "Epoch 246/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 58.7094 - val_loss: 61.8870\n",
      "Epoch 247/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.8575 - val_loss: 61.6367\n",
      "Epoch 248/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 54.2404 - val_loss: 61.4610\n",
      "Epoch 249/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 53.5767 - val_loss: 61.0746\n",
      "Epoch 250/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 56.1875 - val_loss: 60.9982\n",
      "Epoch 251/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 54.5933 - val_loss: 60.5822\n",
      "Epoch 252/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 55.2966 - val_loss: 60.4283\n",
      "Epoch 253/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.3591 - val_loss: 60.3175\n",
      "Epoch 254/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 53.7359 - val_loss: 60.2562\n",
      "Epoch 255/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 51.8427 - val_loss: 60.2325\n",
      "Epoch 256/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 53.0699 - val_loss: 59.9791\n",
      "Epoch 257/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 54.5390 - val_loss: 59.7345\n",
      "Epoch 258/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 57.1047 - val_loss: 59.5006\n",
      "Epoch 259/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.1342 - val_loss: 59.3631\n",
      "Epoch 260/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 56.1360 - val_loss: 59.1659\n",
      "Epoch 261/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 53.5548 - val_loss: 59.2383\n",
      "Epoch 262/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 55.0214 - val_loss: 58.8802\n",
      "Epoch 263/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 56.4454 - val_loss: 58.7707\n",
      "Epoch 264/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 52.4942 - val_loss: 58.5361\n",
      "Epoch 265/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 52.5771 - val_loss: 58.6172\n",
      "Epoch 266/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 57.4769 - val_loss: 58.1404\n",
      "Epoch 267/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 54.5016 - val_loss: 57.9945\n",
      "Epoch 268/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 55.9070 - val_loss: 57.8994\n",
      "Epoch 269/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 49.7165 - val_loss: 57.8630\n",
      "Epoch 270/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 53.2713 - val_loss: 57.7254\n",
      "Epoch 271/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 53.9356 - val_loss: 57.6703\n",
      "Epoch 272/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 52.5588 - val_loss: 57.5954\n",
      "Epoch 273/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50.8079 - val_loss: 57.1280\n",
      "Epoch 274/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50.7687 - val_loss: 57.1271\n",
      "Epoch 275/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 53.4521 - val_loss: 56.9260\n",
      "Epoch 276/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.7812 - val_loss: 56.8377\n",
      "Epoch 277/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 46.5485 - val_loss: 56.7086\n",
      "Epoch 278/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 48.3743 - val_loss: 56.4179\n",
      "Epoch 279/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50.5792 - val_loss: 56.3939\n",
      "Epoch 280/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 52.5882 - val_loss: 56.3086\n",
      "Epoch 281/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 52.8691 - val_loss: 56.1552\n",
      "Epoch 282/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 51.6881 - val_loss: 55.9414\n",
      "Epoch 283/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 54.3492 - val_loss: 55.8853\n",
      "Epoch 284/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.9158 - val_loss: 55.9436\n",
      "Epoch 285/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 46.9809 - val_loss: 55.7731\n",
      "Epoch 286/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 51.4407 - val_loss: 55.7224\n",
      "Epoch 287/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 52.6487 - val_loss: 55.6551\n",
      "Epoch 288/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 48.4654 - val_loss: 55.4663\n",
      "Epoch 289/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50.5695 - val_loss: 55.3095\n",
      "Epoch 290/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.3781 - val_loss: 55.0930\n",
      "Epoch 291/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 48.9272 - val_loss: 55.0818\n",
      "Epoch 292/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 48.2261 - val_loss: 54.8708\n",
      "Epoch 293/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.9561 - val_loss: 54.7429\n",
      "Epoch 294/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 48.4935 - val_loss: 54.6515\n",
      "Epoch 295/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 49.9177 - val_loss: 54.7217\n",
      "Epoch 296/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 48.8511 - val_loss: 54.4660\n",
      "Epoch 297/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.5098 - val_loss: 54.3632\n",
      "Epoch 298/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50.6373 - val_loss: 54.3071\n",
      "Epoch 299/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.9763 - val_loss: 54.0611\n",
      "Epoch 300/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.7532 - val_loss: 53.9610\n",
      "Epoch 301/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.6404 - val_loss: 54.0832\n",
      "Epoch 302/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 49.1860 - val_loss: 54.0168\n",
      "Epoch 303/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.6403 - val_loss: 53.5473\n",
      "Epoch 304/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 47.9124 - val_loss: 53.5325\n",
      "Epoch 305/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 49.7723 - val_loss: 53.4077\n",
      "Epoch 306/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 44.7610 - val_loss: 53.5784\n",
      "Epoch 307/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.8136 - val_loss: 53.6893\n",
      "Epoch 308/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 46.4472 - val_loss: 53.4037\n",
      "Epoch 309/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.2433 - val_loss: 53.3129\n",
      "Epoch 310/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 49.4055 - val_loss: 52.9302\n",
      "Epoch 311/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 48.0439 - val_loss: 52.7280\n",
      "Epoch 312/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 48.8291 - val_loss: 52.7279\n",
      "Epoch 313/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.4657 - val_loss: 52.7450\n",
      "Epoch 314/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 46.2181 - val_loss: 52.6750\n",
      "Epoch 315/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 43.8458 - val_loss: 52.7999\n",
      "Epoch 316/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.1477 - val_loss: 52.2567\n",
      "Epoch 317/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.0308 - val_loss: 52.2212\n",
      "Epoch 318/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.8361 - val_loss: 52.0242\n",
      "Epoch 319/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.8382 - val_loss: 51.9556\n",
      "Epoch 320/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.3780 - val_loss: 52.0133\n",
      "Epoch 321/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.5800 - val_loss: 51.8811\n",
      "Epoch 322/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 47.0688 - val_loss: 51.8730\n",
      "Epoch 323/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.7961 - val_loss: 51.7257\n",
      "Epoch 324/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.2531 - val_loss: 51.6692\n",
      "Epoch 325/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 43.5418 - val_loss: 51.5363\n",
      "Epoch 326/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45.8667 - val_loss: 51.3136\n",
      "Epoch 327/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.1774 - val_loss: 51.2607\n",
      "Epoch 328/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 43.8717 - val_loss: 51.2469\n",
      "Epoch 329/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.6899 - val_loss: 51.2505\n",
      "Epoch 330/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 43.2831 - val_loss: 51.1570\n",
      "Epoch 331/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.5124 - val_loss: 50.8133\n",
      "Epoch 332/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.2326 - val_loss: 50.9905\n",
      "Epoch 333/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.3475 - val_loss: 50.5782\n",
      "Epoch 334/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 41.2177 - val_loss: 50.5566\n",
      "Epoch 335/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.8842 - val_loss: 50.4721\n",
      "Epoch 336/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 46.5061 - val_loss: 50.3299\n",
      "Epoch 337/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.5321 - val_loss: 50.0997\n",
      "Epoch 338/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.8988 - val_loss: 50.3260\n",
      "Epoch 339/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 41.6765 - val_loss: 50.0756\n",
      "Epoch 340/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.9319 - val_loss: 49.9232\n",
      "Epoch 341/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 41.4682 - val_loss: 49.8745\n",
      "Epoch 342/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.7461 - val_loss: 49.8340\n",
      "Epoch 343/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 43.7557 - val_loss: 49.5827\n",
      "Epoch 344/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.7759 - val_loss: 49.5805\n",
      "Epoch 345/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 44.7884 - val_loss: 49.4182\n",
      "Epoch 346/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.9335 - val_loss: 49.4065\n",
      "Epoch 347/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 43.5206 - val_loss: 49.1238\n",
      "Epoch 348/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.5249 - val_loss: 49.3177\n",
      "Epoch 349/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 41.8378 - val_loss: 49.2856\n",
      "Epoch 350/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 42.9073 - val_loss: 49.0545\n",
      "Epoch 351/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.6165 - val_loss: 49.1157\n",
      "Epoch 352/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.0876 - val_loss: 48.7764\n",
      "Epoch 353/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.7916 - val_loss: 48.6810\n",
      "Epoch 354/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.6117 - val_loss: 48.6091\n",
      "Epoch 355/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 43.2020 - val_loss: 48.4700\n",
      "Epoch 356/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 45.3450 - val_loss: 48.3474\n",
      "Epoch 357/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 40.1467 - val_loss: 48.5054\n",
      "Epoch 358/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.1681 - val_loss: 48.4808\n",
      "Epoch 359/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 42.2528 - val_loss: 48.2872\n",
      "Epoch 360/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.9778 - val_loss: 48.2063\n",
      "Epoch 361/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.5709 - val_loss: 48.0410\n",
      "Epoch 362/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 41.3566 - val_loss: 47.9141\n",
      "Epoch 363/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.1822 - val_loss: 47.7210\n",
      "Epoch 364/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.4959 - val_loss: 47.7493\n",
      "Epoch 365/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.7925 - val_loss: 47.5491\n",
      "Epoch 366/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 42.5866 - val_loss: 47.5559\n",
      "Epoch 367/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.1987 - val_loss: 47.3314\n",
      "Epoch 368/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.7009 - val_loss: 47.3165\n",
      "Epoch 369/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.1200 - val_loss: 47.2737\n",
      "Epoch 370/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.6013 - val_loss: 47.3898\n",
      "Epoch 371/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.6552 - val_loss: 47.0690\n",
      "Epoch 372/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.6108 - val_loss: 47.0014\n",
      "Epoch 373/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.3770 - val_loss: 46.8849\n",
      "Epoch 374/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 41.1433 - val_loss: 46.7626\n",
      "Epoch 375/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.6310 - val_loss: 46.5749\n",
      "Epoch 376/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.3076 - val_loss: 46.4314\n",
      "Epoch 377/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 38.1084 - val_loss: 46.5095\n",
      "Epoch 378/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.1534 - val_loss: 46.2418\n",
      "Epoch 379/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 41.3200 - val_loss: 46.3588\n",
      "Epoch 380/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.8115 - val_loss: 46.3124\n",
      "Epoch 381/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.1506 - val_loss: 46.0115\n",
      "Epoch 382/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.4228 - val_loss: 45.7522\n",
      "Epoch 383/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.2810 - val_loss: 45.8786\n",
      "Epoch 384/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.2523 - val_loss: 46.0350\n",
      "Epoch 385/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.9936 - val_loss: 45.9066\n",
      "Epoch 386/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 40.0838 - val_loss: 45.7236\n",
      "Epoch 387/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.7827 - val_loss: 45.5742\n",
      "Epoch 388/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.0201 - val_loss: 45.6152\n",
      "Epoch 389/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.1534 - val_loss: 45.6608\n",
      "Epoch 390/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.8217 - val_loss: 45.6273\n",
      "Epoch 391/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.8917 - val_loss: 45.1791\n",
      "Epoch 392/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.7170 - val_loss: 44.7406\n",
      "Epoch 393/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.1307 - val_loss: 44.8246\n",
      "Epoch 394/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.1602 - val_loss: 44.6399\n",
      "Epoch 395/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 37.4738 - val_loss: 45.0247\n",
      "Epoch 396/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.3812 - val_loss: 45.0405\n",
      "Epoch 397/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.6831 - val_loss: 44.9798\n",
      "Epoch 398/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.5947 - val_loss: 44.9429\n",
      "Epoch 399/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.2842 - val_loss: 44.8942\n",
      "Epoch 400/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.9155 - val_loss: 44.7917\n",
      "Epoch 401/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 38.9126 - val_loss: 44.8995\n",
      "Epoch 402/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 38.7176 - val_loss: 44.7423\n",
      "Epoch 403/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.4810 - val_loss: 44.7319\n",
      "Epoch 404/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.2892 - val_loss: 44.6323\n",
      "Epoch 405/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.8605 - val_loss: 44.5201\n",
      "Epoch 406/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.0166 - val_loss: 44.4340\n",
      "Epoch 407/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.6703 - val_loss: 44.5163\n",
      "Epoch 408/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.6204 - val_loss: 44.0602\n",
      "Epoch 409/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 36.0342 - val_loss: 44.4562\n",
      "Epoch 410/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.1975 - val_loss: 44.4448\n",
      "Epoch 411/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.7109 - val_loss: 44.0638\n",
      "Epoch 412/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.8658 - val_loss: 44.1169\n",
      "Epoch 413/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 38.2323 - val_loss: 44.0581\n",
      "Epoch 414/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.6754 - val_loss: 44.0764\n",
      "Epoch 415/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.6593 - val_loss: 43.9605\n",
      "Epoch 416/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 36.2765 - val_loss: 43.8768\n",
      "Epoch 417/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.7401 - val_loss: 43.8272\n",
      "Epoch 418/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.6092 - val_loss: 43.5246\n",
      "Epoch 419/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.2573 - val_loss: 43.4557\n",
      "Epoch 420/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.7638 - val_loss: 43.5569\n",
      "Epoch 421/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 39.7361 - val_loss: 43.5767\n",
      "Epoch 422/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.2502 - val_loss: 43.1940\n",
      "Epoch 423/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.2438 - val_loss: 43.3442\n",
      "Epoch 424/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.7602 - val_loss: 43.1794\n",
      "Epoch 425/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.3789 - val_loss: 43.2267\n",
      "Epoch 426/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.8290 - val_loss: 43.2039\n",
      "Epoch 427/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.6062 - val_loss: 43.1397\n",
      "Epoch 428/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.1618 - val_loss: 42.9129\n",
      "Epoch 429/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.6814 - val_loss: 42.9565\n",
      "Epoch 430/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.7095 - val_loss: 42.8341\n",
      "Epoch 431/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.3102 - val_loss: 42.9589\n",
      "Epoch 432/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 35.7398 - val_loss: 42.8510\n",
      "Epoch 433/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.2656 - val_loss: 42.7348\n",
      "Epoch 434/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.3660 - val_loss: 42.6834\n",
      "Epoch 435/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.0681 - val_loss: 42.6972\n",
      "Epoch 436/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.7545 - val_loss: 42.5069\n",
      "Epoch 437/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.1385 - val_loss: 42.5827\n",
      "Epoch 438/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 36.9363 - val_loss: 42.4124\n",
      "Epoch 439/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.1273 - val_loss: 42.3978\n",
      "Epoch 440/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.4503 - val_loss: 42.4984\n",
      "Epoch 441/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.3196 - val_loss: 42.5329\n",
      "Epoch 442/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.7694 - val_loss: 42.4340\n",
      "Epoch 443/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.1205 - val_loss: 42.4669\n",
      "Epoch 444/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.6673 - val_loss: 42.4320\n",
      "Epoch 445/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.1242 - val_loss: 42.4904\n",
      "Epoch 446/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 38.4136 - val_loss: 42.1381\n",
      "Epoch 447/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.6863 - val_loss: 42.2981\n",
      "Epoch 448/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.4173 - val_loss: 42.3924\n",
      "Epoch 449/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.1559 - val_loss: 42.2812\n",
      "Epoch 450/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.7654 - val_loss: 42.1326\n",
      "Epoch 451/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.9408 - val_loss: 42.0988\n",
      "Epoch 452/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.4081 - val_loss: 42.0924\n",
      "Epoch 453/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.4211 - val_loss: 41.9494\n",
      "Epoch 454/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.4320 - val_loss: 41.9354\n",
      "Epoch 455/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 36.8967 - val_loss: 41.6284\n",
      "Epoch 456/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.4607 - val_loss: 41.4995\n",
      "Epoch 457/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 36.3034 - val_loss: 41.6731\n",
      "Epoch 458/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.5528 - val_loss: 41.6934\n",
      "Epoch 459/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.6842 - val_loss: 41.4405\n",
      "Epoch 460/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.6844 - val_loss: 41.3793\n",
      "Epoch 461/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.7988 - val_loss: 41.2391\n",
      "Epoch 462/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 35.5718 - val_loss: 41.0682\n",
      "Epoch 463/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.0191 - val_loss: 41.0540\n",
      "Epoch 464/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.2093 - val_loss: 41.1740\n",
      "Epoch 465/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 36.2954 - val_loss: 40.8535\n",
      "Epoch 466/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 37.6037 - val_loss: 40.9949\n",
      "Epoch 467/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.3500 - val_loss: 41.0947\n",
      "Epoch 468/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.3358 - val_loss: 41.0310\n",
      "Epoch 469/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.3457 - val_loss: 41.1637\n",
      "Epoch 470/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 35.9613 - val_loss: 40.9731\n",
      "Epoch 471/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 36.0304 - val_loss: 40.9958\n",
      "Epoch 472/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1582 - val_loss: 40.7932\n",
      "Epoch 473/50000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 32.7580 - val_loss: 40.6824\n",
      "Epoch 474/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.3804 - val_loss: 40.4024\n",
      "Epoch 475/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.0128 - val_loss: 40.5680\n",
      "Epoch 476/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 35.4064 - val_loss: 40.6677\n",
      "Epoch 477/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.5897 - val_loss: 40.7723\n",
      "Epoch 478/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1628 - val_loss: 40.7594\n",
      "Epoch 479/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.7492 - val_loss: 40.4472\n",
      "Epoch 480/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.0492 - val_loss: 40.5175\n",
      "Epoch 481/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.6343 - val_loss: 40.7137\n",
      "Epoch 482/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2769 - val_loss: 40.5382\n",
      "Epoch 483/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.5851 - val_loss: 40.6022\n",
      "Epoch 484/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.4671 - val_loss: 40.5690\n",
      "Epoch 485/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.2424 - val_loss: 40.7040\n",
      "Epoch 486/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.4120 - val_loss: 40.5639\n",
      "Epoch 487/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.7321 - val_loss: 40.3405\n",
      "Epoch 488/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1148 - val_loss: 40.0138\n",
      "Epoch 489/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.5625 - val_loss: 40.3472\n",
      "Epoch 490/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.7703 - val_loss: 40.1801\n",
      "Epoch 491/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.8892 - val_loss: 40.4223\n",
      "Epoch 492/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0777 - val_loss: 40.0522\n",
      "Epoch 493/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.5277 - val_loss: 39.7249\n",
      "Epoch 494/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.6021 - val_loss: 39.5828\n",
      "Epoch 495/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.5960 - val_loss: 39.9581\n",
      "Epoch 496/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.3499 - val_loss: 40.0789\n",
      "Epoch 497/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.2871 - val_loss: 40.1474\n",
      "Epoch 498/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.8284 - val_loss: 39.7754\n",
      "Epoch 499/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.6150 - val_loss: 39.5854\n",
      "Epoch 500/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.8466 - val_loss: 39.6929\n",
      "Epoch 501/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.8761 - val_loss: 39.5513\n",
      "Epoch 502/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.6552 - val_loss: 39.5292\n",
      "Epoch 503/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.5841 - val_loss: 39.5879\n",
      "Epoch 504/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.1511 - val_loss: 39.5298\n",
      "Epoch 505/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 34.5932 - val_loss: 39.9273\n",
      "Epoch 506/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.1594 - val_loss: 39.6465\n",
      "Epoch 507/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.1100 - val_loss: 39.5456\n",
      "Epoch 508/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.8416 - val_loss: 39.4576\n",
      "Epoch 509/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 34.7461 - val_loss: 39.5612\n",
      "Epoch 510/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.6211 - val_loss: 39.4729\n",
      "Epoch 511/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.6322 - val_loss: 39.1749\n",
      "Epoch 512/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.1710 - val_loss: 39.5255\n",
      "Epoch 513/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1338 - val_loss: 39.1990\n",
      "Epoch 514/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.1686 - val_loss: 39.3416\n",
      "Epoch 515/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.6445 - val_loss: 39.4432\n",
      "Epoch 516/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.1167 - val_loss: 39.2894\n",
      "Epoch 517/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.5357 - val_loss: 39.1738\n",
      "Epoch 518/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.2099 - val_loss: 38.7623\n",
      "Epoch 519/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.9474 - val_loss: 39.0431\n",
      "Epoch 520/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0837 - val_loss: 38.8964\n",
      "Epoch 521/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.7169 - val_loss: 38.9207\n",
      "Epoch 522/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.7551 - val_loss: 38.9196\n",
      "Epoch 523/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.8445 - val_loss: 38.9176\n",
      "Epoch 524/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.1358 - val_loss: 38.8563\n",
      "Epoch 525/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.7382 - val_loss: 38.7920\n",
      "Epoch 526/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.1650 - val_loss: 38.7876\n",
      "Epoch 527/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.3645 - val_loss: 38.8366\n",
      "Epoch 528/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.7375 - val_loss: 39.0375\n",
      "Epoch 529/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.0708 - val_loss: 38.9877\n",
      "Epoch 530/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.0534 - val_loss: 38.6335\n",
      "Epoch 531/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.6604 - val_loss: 38.6757\n",
      "Epoch 532/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.9119 - val_loss: 38.5723\n",
      "Epoch 533/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.6541 - val_loss: 38.3705\n",
      "Epoch 534/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.4205 - val_loss: 38.3633\n",
      "Epoch 535/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.9488 - val_loss: 38.3649\n",
      "Epoch 536/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.4533 - val_loss: 38.5658\n",
      "Epoch 537/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.8619 - val_loss: 38.2710\n",
      "Epoch 538/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.6493 - val_loss: 38.4520\n",
      "Epoch 539/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.0044 - val_loss: 38.3560\n",
      "Epoch 540/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.6582 - val_loss: 38.0647\n",
      "Epoch 541/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.6433 - val_loss: 38.2569\n",
      "Epoch 542/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.2229 - val_loss: 38.3554\n",
      "Epoch 543/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.0110 - val_loss: 38.2648\n",
      "Epoch 544/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.0621 - val_loss: 38.0973\n",
      "Epoch 545/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.4404 - val_loss: 38.3693\n",
      "Epoch 546/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.4095 - val_loss: 38.3983\n",
      "Epoch 547/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.9608 - val_loss: 38.0440\n",
      "Epoch 548/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.5986 - val_loss: 38.0333\n",
      "Epoch 549/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.2055 - val_loss: 38.3016\n",
      "Epoch 550/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.9938 - val_loss: 38.0481\n",
      "Epoch 551/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.6720 - val_loss: 37.9937\n",
      "Epoch 552/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.9797 - val_loss: 37.9216\n",
      "Epoch 553/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.8049 - val_loss: 37.8736\n",
      "Epoch 554/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.9577 - val_loss: 38.1968\n",
      "Epoch 555/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.6040 - val_loss: 37.9383\n",
      "Epoch 556/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.3743 - val_loss: 37.8866\n",
      "Epoch 557/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9842 - val_loss: 38.1590\n",
      "Epoch 558/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.0926 - val_loss: 37.9365\n",
      "Epoch 559/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.0588 - val_loss: 37.6916\n",
      "Epoch 560/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.9688 - val_loss: 37.4700\n",
      "Epoch 561/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.6936 - val_loss: 37.7732\n",
      "Epoch 562/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.9380 - val_loss: 37.8964\n",
      "Epoch 563/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.2317 - val_loss: 37.7758\n",
      "Epoch 564/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.7326 - val_loss: 38.0868\n",
      "Epoch 565/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.7961 - val_loss: 37.7083\n",
      "Epoch 566/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.0747 - val_loss: 37.8039\n",
      "Epoch 567/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.1480 - val_loss: 37.3182\n",
      "Epoch 568/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.8599 - val_loss: 37.5476\n",
      "Epoch 569/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.3055 - val_loss: 37.5793\n",
      "Epoch 570/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.4754 - val_loss: 37.5306\n",
      "Epoch 571/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.4596 - val_loss: 37.5707\n",
      "Epoch 572/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.3094 - val_loss: 37.4020\n",
      "Epoch 573/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.4566 - val_loss: 37.3340\n",
      "Epoch 574/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.5097 - val_loss: 37.3358\n",
      "Epoch 575/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.8081 - val_loss: 37.3852\n",
      "Epoch 576/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.1573 - val_loss: 37.3213\n",
      "Epoch 577/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.3190 - val_loss: 37.4360\n",
      "Epoch 578/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.9853 - val_loss: 37.4289\n",
      "Epoch 579/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 34.5950 - val_loss: 37.6217\n",
      "Epoch 580/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.4461 - val_loss: 37.3176\n",
      "Epoch 581/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.7874 - val_loss: 37.3826\n",
      "Epoch 582/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.8563 - val_loss: 37.3337\n",
      "Epoch 583/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.3997 - val_loss: 37.3345\n",
      "Epoch 584/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1077 - val_loss: 37.3783\n",
      "Epoch 585/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.1172 - val_loss: 37.0563\n",
      "Epoch 586/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.6245 - val_loss: 37.1864\n",
      "Epoch 587/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.3779 - val_loss: 37.0651\n",
      "Epoch 588/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.7158 - val_loss: 36.8956\n",
      "Epoch 589/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.3943 - val_loss: 36.9014\n",
      "Epoch 590/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.9825 - val_loss: 36.9561\n",
      "Epoch 591/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.3313 - val_loss: 36.9558\n",
      "Epoch 592/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.8548 - val_loss: 37.0489\n",
      "Epoch 593/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.9436 - val_loss: 36.9075\n",
      "Epoch 594/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.5054 - val_loss: 36.8017\n",
      "Epoch 595/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.4834 - val_loss: 36.8026\n",
      "Epoch 596/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.6085 - val_loss: 37.0191\n",
      "Epoch 597/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4515 - val_loss: 36.9427\n",
      "Epoch 598/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.4199 - val_loss: 36.7762\n",
      "Epoch 599/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.4403 - val_loss: 36.7443\n",
      "Epoch 600/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.0525 - val_loss: 36.8182\n",
      "Epoch 601/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.4723 - val_loss: 36.6821\n",
      "Epoch 602/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7889 - val_loss: 36.9281\n",
      "Epoch 603/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.6338 - val_loss: 36.6299\n",
      "Epoch 604/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4820 - val_loss: 36.6232\n",
      "Epoch 605/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.3450 - val_loss: 36.6384\n",
      "Epoch 606/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.8493 - val_loss: 36.4456\n",
      "Epoch 607/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.2301 - val_loss: 36.3220\n",
      "Epoch 608/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.9821 - val_loss: 36.5640\n",
      "Epoch 609/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.9976 - val_loss: 36.5222\n",
      "Epoch 610/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.1828 - val_loss: 36.8032\n",
      "Epoch 611/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.8853 - val_loss: 36.7584\n",
      "Epoch 612/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7824 - val_loss: 36.4137\n",
      "Epoch 613/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.7849 - val_loss: 36.7360\n",
      "Epoch 614/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.7785 - val_loss: 36.4113\n",
      "Epoch 615/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.4121 - val_loss: 36.4773\n",
      "Epoch 616/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.9366 - val_loss: 36.2189\n",
      "Epoch 617/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.5941 - val_loss: 36.3720\n",
      "Epoch 618/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.4949 - val_loss: 36.5726\n",
      "Epoch 619/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.3183 - val_loss: 36.3821\n",
      "Epoch 620/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.4849 - val_loss: 36.3489\n",
      "Epoch 621/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.7344 - val_loss: 36.3984\n",
      "Epoch 622/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.8145 - val_loss: 36.5717\n",
      "Epoch 623/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.7812 - val_loss: 36.3987\n",
      "Epoch 624/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7712 - val_loss: 36.2912\n",
      "Epoch 625/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.7750 - val_loss: 36.2405\n",
      "Epoch 626/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.0560 - val_loss: 36.3355\n",
      "Epoch 627/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.2965 - val_loss: 36.2096\n",
      "Epoch 628/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.5451 - val_loss: 35.9255\n",
      "Epoch 629/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.3337 - val_loss: 36.1633\n",
      "Epoch 630/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.6237 - val_loss: 36.1695\n",
      "Epoch 631/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.4027 - val_loss: 36.1619\n",
      "Epoch 632/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.9856 - val_loss: 36.2774\n",
      "Epoch 633/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.6242 - val_loss: 36.2403\n",
      "Epoch 634/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.6972 - val_loss: 36.0978\n",
      "Epoch 635/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7162 - val_loss: 36.0519\n",
      "Epoch 636/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.8371 - val_loss: 36.1192\n",
      "Epoch 637/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.8538 - val_loss: 35.9934\n",
      "Epoch 638/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.6009 - val_loss: 36.1981\n",
      "Epoch 639/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.2886 - val_loss: 36.1517\n",
      "Epoch 640/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.3446 - val_loss: 35.9789\n",
      "Epoch 641/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.8645 - val_loss: 35.8694\n",
      "Epoch 642/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.3080 - val_loss: 36.1465\n",
      "Epoch 643/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.1623 - val_loss: 35.9722\n",
      "Epoch 644/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.4558 - val_loss: 36.0616\n",
      "Epoch 645/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.0247 - val_loss: 35.9938\n",
      "Epoch 646/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.5923 - val_loss: 35.9412\n",
      "Epoch 647/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4978 - val_loss: 35.9694\n",
      "Epoch 648/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.1860 - val_loss: 35.9861\n",
      "Epoch 649/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.5845 - val_loss: 36.0180\n",
      "Epoch 650/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7268 - val_loss: 36.0341\n",
      "Epoch 651/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.5743 - val_loss: 35.9103\n",
      "Epoch 652/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.1265 - val_loss: 35.9025\n",
      "Epoch 653/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 31.4011 - val_loss: 35.7141\n",
      "Epoch 654/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.2157 - val_loss: 35.5187\n",
      "Epoch 655/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.3904 - val_loss: 35.6844\n",
      "Epoch 656/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.0166 - val_loss: 35.8604\n",
      "Epoch 657/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4697 - val_loss: 36.0518\n",
      "Epoch 658/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.4640 - val_loss: 35.9449\n",
      "Epoch 659/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.5475 - val_loss: 36.1154\n",
      "Epoch 660/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.6022 - val_loss: 35.8696\n",
      "Epoch 661/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.0833 - val_loss: 35.7552\n",
      "Epoch 662/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.1297 - val_loss: 35.7908\n",
      "Epoch 663/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.0809 - val_loss: 35.9639\n",
      "Epoch 664/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.8513 - val_loss: 35.6827\n",
      "Epoch 665/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.5142 - val_loss: 35.7524\n",
      "Epoch 666/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.4399 - val_loss: 35.5923\n",
      "Epoch 667/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.0806 - val_loss: 35.5031\n",
      "Epoch 668/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.4523 - val_loss: 35.7891\n",
      "Epoch 669/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.2706 - val_loss: 36.0839\n",
      "Epoch 670/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.5026 - val_loss: 35.5888\n",
      "Epoch 671/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.9745 - val_loss: 35.5989\n",
      "Epoch 672/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.5385 - val_loss: 35.5111\n",
      "Epoch 673/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.0528 - val_loss: 35.4840\n",
      "Epoch 674/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.3455 - val_loss: 35.4958\n",
      "Epoch 675/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.7229 - val_loss: 35.6381\n",
      "Epoch 676/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7452 - val_loss: 35.6271\n",
      "Epoch 677/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.9598 - val_loss: 35.5931\n",
      "Epoch 678/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.9328 - val_loss: 35.5874\n",
      "Epoch 679/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.3632 - val_loss: 35.4895\n",
      "Epoch 680/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.2894 - val_loss: 35.6558\n",
      "Epoch 681/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4101 - val_loss: 35.6978\n",
      "Epoch 682/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.9517 - val_loss: 35.7947\n",
      "Epoch 683/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.8567 - val_loss: 35.5625\n",
      "Epoch 684/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.4239 - val_loss: 35.5288\n",
      "Epoch 685/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.6293 - val_loss: 35.3744\n",
      "Epoch 686/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.8302 - val_loss: 35.5936\n",
      "Epoch 687/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.7348 - val_loss: 35.4362\n",
      "Epoch 688/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.2845 - val_loss: 35.5589\n",
      "Epoch 689/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.5493 - val_loss: 35.4111\n",
      "Epoch 690/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 30.3655 - val_loss: 35.3104\n",
      "Epoch 691/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.9542 - val_loss: 35.3781\n",
      "Epoch 692/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.2759 - val_loss: 35.2778\n",
      "Epoch 693/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.1549 - val_loss: 35.3265\n",
      "Epoch 694/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.4416 - val_loss: 35.2690\n",
      "Epoch 695/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.6835 - val_loss: 35.3000\n",
      "Epoch 696/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.8686 - val_loss: 35.2235\n",
      "Epoch 697/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.8299 - val_loss: 35.4991\n",
      "Epoch 698/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.5943 - val_loss: 35.1338\n",
      "Epoch 699/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.5380 - val_loss: 35.2129\n",
      "Epoch 700/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.4177 - val_loss: 35.3943\n",
      "Epoch 701/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.1690 - val_loss: 35.2822\n",
      "Epoch 702/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30.3967 - val_loss: 35.1701\n",
      "Epoch 703/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.9638 - val_loss: 35.0850\n",
      "Epoch 704/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.8435 - val_loss: 35.0063\n",
      "Epoch 705/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.4006 - val_loss: 35.1836\n",
      "Epoch 706/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.9958 - val_loss: 35.1761\n",
      "Epoch 707/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.4319 - val_loss: 35.0854\n",
      "Epoch 708/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.4269 - val_loss: 35.1113\n",
      "Epoch 709/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.3707 - val_loss: 35.1188\n",
      "Epoch 710/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.7216 - val_loss: 34.9294\n",
      "Epoch 711/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.3155 - val_loss: 35.0674\n",
      "Epoch 712/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.3702 - val_loss: 35.2071\n",
      "Epoch 713/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.2349 - val_loss: 34.9935\n",
      "Epoch 714/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.8726 - val_loss: 35.0981\n",
      "Epoch 715/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.5675 - val_loss: 35.6519\n",
      "Epoch 716/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.2641 - val_loss: 35.3008\n",
      "Epoch 717/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.3037 - val_loss: 35.0870\n",
      "Epoch 718/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.4613 - val_loss: 34.9161\n",
      "Epoch 719/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.2915 - val_loss: 34.7604\n",
      "Epoch 720/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.9314 - val_loss: 34.8966\n",
      "Epoch 721/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.2622 - val_loss: 34.9568\n",
      "Epoch 722/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.8388 - val_loss: 35.0211\n",
      "Epoch 723/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.0879 - val_loss: 35.0344\n",
      "Epoch 724/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.9694 - val_loss: 34.6089\n",
      "Epoch 725/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.8226 - val_loss: 34.5170\n",
      "Epoch 726/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.7763 - val_loss: 34.6098\n",
      "Epoch 727/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.6013 - val_loss: 34.9100\n",
      "Epoch 728/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.5624 - val_loss: 34.5146\n",
      "Epoch 729/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.8741 - val_loss: 34.9091\n",
      "Epoch 730/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.0798 - val_loss: 34.9053\n",
      "Epoch 731/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29.6560 - val_loss: 34.9032\n",
      "Epoch 732/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.6252 - val_loss: 34.8474\n",
      "Epoch 733/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.4803 - val_loss: 34.6691\n",
      "Epoch 734/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.0247 - val_loss: 34.1841\n",
      "Epoch 735/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.9872 - val_loss: 34.2739\n",
      "Epoch 736/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.4448 - val_loss: 34.5105\n",
      "Epoch 737/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 28.7982 - val_loss: 34.8309\n",
      "Epoch 738/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.4369 - val_loss: 34.7213\n",
      "Epoch 739/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.0651 - val_loss: 34.4455\n",
      "Epoch 740/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.6466 - val_loss: 34.7094\n",
      "Epoch 741/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.2440 - val_loss: 34.7223\n",
      "Epoch 742/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.2006 - val_loss: 34.5228\n",
      "Epoch 743/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.6912 - val_loss: 34.5156\n",
      "Epoch 744/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.5014 - val_loss: 34.3154\n",
      "Epoch 745/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.4702 - val_loss: 34.8640\n",
      "Epoch 746/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.2816 - val_loss: 34.2545\n",
      "Epoch 747/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.2356 - val_loss: 34.5197\n",
      "Epoch 748/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.2742 - val_loss: 34.4600\n",
      "Epoch 749/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.8558 - val_loss: 34.4973\n",
      "Epoch 750/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.8562 - val_loss: 34.3837\n",
      "Epoch 751/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.9019 - val_loss: 34.3497\n",
      "Epoch 752/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.5011 - val_loss: 34.4562\n",
      "Epoch 753/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.5960 - val_loss: 34.3887\n",
      "Epoch 754/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.8746 - val_loss: 34.3913\n",
      "Epoch 755/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.8621 - val_loss: 34.0387\n",
      "Epoch 756/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.4752 - val_loss: 34.1814\n",
      "Epoch 757/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.5277 - val_loss: 34.1374\n",
      "Epoch 758/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.3428 - val_loss: 34.1010\n",
      "Epoch 759/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.1272 - val_loss: 34.2951\n",
      "Epoch 760/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.1587 - val_loss: 34.2234\n",
      "Epoch 761/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.4253 - val_loss: 34.1993\n",
      "Epoch 762/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.6380 - val_loss: 34.0805\n",
      "Epoch 763/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.1619 - val_loss: 34.2304\n",
      "Epoch 764/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.0318 - val_loss: 34.6043\n",
      "Epoch 765/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.0041 - val_loss: 34.1662\n",
      "Epoch 766/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.2107 - val_loss: 34.0601\n",
      "Epoch 767/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.5185 - val_loss: 34.1104\n",
      "Epoch 768/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.9429 - val_loss: 34.5255\n",
      "Epoch 769/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.2863 - val_loss: 34.1885\n",
      "Epoch 770/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.3219 - val_loss: 34.4318\n",
      "Epoch 771/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.1739 - val_loss: 34.1394\n",
      "Epoch 772/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.6472 - val_loss: 34.3479\n",
      "Epoch 773/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.8961 - val_loss: 33.8247\n",
      "Epoch 774/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.1003 - val_loss: 33.7504\n",
      "Epoch 775/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.0328 - val_loss: 33.9069\n",
      "Epoch 776/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.0670 - val_loss: 34.0820\n",
      "Epoch 777/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.0313 - val_loss: 34.2902\n",
      "Epoch 778/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.1290 - val_loss: 34.0503\n",
      "Epoch 779/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.5780 - val_loss: 33.9360\n",
      "Epoch 780/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.6939 - val_loss: 33.8340\n",
      "Epoch 781/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.8105 - val_loss: 33.9810\n",
      "Epoch 782/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.1187 - val_loss: 34.0224\n",
      "Epoch 783/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.4298 - val_loss: 33.9769\n",
      "Epoch 784/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.2364 - val_loss: 34.0618\n",
      "Epoch 785/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.5204 - val_loss: 33.9742\n",
      "Epoch 786/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.2728 - val_loss: 33.9375\n",
      "Epoch 787/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.6834 - val_loss: 33.5935\n",
      "Epoch 788/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.8462 - val_loss: 33.9970\n",
      "Epoch 789/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.2979 - val_loss: 33.7076\n",
      "Epoch 790/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.5188 - val_loss: 33.9677\n",
      "Epoch 791/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.6342 - val_loss: 34.0808\n",
      "Epoch 792/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.3714 - val_loss: 33.9495\n",
      "Epoch 793/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.2267 - val_loss: 33.8623\n",
      "Epoch 794/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.4235 - val_loss: 33.8462\n",
      "Epoch 795/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.7270 - val_loss: 33.7151\n",
      "Epoch 796/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.2531 - val_loss: 33.6231\n",
      "Epoch 797/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.5461 - val_loss: 33.6056\n",
      "Epoch 798/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.9435 - val_loss: 33.7912\n",
      "Epoch 799/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 27.6623 - val_loss: 33.8431\n",
      "Epoch 800/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.1404 - val_loss: 33.7654\n",
      "Epoch 801/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.3705 - val_loss: 33.9335\n",
      "Epoch 802/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.0452 - val_loss: 33.9431\n",
      "Epoch 803/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.5742 - val_loss: 33.5444\n",
      "Epoch 804/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1145 - val_loss: 33.4565\n",
      "Epoch 805/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.4714 - val_loss: 33.9467\n",
      "Epoch 806/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.1748 - val_loss: 34.1259\n",
      "Epoch 807/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.1151 - val_loss: 34.1039\n",
      "Epoch 808/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26.3148 - val_loss: 34.0354\n",
      "Epoch 809/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.6771 - val_loss: 33.5148\n",
      "Epoch 810/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.0933 - val_loss: 33.7043\n",
      "Epoch 811/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.3547 - val_loss: 33.6939\n",
      "Epoch 812/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.1972 - val_loss: 33.5597\n",
      "Epoch 813/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.9510 - val_loss: 33.5201\n",
      "Epoch 814/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.5948 - val_loss: 33.7337\n",
      "Epoch 815/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.4230 - val_loss: 33.5775\n",
      "Epoch 816/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.4084 - val_loss: 33.5996\n",
      "Epoch 817/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.3999 - val_loss: 33.5333\n",
      "Epoch 818/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.6996 - val_loss: 33.4508\n",
      "Epoch 819/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.3864 - val_loss: 33.3908\n",
      "Epoch 820/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.6725 - val_loss: 33.4911\n",
      "Epoch 821/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.4985 - val_loss: 33.4327\n",
      "Epoch 822/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.4101 - val_loss: 33.7777\n",
      "Epoch 823/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.1283 - val_loss: 33.5415\n",
      "Epoch 824/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.4616 - val_loss: 33.3396\n",
      "Epoch 825/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.3368 - val_loss: 33.5934\n",
      "Epoch 826/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.2028 - val_loss: 33.7089\n",
      "Epoch 827/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.7026 - val_loss: 33.5874\n",
      "Epoch 828/50000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 25.2686 - val_loss: 33.4094\n",
      "Epoch 829/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1164 - val_loss: 33.6268\n",
      "Epoch 830/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.4775 - val_loss: 33.7002\n",
      "Epoch 831/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9249 - val_loss: 33.7317\n",
      "Epoch 832/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.3376 - val_loss: 33.4046\n",
      "Epoch 833/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.1671 - val_loss: 33.5208\n",
      "Epoch 834/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.2753 - val_loss: 33.3229\n",
      "Epoch 835/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.5041 - val_loss: 33.2067\n",
      "Epoch 836/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.4118 - val_loss: 33.1817\n",
      "Epoch 837/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.8861 - val_loss: 33.4678\n",
      "Epoch 838/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.8056 - val_loss: 33.5525\n",
      "Epoch 839/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1357 - val_loss: 33.3805\n",
      "Epoch 840/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.5239 - val_loss: 33.3127\n",
      "Epoch 841/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.2046 - val_loss: 33.4084\n",
      "Epoch 842/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.3030 - val_loss: 33.4159\n",
      "Epoch 843/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1911 - val_loss: 33.1245\n",
      "Epoch 844/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.7615 - val_loss: 33.0962\n",
      "Epoch 845/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.0944 - val_loss: 33.1503\n",
      "Epoch 846/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.0955 - val_loss: 33.3125\n",
      "Epoch 847/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9273 - val_loss: 33.0872\n",
      "Epoch 848/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.1649 - val_loss: 33.2681\n",
      "Epoch 849/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4619 - val_loss: 33.2210\n",
      "Epoch 850/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.3627 - val_loss: 33.0272\n",
      "Epoch 851/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9017 - val_loss: 33.1158\n",
      "Epoch 852/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 25.6179 - val_loss: 32.9806\n",
      "Epoch 853/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.7546 - val_loss: 33.0733\n",
      "Epoch 854/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.8436 - val_loss: 33.0377\n",
      "Epoch 855/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1927 - val_loss: 33.2306\n",
      "Epoch 856/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1243 - val_loss: 33.4667\n",
      "Epoch 857/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1033 - val_loss: 33.0476\n",
      "Epoch 858/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 24.8615 - val_loss: 33.0051\n",
      "Epoch 859/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1154 - val_loss: 33.2647\n",
      "Epoch 860/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6842 - val_loss: 32.7745\n",
      "Epoch 861/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9186 - val_loss: 32.7695\n",
      "Epoch 862/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.0314 - val_loss: 33.2320\n",
      "Epoch 863/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.0341 - val_loss: 32.9329\n",
      "Epoch 864/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9438 - val_loss: 33.0800\n",
      "Epoch 865/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.2746 - val_loss: 32.9226\n",
      "Epoch 866/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.6356 - val_loss: 33.0842\n",
      "Epoch 867/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.8845 - val_loss: 33.1590\n",
      "Epoch 868/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.9746 - val_loss: 33.3656\n",
      "Epoch 869/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.7835 - val_loss: 32.9233\n",
      "Epoch 870/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9084 - val_loss: 32.9541\n",
      "Epoch 871/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1129 - val_loss: 32.8549\n",
      "Epoch 872/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6770 - val_loss: 32.9149\n",
      "Epoch 873/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.9629 - val_loss: 32.7959\n",
      "Epoch 874/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.4274 - val_loss: 33.0124\n",
      "Epoch 875/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.8740 - val_loss: 32.7922\n",
      "Epoch 876/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.0790 - val_loss: 32.6892\n",
      "Epoch 877/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9632 - val_loss: 32.9439\n",
      "Epoch 878/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.9137 - val_loss: 32.9200\n",
      "Epoch 879/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9669 - val_loss: 32.9227\n",
      "Epoch 880/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.7988 - val_loss: 32.7731\n",
      "Epoch 881/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3286 - val_loss: 32.9197\n",
      "Epoch 882/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.2277 - val_loss: 32.5198\n",
      "Epoch 883/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9430 - val_loss: 32.8336\n",
      "Epoch 884/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3989 - val_loss: 32.8257\n",
      "Epoch 885/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9510 - val_loss: 32.8546\n",
      "Epoch 886/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4666 - val_loss: 32.5289\n",
      "Epoch 887/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.6858 - val_loss: 32.6975\n",
      "Epoch 888/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4251 - val_loss: 32.9852\n",
      "Epoch 889/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.7965 - val_loss: 32.8768\n",
      "Epoch 890/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.3089 - val_loss: 32.9365\n",
      "Epoch 891/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9314 - val_loss: 32.7985\n",
      "Epoch 892/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.5195 - val_loss: 32.3759\n",
      "Epoch 893/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3890 - val_loss: 32.7597\n",
      "Epoch 894/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9496 - val_loss: 32.8160\n",
      "Epoch 895/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2201 - val_loss: 32.2311\n",
      "Epoch 896/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6678 - val_loss: 32.2297\n",
      "Epoch 897/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.5569 - val_loss: 32.3262\n",
      "Epoch 898/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6035 - val_loss: 32.6194\n",
      "Epoch 899/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2700 - val_loss: 32.6255\n",
      "Epoch 900/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1184 - val_loss: 32.5285\n",
      "Epoch 901/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2431 - val_loss: 32.6290\n",
      "Epoch 902/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9445 - val_loss: 32.6612\n",
      "Epoch 903/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3047 - val_loss: 32.4842\n",
      "Epoch 904/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4151 - val_loss: 32.3816\n",
      "Epoch 905/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.5216 - val_loss: 32.4445\n",
      "Epoch 906/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.7501 - val_loss: 32.4116\n",
      "Epoch 907/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2455 - val_loss: 32.5764\n",
      "Epoch 908/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.0669 - val_loss: 32.6576\n",
      "Epoch 909/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1941 - val_loss: 32.9452\n",
      "Epoch 910/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2512 - val_loss: 32.6952\n",
      "Epoch 911/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9827 - val_loss: 32.3885\n",
      "Epoch 912/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4672 - val_loss: 32.6053\n",
      "Epoch 913/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3090 - val_loss: 32.4234\n",
      "Epoch 914/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.5256 - val_loss: 32.6245\n",
      "Epoch 915/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3108 - val_loss: 32.3058\n",
      "Epoch 916/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2944 - val_loss: 32.4263\n",
      "Epoch 917/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.8054 - val_loss: 32.3279\n",
      "Epoch 918/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4197 - val_loss: 32.4317\n",
      "Epoch 919/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1772 - val_loss: 32.3055\n",
      "Epoch 920/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1888 - val_loss: 32.6039\n",
      "Epoch 921/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.9115 - val_loss: 32.4962\n",
      "Epoch 922/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.1146 - val_loss: 32.4221\n",
      "Epoch 923/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6751 - val_loss: 32.3717\n",
      "Epoch 924/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9172 - val_loss: 32.4779\n",
      "Epoch 925/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 25.4217 - val_loss: 32.5575\n",
      "Epoch 926/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.9096 - val_loss: 32.3004\n",
      "Epoch 927/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.9821 - val_loss: 32.1087\n",
      "Epoch 928/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4994 - val_loss: 32.0410\n",
      "Epoch 929/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.7353 - val_loss: 32.3094\n",
      "Epoch 930/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.0659 - val_loss: 32.2511\n",
      "Epoch 931/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.0741 - val_loss: 32.3748\n",
      "Epoch 932/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.5345 - val_loss: 32.2341\n",
      "Epoch 933/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.0922 - val_loss: 32.1548\n",
      "Epoch 934/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1225 - val_loss: 31.9675\n",
      "Epoch 935/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2513 - val_loss: 32.2696\n",
      "Epoch 936/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.7265 - val_loss: 32.2653\n",
      "Epoch 937/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.0874 - val_loss: 32.3040\n",
      "Epoch 938/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6117 - val_loss: 32.0791\n",
      "Epoch 939/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3299 - val_loss: 32.2633\n",
      "Epoch 940/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5853 - val_loss: 32.0898\n",
      "Epoch 941/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9798 - val_loss: 32.2756\n",
      "Epoch 942/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.8764 - val_loss: 32.4211\n",
      "Epoch 943/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.2053 - val_loss: 32.0684\n",
      "Epoch 944/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2454 - val_loss: 32.1567\n",
      "Epoch 945/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9292 - val_loss: 32.1129\n",
      "Epoch 946/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6011 - val_loss: 32.1307\n",
      "Epoch 947/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1893 - val_loss: 31.9180\n",
      "Epoch 948/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.2013 - val_loss: 32.1484\n",
      "Epoch 949/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.7700 - val_loss: 32.0183\n",
      "Epoch 950/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9602 - val_loss: 32.1291\n",
      "Epoch 951/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.9686 - val_loss: 32.2006\n",
      "Epoch 952/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.6517 - val_loss: 31.9713\n",
      "Epoch 953/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1696 - val_loss: 32.0473\n",
      "Epoch 954/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.2763 - val_loss: 32.2519\n",
      "Epoch 955/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3323 - val_loss: 31.9408\n",
      "Epoch 956/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.7437 - val_loss: 32.1611\n",
      "Epoch 957/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.2446 - val_loss: 31.9518\n",
      "Epoch 958/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.8034 - val_loss: 31.8923\n",
      "Epoch 959/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.8492 - val_loss: 32.0403\n",
      "Epoch 960/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 23.7960 - val_loss: 31.8760\n",
      "Epoch 961/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.1462 - val_loss: 32.1856\n",
      "Epoch 962/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5435 - val_loss: 32.0253\n",
      "Epoch 963/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6491 - val_loss: 31.9616\n",
      "Epoch 964/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3175 - val_loss: 31.9183\n",
      "Epoch 965/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6276 - val_loss: 31.8113\n",
      "Epoch 966/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9015 - val_loss: 31.8023\n",
      "Epoch 967/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.8223 - val_loss: 31.7410\n",
      "Epoch 968/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6219 - val_loss: 31.8733\n",
      "Epoch 969/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3613 - val_loss: 31.9507\n",
      "Epoch 970/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5069 - val_loss: 31.7811\n",
      "Epoch 971/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5002 - val_loss: 31.8116\n",
      "Epoch 972/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.7717 - val_loss: 32.0370\n",
      "Epoch 973/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.8414 - val_loss: 32.5143\n",
      "Epoch 974/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5410 - val_loss: 31.8430\n",
      "Epoch 975/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 23.7729 - val_loss: 31.6863\n",
      "Epoch 976/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2961 - val_loss: 32.1232\n",
      "Epoch 977/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.8161 - val_loss: 31.9511\n",
      "Epoch 978/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.7391 - val_loss: 31.8829\n",
      "Epoch 979/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5461 - val_loss: 31.6828\n",
      "Epoch 980/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.3769 - val_loss: 31.5900\n",
      "Epoch 981/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.6837 - val_loss: 31.8946\n",
      "Epoch 982/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.0628 - val_loss: 31.6579\n",
      "Epoch 983/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4194 - val_loss: 31.7558\n",
      "Epoch 984/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.0984 - val_loss: 31.6160\n",
      "Epoch 985/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4822 - val_loss: 31.8553\n",
      "Epoch 986/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.9786 - val_loss: 31.7438\n",
      "Epoch 987/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6645 - val_loss: 32.2407\n",
      "Epoch 988/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4213 - val_loss: 32.1279\n",
      "Epoch 989/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5427 - val_loss: 32.0537\n",
      "Epoch 990/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4559 - val_loss: 31.7202\n",
      "Epoch 991/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6070 - val_loss: 31.7809\n",
      "Epoch 992/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4836 - val_loss: 31.9403\n",
      "Epoch 993/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3907 - val_loss: 31.8729\n",
      "Epoch 994/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2923 - val_loss: 31.7808\n",
      "Epoch 995/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.7029 - val_loss: 31.6880\n",
      "Epoch 996/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5543 - val_loss: 31.7303\n",
      "Epoch 997/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5562 - val_loss: 31.7393\n",
      "Epoch 998/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.6135 - val_loss: 31.8332\n",
      "Epoch 999/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3056 - val_loss: 31.4635\n",
      "Epoch 1000/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3551 - val_loss: 31.6774\n",
      "Epoch 1001/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.7975 - val_loss: 31.6653\n",
      "Epoch 1002/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.7486 - val_loss: 31.7295\n",
      "Epoch 1003/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6979 - val_loss: 31.3973\n",
      "Epoch 1004/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.8739 - val_loss: 31.4657\n",
      "Epoch 1005/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.4080 - val_loss: 31.5393\n",
      "Epoch 1006/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2883 - val_loss: 32.1116\n",
      "Epoch 1007/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2446 - val_loss: 31.7686\n",
      "Epoch 1008/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5139 - val_loss: 31.8839\n",
      "Epoch 1009/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24.1335 - val_loss: 31.7625\n",
      "Epoch 1010/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4361 - val_loss: 31.7854\n",
      "Epoch 1011/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 24.0819 - val_loss: 31.5477\n",
      "Epoch 1012/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5444 - val_loss: 31.7286\n",
      "Epoch 1013/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8390 - val_loss: 31.9489\n",
      "Epoch 1014/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6557 - val_loss: 31.5057\n",
      "Epoch 1015/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9429 - val_loss: 31.4830\n",
      "Epoch 1016/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.6543 - val_loss: 31.1577\n",
      "Epoch 1017/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1150 - val_loss: 31.7287\n",
      "Epoch 1018/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3971 - val_loss: 31.4463\n",
      "Epoch 1019/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1711 - val_loss: 31.5218\n",
      "Epoch 1020/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2567 - val_loss: 31.3423\n",
      "Epoch 1021/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.0961 - val_loss: 31.6295\n",
      "Epoch 1022/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1762 - val_loss: 31.6289\n",
      "Epoch 1023/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9712 - val_loss: 31.4041\n",
      "Epoch 1024/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8185 - val_loss: 31.3951\n",
      "Epoch 1025/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1602 - val_loss: 31.8512\n",
      "Epoch 1026/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.7685 - val_loss: 31.5795\n",
      "Epoch 1027/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1833 - val_loss: 31.4104\n",
      "Epoch 1028/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2591 - val_loss: 31.3685\n",
      "Epoch 1029/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.1345 - val_loss: 31.5854\n",
      "Epoch 1030/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4218 - val_loss: 31.8335\n",
      "Epoch 1031/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2041 - val_loss: 31.7909\n",
      "Epoch 1032/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.5337 - val_loss: 31.5358\n",
      "Epoch 1033/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4957 - val_loss: 31.4987\n",
      "Epoch 1034/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8117 - val_loss: 31.2494\n",
      "Epoch 1035/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.2244 - val_loss: 31.1970\n",
      "Epoch 1036/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9917 - val_loss: 31.3812\n",
      "Epoch 1037/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3227 - val_loss: 31.4890\n",
      "Epoch 1038/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1679 - val_loss: 31.7785\n",
      "Epoch 1039/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6881 - val_loss: 31.1804\n",
      "Epoch 1040/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6621 - val_loss: 31.8478\n",
      "Epoch 1041/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3951 - val_loss: 31.4920\n",
      "Epoch 1042/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1437 - val_loss: 31.3057\n",
      "Epoch 1043/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 22.8868 - val_loss: 31.6014\n",
      "Epoch 1044/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7520 - val_loss: 31.2159\n",
      "Epoch 1045/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.3024 - val_loss: 31.3948\n",
      "Epoch 1046/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7227 - val_loss: 31.3202\n",
      "Epoch 1047/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8557 - val_loss: 31.4007\n",
      "Epoch 1048/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1865 - val_loss: 31.4831\n",
      "Epoch 1049/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.0214 - val_loss: 31.1054\n",
      "Epoch 1050/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3921 - val_loss: 31.6560\n",
      "Epoch 1051/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6863 - val_loss: 31.5499\n",
      "Epoch 1052/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9173 - val_loss: 31.3528\n",
      "Epoch 1053/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.8184 - val_loss: 31.3572\n",
      "Epoch 1054/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1167 - val_loss: 31.4807\n",
      "Epoch 1055/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9374 - val_loss: 31.3581\n",
      "Epoch 1056/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.9283 - val_loss: 31.2222\n",
      "Epoch 1057/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.0261 - val_loss: 31.1930\n",
      "Epoch 1058/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.0942 - val_loss: 31.6287\n",
      "Epoch 1059/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8605 - val_loss: 31.2049\n",
      "Epoch 1060/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6864 - val_loss: 31.4772\n",
      "Epoch 1061/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.4146 - val_loss: 31.1873\n",
      "Epoch 1062/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.6946 - val_loss: 31.5029\n",
      "Epoch 1063/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8420 - val_loss: 31.4966\n",
      "Epoch 1064/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9424 - val_loss: 31.3131\n",
      "Epoch 1065/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8681 - val_loss: 31.3277\n",
      "Epoch 1066/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.3791 - val_loss: 30.9000\n",
      "Epoch 1067/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5177 - val_loss: 31.6473\n",
      "Epoch 1068/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7416 - val_loss: 31.4718\n",
      "Epoch 1069/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9068 - val_loss: 31.4261\n",
      "Epoch 1070/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7339 - val_loss: 31.0964\n",
      "Epoch 1071/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 23.2356 - val_loss: 31.4740\n",
      "Epoch 1072/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9143 - val_loss: 31.2788\n",
      "Epoch 1073/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1666 - val_loss: 31.5357\n",
      "Epoch 1074/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.7170 - val_loss: 31.4412\n",
      "Epoch 1075/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5687 - val_loss: 31.5688\n",
      "Epoch 1076/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.9065 - val_loss: 31.3977\n",
      "Epoch 1077/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9858 - val_loss: 31.2579\n",
      "Epoch 1078/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9238 - val_loss: 30.8471\n",
      "Epoch 1079/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.7284 - val_loss: 31.3996\n",
      "Epoch 1080/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.4938 - val_loss: 31.0584\n",
      "Epoch 1081/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9899 - val_loss: 31.7864\n",
      "Epoch 1082/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3169 - val_loss: 31.4504\n",
      "Epoch 1083/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.5785 - val_loss: 31.3790\n",
      "Epoch 1084/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.7315 - val_loss: 31.2678\n",
      "Epoch 1085/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6911 - val_loss: 31.1871\n",
      "Epoch 1086/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8566 - val_loss: 31.2009\n",
      "Epoch 1087/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6086 - val_loss: 31.5263\n",
      "Epoch 1088/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5657 - val_loss: 31.4005\n",
      "Epoch 1089/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.5686 - val_loss: 31.0624\n",
      "Epoch 1090/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5024 - val_loss: 31.2550\n",
      "Epoch 1091/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5704 - val_loss: 31.2498\n",
      "Epoch 1092/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8548 - val_loss: 31.2168\n",
      "Epoch 1093/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2962 - val_loss: 31.2087\n",
      "Epoch 1094/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6239 - val_loss: 30.9028\n",
      "Epoch 1095/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.3465 - val_loss: 31.2433\n",
      "Epoch 1096/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6819 - val_loss: 31.0401\n",
      "Epoch 1097/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3584 - val_loss: 31.3563\n",
      "Epoch 1098/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7152 - val_loss: 31.0403\n",
      "Epoch 1099/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9507 - val_loss: 30.8951\n",
      "Epoch 1100/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0640 - val_loss: 31.6878\n",
      "Epoch 1101/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8954 - val_loss: 31.5015\n",
      "Epoch 1102/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.7710 - val_loss: 31.1267\n",
      "Epoch 1103/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.8734 - val_loss: 31.3001\n",
      "Epoch 1104/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7395 - val_loss: 31.3865\n",
      "Epoch 1105/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3894 - val_loss: 31.0566\n",
      "Epoch 1106/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3065 - val_loss: 31.1079\n",
      "Epoch 1107/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0604 - val_loss: 30.9907\n",
      "Epoch 1108/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5005 - val_loss: 31.3724\n",
      "Epoch 1109/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6978 - val_loss: 31.2797\n",
      "Epoch 1110/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4298 - val_loss: 31.1563\n",
      "Epoch 1111/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5390 - val_loss: 31.3428\n",
      "Epoch 1112/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1639 - val_loss: 30.8106\n",
      "Epoch 1113/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6523 - val_loss: 31.3487\n",
      "Epoch 1114/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4111 - val_loss: 31.3872\n",
      "Epoch 1115/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1103 - val_loss: 31.5826\n",
      "Epoch 1116/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.9660 - val_loss: 31.6083\n",
      "Epoch 1117/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.0322 - val_loss: 31.1516\n",
      "Epoch 1118/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5124 - val_loss: 31.1926\n",
      "Epoch 1119/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5561 - val_loss: 31.4690\n",
      "Epoch 1120/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3940 - val_loss: 31.3846\n",
      "Epoch 1121/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5537 - val_loss: 31.1701\n",
      "Epoch 1122/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2225 - val_loss: 31.1027\n",
      "Epoch 1123/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2653 - val_loss: 31.3231\n",
      "Epoch 1124/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4467 - val_loss: 31.2775\n",
      "Epoch 1125/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2981 - val_loss: 31.0796\n",
      "Epoch 1126/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.1935 - val_loss: 31.1346\n",
      "Epoch 1127/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.2143 - val_loss: 31.3239\n",
      "Epoch 1128/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.0066 - val_loss: 30.8136\n",
      "Epoch 1129/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3463 - val_loss: 30.7182\n",
      "Epoch 1130/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1669 - val_loss: 31.0937\n",
      "Epoch 1131/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9094 - val_loss: 30.9341\n",
      "Epoch 1132/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.7409 - val_loss: 30.9980\n",
      "Epoch 1133/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7781 - val_loss: 30.9684\n",
      "Epoch 1134/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1186 - val_loss: 31.0843\n",
      "Epoch 1135/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3032 - val_loss: 31.1080\n",
      "Epoch 1136/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1766 - val_loss: 31.2495\n",
      "Epoch 1137/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7943 - val_loss: 31.4024\n",
      "Epoch 1138/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4677 - val_loss: 30.9185\n",
      "Epoch 1139/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5794 - val_loss: 30.6861\n",
      "Epoch 1140/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2154 - val_loss: 30.9473\n",
      "Epoch 1141/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.8666 - val_loss: 30.5471\n",
      "Epoch 1142/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5756 - val_loss: 31.0340\n",
      "Epoch 1143/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2934 - val_loss: 31.4274\n",
      "Epoch 1144/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0530 - val_loss: 30.8487\n",
      "Epoch 1145/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 22.2277 - val_loss: 31.0826\n",
      "Epoch 1146/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6140 - val_loss: 31.1575\n",
      "Epoch 1147/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9825 - val_loss: 31.2637\n",
      "Epoch 1148/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8716 - val_loss: 30.9184\n",
      "Epoch 1149/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2831 - val_loss: 31.1212\n",
      "Epoch 1150/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7049 - val_loss: 30.9255\n",
      "Epoch 1151/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2882 - val_loss: 31.1053\n",
      "Epoch 1152/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9336 - val_loss: 31.0355\n",
      "Epoch 1153/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.6800 - val_loss: 31.0882\n",
      "Epoch 1154/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1382 - val_loss: 30.8417\n",
      "Epoch 1155/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.9481 - val_loss: 30.9634\n",
      "Epoch 1156/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7385 - val_loss: 30.9513\n",
      "Epoch 1157/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2157 - val_loss: 30.6845\n",
      "Epoch 1158/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4886 - val_loss: 30.9560\n",
      "Epoch 1159/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7816 - val_loss: 31.3906\n",
      "Epoch 1160/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3927 - val_loss: 31.1709\n",
      "Epoch 1161/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4072 - val_loss: 30.6625\n",
      "Epoch 1162/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1179 - val_loss: 30.6879\n",
      "Epoch 1163/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.8369 - val_loss: 31.3407\n",
      "Epoch 1164/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3395 - val_loss: 30.6161\n",
      "Epoch 1165/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3723 - val_loss: 30.8158\n",
      "Epoch 1166/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7867 - val_loss: 31.0472\n",
      "Epoch 1167/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0659 - val_loss: 31.2102\n",
      "Epoch 1168/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.4944 - val_loss: 30.7091\n",
      "Epoch 1169/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0951 - val_loss: 30.8668\n",
      "Epoch 1170/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.9938 - val_loss: 30.8431\n",
      "Epoch 1171/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8948 - val_loss: 30.4184\n",
      "Epoch 1172/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.1882 - val_loss: 30.9090\n",
      "Epoch 1173/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.0671 - val_loss: 31.2972\n",
      "Epoch 1174/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.2055 - val_loss: 31.1283\n",
      "Epoch 1175/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7138 - val_loss: 30.8353\n",
      "Epoch 1176/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8194 - val_loss: 30.7435\n",
      "Epoch 1177/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9047 - val_loss: 30.7443\n",
      "Epoch 1178/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.6205 - val_loss: 31.1498\n",
      "Epoch 1179/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1992 - val_loss: 30.9514\n",
      "Epoch 1180/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2734 - val_loss: 31.3566\n",
      "Epoch 1181/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.7402 - val_loss: 31.5582\n",
      "Epoch 1182/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9712 - val_loss: 30.7996\n",
      "Epoch 1183/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8513 - val_loss: 30.9107\n",
      "Epoch 1184/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6947 - val_loss: 30.8279\n",
      "Epoch 1185/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.5808 - val_loss: 31.1731\n",
      "Epoch 1186/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.1601 - val_loss: 30.6453\n",
      "Epoch 1187/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5534 - val_loss: 31.0137\n",
      "Epoch 1188/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.8772 - val_loss: 31.1484\n",
      "Epoch 1189/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1494 - val_loss: 30.9109\n",
      "Epoch 1190/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.6987 - val_loss: 30.9547\n",
      "Epoch 1191/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 22.0058 - val_loss: 31.0532\n",
      "Epoch 1192/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.5612 - val_loss: 30.3781\n",
      "Epoch 1193/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2567 - val_loss: 31.0285\n",
      "Epoch 1194/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0397 - val_loss: 30.7960\n",
      "Epoch 1195/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1755 - val_loss: 30.8943\n",
      "Epoch 1196/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0479 - val_loss: 31.1685\n",
      "Epoch 1197/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.7831 - val_loss: 31.1347\n",
      "Epoch 1198/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8217 - val_loss: 31.0233\n",
      "Epoch 1199/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1529 - val_loss: 30.7753\n",
      "Epoch 1200/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4995 - val_loss: 30.9963\n",
      "Epoch 1201/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9960 - val_loss: 31.0417\n",
      "Epoch 1202/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.3695 - val_loss: 30.7127\n",
      "Epoch 1203/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.1935 - val_loss: 30.9814\n",
      "Epoch 1204/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6731 - val_loss: 30.9512\n",
      "Epoch 1205/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8694 - val_loss: 30.9617\n",
      "Epoch 1206/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7835 - val_loss: 30.8591\n",
      "Epoch 1207/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6927 - val_loss: 30.8912\n",
      "Epoch 1208/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.8754 - val_loss: 31.4324\n",
      "Epoch 1209/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7195 - val_loss: 30.7618\n",
      "Epoch 1210/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.7589 - val_loss: 30.9963\n",
      "Epoch 1211/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7719 - val_loss: 30.9971\n",
      "Epoch 1212/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.0317 - val_loss: 31.2934\n",
      "Epoch 1213/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.9441 - val_loss: 31.0302\n",
      "Epoch 1214/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8273 - val_loss: 30.6499\n",
      "Epoch 1215/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6790 - val_loss: 31.0627\n",
      "Epoch 1216/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.4889 - val_loss: 31.1814\n",
      "Epoch 1217/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8709 - val_loss: 30.7267\n",
      "Epoch 1218/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9860 - val_loss: 30.8234\n",
      "Epoch 1219/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4066 - val_loss: 30.9479\n",
      "Epoch 1220/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4494 - val_loss: 30.8125\n",
      "Epoch 1221/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3105 - val_loss: 30.6878\n",
      "Epoch 1222/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.2572 - val_loss: 30.7730\n",
      "Epoch 1223/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.7815 - val_loss: 30.9606\n",
      "Epoch 1224/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1721 - val_loss: 30.8695\n",
      "Epoch 1225/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7664 - val_loss: 30.2686\n",
      "Epoch 1226/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.0001 - val_loss: 31.0079\n",
      "Epoch 1227/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9788 - val_loss: 30.7016\n",
      "Epoch 1228/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9335 - val_loss: 30.9394\n",
      "Epoch 1229/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1293 - val_loss: 30.7587\n",
      "Epoch 1230/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4723 - val_loss: 30.9982\n",
      "Epoch 1231/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8417 - val_loss: 31.1311\n",
      "Epoch 1232/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9305 - val_loss: 30.6455\n",
      "Epoch 1233/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8258 - val_loss: 30.9280\n",
      "Epoch 1234/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.2942 - val_loss: 30.5584\n",
      "Epoch 1235/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22.3428 - val_loss: 30.2924\n",
      "Epoch 1236/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6199 - val_loss: 30.7252\n",
      "Epoch 1237/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6704 - val_loss: 31.1229\n",
      "Epoch 1238/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8537 - val_loss: 30.7067\n",
      "Epoch 1239/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.7443 - val_loss: 30.6963\n",
      "Epoch 1240/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3531 - val_loss: 31.1948\n",
      "Epoch 1241/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6262 - val_loss: 30.8554\n",
      "Epoch 1242/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1138 - val_loss: 30.7417\n",
      "Epoch 1243/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.5350 - val_loss: 30.8255\n",
      "Epoch 1244/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7483 - val_loss: 30.7193\n",
      "Epoch 1245/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9607 - val_loss: 30.5527\n",
      "Epoch 1246/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.8263 - val_loss: 30.8297\n",
      "Epoch 1247/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4096 - val_loss: 30.9384\n",
      "Epoch 1248/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9014 - val_loss: 31.1559\n",
      "Epoch 1249/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3144 - val_loss: 30.4264\n",
      "Epoch 1250/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5481 - val_loss: 30.3996\n",
      "Epoch 1251/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.9373 - val_loss: 30.3669\n",
      "Epoch 1252/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.5361 - val_loss: 30.9408\n",
      "Epoch 1253/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6959 - val_loss: 31.2566\n",
      "Epoch 1254/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3744 - val_loss: 31.0995\n",
      "Epoch 1255/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.3519 - val_loss: 30.6648\n",
      "Epoch 1256/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.6501 - val_loss: 30.7389\n",
      "Epoch 1257/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.3135 - val_loss: 30.6708\n",
      "Epoch 1258/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4912 - val_loss: 30.7551\n",
      "Epoch 1259/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.2356 - val_loss: 30.6733\n",
      "Epoch 1260/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1877 - val_loss: 30.9848\n",
      "Epoch 1261/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7491 - val_loss: 30.6869\n",
      "Epoch 1262/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1749 - val_loss: 30.6628\n",
      "Epoch 1263/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4666 - val_loss: 31.0450\n",
      "Epoch 1264/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5309 - val_loss: 30.8994\n",
      "Epoch 1265/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 22.0704 - val_loss: 30.7036\n",
      "Epoch 1266/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.7442 - val_loss: 30.7501\n",
      "Epoch 1267/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.0922 - val_loss: 30.4916\n",
      "Epoch 1268/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3157 - val_loss: 31.0724\n",
      "Epoch 1269/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.4831 - val_loss: 30.6057\n",
      "Epoch 1270/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.5671 - val_loss: 30.6487\n",
      "Epoch 1271/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.7004 - val_loss: 30.9277\n",
      "Epoch 1272/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.3144 - val_loss: 30.9987\n",
      "Epoch 1273/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.1547 - val_loss: 30.7957\n",
      "Epoch 1274/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3999 - val_loss: 30.6393\n",
      "Epoch 1275/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1299 - val_loss: 30.8575\n",
      "Epoch 1276/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5281 - val_loss: 30.9172\n",
      "Epoch 1277/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.4539 - val_loss: 30.8873\n",
      "Epoch 1278/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1182 - val_loss: 30.7465\n",
      "Epoch 1279/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4127 - val_loss: 30.3155\n",
      "Epoch 1280/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5030 - val_loss: 30.4002\n",
      "Epoch 1281/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4206 - val_loss: 30.7278\n",
      "Epoch 1282/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.3613 - val_loss: 30.6898\n",
      "Epoch 1283/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9385 - val_loss: 30.9231\n",
      "Epoch 1284/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.8849 - val_loss: 30.6641\n",
      "Epoch 1285/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4616 - val_loss: 30.7283\n",
      "Epoch 1286/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9707 - val_loss: 31.0452\n",
      "Epoch 1287/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.3835 - val_loss: 30.5331\n",
      "Epoch 1288/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.2661 - val_loss: 30.7521\n",
      "Epoch 1289/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1744 - val_loss: 30.2964\n",
      "Epoch 1290/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9222 - val_loss: 30.5217\n",
      "Epoch 1291/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.8668 - val_loss: 30.5648\n",
      "Epoch 1292/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.2446 - val_loss: 30.6091\n",
      "Epoch 1293/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.2964 - val_loss: 30.8711\n",
      "Epoch 1294/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3843 - val_loss: 30.9650\n",
      "Epoch 1295/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1797 - val_loss: 30.3234\n",
      "Epoch 1296/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.2226 - val_loss: 30.4344\n",
      "Epoch 1297/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5482 - val_loss: 30.6917\n",
      "Epoch 1298/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1268 - val_loss: 30.9790\n",
      "Epoch 1299/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3075 - val_loss: 30.7356\n",
      "Epoch 1300/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1178 - val_loss: 30.9830\n",
      "Epoch 1301/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3488 - val_loss: 30.8023\n",
      "Epoch 1302/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.2069 - val_loss: 30.7854\n",
      "Epoch 1303/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.0905 - val_loss: 30.2777\n",
      "Epoch 1304/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.2785 - val_loss: 30.2353\n",
      "Epoch 1305/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.7888 - val_loss: 30.4478\n",
      "Epoch 1306/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1639 - val_loss: 30.7961\n",
      "Epoch 1307/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.5791 - val_loss: 30.5488\n",
      "Epoch 1308/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3961 - val_loss: 30.7059\n",
      "Epoch 1309/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9926 - val_loss: 30.5990\n",
      "Epoch 1310/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5201 - val_loss: 30.7197\n",
      "Epoch 1311/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7950 - val_loss: 30.7560\n",
      "Epoch 1312/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1552 - val_loss: 30.4754\n",
      "Epoch 1313/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4105 - val_loss: 30.3573\n",
      "Epoch 1314/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.4516 - val_loss: 30.4933\n",
      "Epoch 1315/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3267 - val_loss: 30.2888\n",
      "Epoch 1316/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3526 - val_loss: 30.3358\n",
      "Epoch 1317/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.0170 - val_loss: 30.7527\n",
      "Epoch 1318/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3063 - val_loss: 31.1823\n",
      "Epoch 1319/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1431 - val_loss: 30.7799\n",
      "Epoch 1320/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9669 - val_loss: 30.7268\n",
      "Epoch 1321/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.3633 - val_loss: 31.0330\n",
      "Epoch 1322/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5031 - val_loss: 30.6913\n",
      "Epoch 1323/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1362 - val_loss: 30.8861\n",
      "Epoch 1324/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9260 - val_loss: 30.4322\n",
      "Epoch 1325/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9616 - val_loss: 30.9169\n",
      "Epoch 1326/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.2160 - val_loss: 31.1475\n",
      "Epoch 1327/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5717 - val_loss: 30.6149\n",
      "Epoch 1328/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8876 - val_loss: 30.5580\n",
      "Epoch 1329/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1521 - val_loss: 30.5675\n",
      "Epoch 1330/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.8928 - val_loss: 31.0665\n",
      "Epoch 1331/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21.1962 - val_loss: 30.8294\n",
      "Epoch 1332/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1905 - val_loss: 30.3164\n",
      "Epoch 1333/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.9379 - val_loss: 30.3335\n",
      "Epoch 1334/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8745 - val_loss: 31.1184\n",
      "Epoch 1335/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.2365 - val_loss: 30.6165\n",
      "Epoch 1336/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1812 - val_loss: 31.0906\n",
      "Epoch 1337/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8415 - val_loss: 30.9077\n",
      "Epoch 1338/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7862 - val_loss: 30.3988\n",
      "Epoch 1339/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7221 - val_loss: 30.6107\n",
      "Epoch 1340/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1673 - val_loss: 30.7002\n",
      "Epoch 1341/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9932 - val_loss: 30.7970\n",
      "Epoch 1342/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8788 - val_loss: 30.5295\n",
      "Epoch 1343/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.6031 - val_loss: 30.6647\n",
      "Epoch 1344/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1099 - val_loss: 30.4647\n",
      "Epoch 1345/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5497 - val_loss: 30.5065\n",
      "Epoch 1346/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3158 - val_loss: 30.2795\n",
      "Epoch 1347/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6723 - val_loss: 30.8448\n",
      "Epoch 1348/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.7582 - val_loss: 30.4775\n",
      "Epoch 1349/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9777 - val_loss: 30.8070\n",
      "Epoch 1350/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.6858 - val_loss: 30.2609\n",
      "Epoch 1351/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.7095 - val_loss: 30.2112\n",
      "Epoch 1352/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1961 - val_loss: 30.5345\n",
      "Epoch 1353/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8163 - val_loss: 30.6262\n",
      "Epoch 1354/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9168 - val_loss: 30.5587\n",
      "Epoch 1355/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.6909 - val_loss: 30.9401\n",
      "Epoch 1356/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.0099 - val_loss: 30.8711\n",
      "Epoch 1357/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6500 - val_loss: 30.3720\n",
      "Epoch 1358/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8705 - val_loss: 30.7426\n",
      "Epoch 1359/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8239 - val_loss: 30.4854\n",
      "Epoch 1360/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.5739 - val_loss: 30.6578\n",
      "Epoch 1361/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5284 - val_loss: 30.4289\n",
      "Epoch 1362/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7295 - val_loss: 30.5509\n",
      "Epoch 1363/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1633 - val_loss: 30.3436\n",
      "Epoch 1364/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6270 - val_loss: 30.6637\n",
      "Epoch 1365/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4910 - val_loss: 30.6450\n",
      "Epoch 1366/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5323 - val_loss: 30.3855\n",
      "Epoch 1367/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6397 - val_loss: 30.2076\n",
      "Epoch 1368/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9532 - val_loss: 30.7377\n",
      "Epoch 1369/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7516 - val_loss: 30.9448\n",
      "Epoch 1370/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.3024 - val_loss: 30.3230\n",
      "Epoch 1371/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5738 - val_loss: 30.4040\n",
      "Epoch 1372/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9941 - val_loss: 30.8009\n",
      "Epoch 1373/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.7892 - val_loss: 30.3135\n",
      "Epoch 1374/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6581 - val_loss: 30.4340\n",
      "Epoch 1375/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9506 - val_loss: 30.5132\n",
      "Epoch 1376/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7668 - val_loss: 30.6267\n",
      "Epoch 1377/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4850 - val_loss: 31.0481\n",
      "Epoch 1378/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1341 - val_loss: 30.5259\n",
      "Epoch 1379/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7006 - val_loss: 30.3740\n",
      "Epoch 1380/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9864 - val_loss: 30.5288\n",
      "Epoch 1381/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6566 - val_loss: 30.9688\n",
      "Epoch 1382/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20.7817 - val_loss: 30.6566\n",
      "Epoch 1383/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.3253 - val_loss: 30.8405\n",
      "Epoch 1384/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4037 - val_loss: 30.5808\n",
      "Epoch 1385/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.5428 - val_loss: 31.0248\n",
      "Epoch 1386/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.0920 - val_loss: 30.7857\n",
      "Epoch 1387/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.1661 - val_loss: 30.9465\n",
      "Epoch 1388/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8629 - val_loss: 30.5045\n",
      "Epoch 1389/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6313 - val_loss: 30.4669\n",
      "Epoch 1390/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.9145 - val_loss: 30.9102\n",
      "Epoch 1391/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21.4386 - val_loss: 30.8983\n",
      "Epoch 1392/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7411 - val_loss: 30.4232\n",
      "Epoch 1393/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.9513 - val_loss: 30.0618\n",
      "Epoch 1394/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5099 - val_loss: 30.6575\n",
      "Epoch 1395/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7894 - val_loss: 30.6783\n",
      "Epoch 1396/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8001 - val_loss: 30.4676\n",
      "Epoch 1397/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8599 - val_loss: 30.8344\n",
      "Epoch 1398/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7204 - val_loss: 30.6856\n",
      "Epoch 1399/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2878 - val_loss: 30.2148\n",
      "Epoch 1400/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21.0995 - val_loss: 30.4519\n",
      "Epoch 1401/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8719 - val_loss: 30.5120\n",
      "Epoch 1402/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6453 - val_loss: 30.6858\n",
      "Epoch 1403/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6050 - val_loss: 30.3582\n",
      "Epoch 1404/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5676 - val_loss: 30.5616\n",
      "Epoch 1405/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7174 - val_loss: 30.1178\n",
      "Epoch 1406/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6424 - val_loss: 30.3062\n",
      "Epoch 1407/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0852 - val_loss: 30.6055\n",
      "Epoch 1408/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8046 - val_loss: 30.8656\n",
      "Epoch 1409/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3017 - val_loss: 30.8218\n",
      "Epoch 1410/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4732 - val_loss: 30.4539\n",
      "Epoch 1411/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8565 - val_loss: 30.5699\n",
      "Epoch 1412/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4353 - val_loss: 30.7063\n",
      "Epoch 1413/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1201 - val_loss: 30.3179\n",
      "Epoch 1414/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2914 - val_loss: 30.1970\n",
      "Epoch 1415/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2594 - val_loss: 30.2829\n",
      "Epoch 1416/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7993 - val_loss: 30.3604\n",
      "Epoch 1417/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5214 - val_loss: 30.3387\n",
      "Epoch 1418/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.8051 - val_loss: 30.4827\n",
      "Epoch 1419/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5476 - val_loss: 30.5789\n",
      "Epoch 1420/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6134 - val_loss: 30.3256\n",
      "Epoch 1421/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0990 - val_loss: 30.4353\n",
      "Epoch 1422/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4311 - val_loss: 30.3474\n",
      "Epoch 1423/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4411 - val_loss: 30.6248\n",
      "Epoch 1424/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.3292 - val_loss: 30.4927\n",
      "Epoch 1425/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6052 - val_loss: 30.3152\n",
      "Epoch 1426/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3402 - val_loss: 30.2585\n",
      "Epoch 1427/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.0412 - val_loss: 30.6159\n",
      "Epoch 1428/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1758 - val_loss: 30.4954\n",
      "Epoch 1429/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.6292 - val_loss: 30.1834\n",
      "Epoch 1430/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1393 - val_loss: 30.7375\n",
      "Epoch 1431/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1200 - val_loss: 29.9356\n",
      "Epoch 1432/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.7813 - val_loss: 30.0246\n",
      "Epoch 1433/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2205 - val_loss: 30.9999\n",
      "Epoch 1434/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6540 - val_loss: 30.2503\n",
      "Epoch 1435/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0852 - val_loss: 30.1129\n",
      "Epoch 1436/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7251 - val_loss: 30.3963\n",
      "Epoch 1437/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.3613 - val_loss: 30.5196\n",
      "Epoch 1438/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1636 - val_loss: 30.5056\n",
      "Epoch 1439/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2565 - val_loss: 30.3899\n",
      "Epoch 1440/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5382 - val_loss: 30.5875\n",
      "Epoch 1441/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7596 - val_loss: 30.4942\n",
      "Epoch 1442/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0401 - val_loss: 30.6902\n",
      "Epoch 1443/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4162 - val_loss: 30.3237\n",
      "Epoch 1444/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9509 - val_loss: 30.2376\n",
      "Epoch 1445/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3622 - val_loss: 30.6428\n",
      "Epoch 1446/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2093 - val_loss: 30.3893\n",
      "Epoch 1447/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1770 - val_loss: 30.4460\n",
      "Epoch 1448/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0537 - val_loss: 30.1471\n",
      "Epoch 1449/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.8596 - val_loss: 29.9643\n",
      "Epoch 1450/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4026 - val_loss: 30.8939\n",
      "Epoch 1451/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4648 - val_loss: 30.0118\n",
      "Epoch 1452/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.7447 - val_loss: 30.4457\n",
      "Epoch 1453/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6725 - val_loss: 30.2874\n",
      "Epoch 1454/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0274 - val_loss: 30.2645\n",
      "Epoch 1455/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1627 - val_loss: 30.6640\n",
      "Epoch 1456/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3734 - val_loss: 30.3151\n",
      "Epoch 1457/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2285 - val_loss: 30.2518\n",
      "Epoch 1458/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2089 - val_loss: 30.0401\n",
      "Epoch 1459/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8535 - val_loss: 30.3636\n",
      "Epoch 1460/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3870 - val_loss: 30.7908\n",
      "Epoch 1461/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6133 - val_loss: 30.2930\n",
      "Epoch 1462/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1070 - val_loss: 30.2812\n",
      "Epoch 1463/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5167 - val_loss: 30.4840\n",
      "Epoch 1464/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8831 - val_loss: 30.1773\n",
      "Epoch 1465/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9944 - val_loss: 30.4389\n",
      "Epoch 1466/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2098 - val_loss: 30.3316\n",
      "Epoch 1467/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.3172 - val_loss: 30.6059\n",
      "Epoch 1468/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2464 - val_loss: 30.5054\n",
      "Epoch 1469/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0633 - val_loss: 30.6586\n",
      "Epoch 1470/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5403 - val_loss: 30.6874\n",
      "Epoch 1471/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2655 - val_loss: 30.7512\n",
      "Epoch 1472/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1079 - val_loss: 30.6031\n",
      "Epoch 1473/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5659 - val_loss: 29.9249\n",
      "Epoch 1474/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.3137 - val_loss: 30.0877\n",
      "Epoch 1475/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1381 - val_loss: 30.2484\n",
      "Epoch 1476/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1379 - val_loss: 29.6174\n",
      "Epoch 1477/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.6666 - val_loss: 30.3803\n",
      "Epoch 1478/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0448 - val_loss: 30.5319\n",
      "Epoch 1479/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3669 - val_loss: 30.3832\n",
      "Epoch 1480/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9647 - val_loss: 30.4720\n",
      "Epoch 1481/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.5449 - val_loss: 30.5863\n",
      "Epoch 1482/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1693 - val_loss: 30.2395\n",
      "Epoch 1483/50000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 20.1732 - val_loss: 30.5769\n",
      "Epoch 1484/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0786 - val_loss: 30.4178\n",
      "Epoch 1485/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0711 - val_loss: 30.7898\n",
      "Epoch 1486/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9255 - val_loss: 30.1022\n",
      "Epoch 1487/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9474 - val_loss: 30.3085\n",
      "Epoch 1488/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0475 - val_loss: 30.2358\n",
      "Epoch 1489/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1862 - val_loss: 30.1982\n",
      "Epoch 1490/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9519 - val_loss: 30.4201\n",
      "Epoch 1491/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4625 - val_loss: 30.2323\n",
      "Epoch 1492/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9999 - val_loss: 30.6341\n",
      "Epoch 1493/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7242 - val_loss: 30.3342\n",
      "Epoch 1494/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1043 - val_loss: 30.2851\n",
      "Epoch 1495/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4664 - val_loss: 30.3002\n",
      "Epoch 1496/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3299 - val_loss: 30.6374\n",
      "Epoch 1497/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2005 - val_loss: 29.8078\n",
      "Epoch 1498/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4102 - val_loss: 30.8536\n",
      "Epoch 1499/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0951 - val_loss: 30.6744\n",
      "Epoch 1500/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7522 - val_loss: 30.5249\n",
      "Epoch 1501/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1069 - val_loss: 30.6014\n",
      "Epoch 1502/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9351 - val_loss: 30.2633\n",
      "Epoch 1503/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8641 - val_loss: 30.4185\n",
      "Epoch 1504/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8825 - val_loss: 30.0931\n",
      "Epoch 1505/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9435 - val_loss: 30.0851\n",
      "Epoch 1506/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2093 - val_loss: 29.9681\n",
      "Epoch 1507/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0854 - val_loss: 30.0707\n",
      "Epoch 1508/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9943 - val_loss: 30.1694\n",
      "Epoch 1509/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2205 - val_loss: 30.3888\n",
      "Epoch 1510/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.6056 - val_loss: 30.6025\n",
      "Epoch 1511/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8211 - val_loss: 30.0212\n",
      "Epoch 1512/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9320 - val_loss: 30.3523\n",
      "Epoch 1513/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0683 - val_loss: 30.0579\n",
      "Epoch 1514/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7201 - val_loss: 30.5237\n",
      "Epoch 1515/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2115 - val_loss: 30.3253\n",
      "Epoch 1516/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0276 - val_loss: 30.4298\n",
      "Epoch 1517/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.2379 - val_loss: 30.5587\n",
      "Epoch 1518/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0559 - val_loss: 30.3443\n",
      "Epoch 1519/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.4067 - val_loss: 30.4779\n",
      "Epoch 1520/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9653 - val_loss: 30.0673\n",
      "Epoch 1521/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7562 - val_loss: 29.8994\n",
      "Epoch 1522/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.3022 - val_loss: 29.7579\n",
      "Epoch 1523/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.1254 - val_loss: 30.4320\n",
      "Epoch 1524/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7183 - val_loss: 30.4246\n",
      "Epoch 1525/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.6631 - val_loss: 30.3509\n",
      "Epoch 1526/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5123 - val_loss: 30.4071\n",
      "Epoch 1527/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9328 - val_loss: 30.2063\n",
      "Epoch 1528/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6427 - val_loss: 30.1176\n",
      "Epoch 1529/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5889 - val_loss: 30.8656\n",
      "Epoch 1530/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7985 - val_loss: 30.0397\n",
      "Epoch 1531/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9779 - val_loss: 30.5266\n",
      "Epoch 1532/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8912 - val_loss: 30.3993\n",
      "Epoch 1533/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9245 - val_loss: 30.4597\n",
      "Epoch 1534/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9574 - val_loss: 30.4961\n",
      "Epoch 1535/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8381 - val_loss: 30.2522\n",
      "Epoch 1536/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7086 - val_loss: 30.2233\n",
      "Epoch 1537/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5337 - val_loss: 30.6638\n",
      "Epoch 1538/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9119 - val_loss: 29.8937\n",
      "Epoch 1539/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9774 - val_loss: 30.4239\n",
      "Epoch 1540/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8803 - val_loss: 30.1018\n",
      "Epoch 1541/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8478 - val_loss: 30.2576\n",
      "Epoch 1542/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6220 - val_loss: 30.3123\n",
      "Epoch 1543/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19.7742 - val_loss: 30.0600\n",
      "Epoch 1544/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5397 - val_loss: 30.6922\n",
      "Epoch 1545/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2869 - val_loss: 30.4087\n",
      "Epoch 1546/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2392 - val_loss: 30.6768\n",
      "Epoch 1547/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9783 - val_loss: 30.4122\n",
      "Epoch 1548/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.1429 - val_loss: 29.7590\n",
      "Epoch 1549/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2524 - val_loss: 30.3698\n",
      "Epoch 1550/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8979 - val_loss: 30.6778\n",
      "Epoch 1551/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9089 - val_loss: 30.2924\n",
      "Epoch 1552/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7101 - val_loss: 30.8135\n",
      "Epoch 1553/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6663 - val_loss: 29.7747\n",
      "Epoch 1554/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2981 - val_loss: 29.9108\n",
      "Epoch 1555/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.0359 - val_loss: 30.4306\n",
      "Epoch 1556/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7139 - val_loss: 30.6576\n",
      "Epoch 1557/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6985 - val_loss: 30.0641\n",
      "Epoch 1558/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.0413 - val_loss: 30.5966\n",
      "Epoch 1559/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.2022 - val_loss: 29.4469\n",
      "Epoch 1560/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.1213 - val_loss: 30.6965\n",
      "Epoch 1561/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4000 - val_loss: 30.1757\n",
      "Epoch 1562/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8633 - val_loss: 29.5692\n",
      "Epoch 1563/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8553 - val_loss: 30.1963\n",
      "Epoch 1564/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4885 - val_loss: 30.0703\n",
      "Epoch 1565/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7449 - val_loss: 30.5689\n",
      "Epoch 1566/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8324 - val_loss: 30.4236\n",
      "Epoch 1567/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9070 - val_loss: 30.0562\n",
      "Epoch 1568/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7349 - val_loss: 29.6331\n",
      "Epoch 1569/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7115 - val_loss: 30.0755\n",
      "Epoch 1570/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6082 - val_loss: 29.8352\n",
      "Epoch 1571/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4842 - val_loss: 30.5861\n",
      "Epoch 1572/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6243 - val_loss: 29.9456\n",
      "Epoch 1573/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7637 - val_loss: 29.9995\n",
      "Epoch 1574/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4880 - val_loss: 29.6485\n",
      "Epoch 1575/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20.0294 - val_loss: 30.3554\n",
      "Epoch 1576/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.0093 - val_loss: 29.7955\n",
      "Epoch 1577/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.9011 - val_loss: 29.8562\n",
      "Epoch 1578/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6068 - val_loss: 30.3050\n",
      "Epoch 1579/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5246 - val_loss: 30.0044\n",
      "Epoch 1580/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.0688 - val_loss: 30.3709\n",
      "Epoch 1581/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8890 - val_loss: 30.0056\n",
      "Epoch 1582/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5220 - val_loss: 30.8064\n",
      "Epoch 1583/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5152 - val_loss: 29.8691\n",
      "Epoch 1584/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7806 - val_loss: 30.2606\n",
      "Epoch 1585/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8882 - val_loss: 30.0420\n",
      "Epoch 1586/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3820 - val_loss: 30.2648\n",
      "Epoch 1587/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7110 - val_loss: 29.5468\n",
      "Epoch 1588/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7302 - val_loss: 30.6023\n",
      "Epoch 1589/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3095 - val_loss: 29.7542\n",
      "Epoch 1590/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8162 - val_loss: 30.6412\n",
      "Epoch 1591/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5001 - val_loss: 30.5684\n",
      "Epoch 1592/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5774 - val_loss: 30.3509\n",
      "Epoch 1593/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5278 - val_loss: 30.1177\n",
      "Epoch 1594/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4952 - val_loss: 29.9023\n",
      "Epoch 1595/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4683 - val_loss: 30.1327\n",
      "Epoch 1596/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7102 - val_loss: 30.0148\n",
      "Epoch 1597/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4022 - val_loss: 30.2870\n",
      "Epoch 1598/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.9257 - val_loss: 30.3582\n",
      "Epoch 1599/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7799 - val_loss: 29.8289\n",
      "Epoch 1600/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6709 - val_loss: 30.1974\n",
      "Epoch 1601/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5217 - val_loss: 30.3068\n",
      "Epoch 1602/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5339 - val_loss: 30.1652\n",
      "Epoch 1603/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4993 - val_loss: 30.1507\n",
      "Epoch 1604/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5548 - val_loss: 29.8908\n",
      "Epoch 1605/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8966 - val_loss: 30.2856\n",
      "Epoch 1606/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5905 - val_loss: 30.0416\n",
      "Epoch 1607/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8048 - val_loss: 29.9103\n",
      "Epoch 1608/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4641 - val_loss: 29.4584\n",
      "Epoch 1609/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6004 - val_loss: 30.1791\n",
      "Epoch 1610/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5032 - val_loss: 29.7841\n",
      "Epoch 1611/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3868 - val_loss: 29.9845\n",
      "Epoch 1612/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7312 - val_loss: 30.5228\n",
      "Epoch 1613/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1846 - val_loss: 30.3267\n",
      "Epoch 1614/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8034 - val_loss: 30.3494\n",
      "Epoch 1615/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5588 - val_loss: 30.7103\n",
      "Epoch 1616/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1772 - val_loss: 30.1932\n",
      "Epoch 1617/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5069 - val_loss: 30.1250\n",
      "Epoch 1618/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4097 - val_loss: 30.0774\n",
      "Epoch 1619/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3799 - val_loss: 29.7866\n",
      "Epoch 1620/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7416 - val_loss: 29.7624\n",
      "Epoch 1621/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5087 - val_loss: 30.0744\n",
      "Epoch 1622/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8327 - val_loss: 30.0108\n",
      "Epoch 1623/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4645 - val_loss: 30.2247\n",
      "Epoch 1624/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7528 - val_loss: 30.4476\n",
      "Epoch 1625/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4421 - val_loss: 30.3277\n",
      "Epoch 1626/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3948 - val_loss: 30.5221\n",
      "Epoch 1627/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2484 - val_loss: 30.0273\n",
      "Epoch 1628/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5592 - val_loss: 29.9977\n",
      "Epoch 1629/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.8994 - val_loss: 30.5902\n",
      "Epoch 1630/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1803 - val_loss: 30.1833\n",
      "Epoch 1631/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5607 - val_loss: 30.5090\n",
      "Epoch 1632/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4794 - val_loss: 30.3184\n",
      "Epoch 1633/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.3899 - val_loss: 29.7973\n",
      "Epoch 1634/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4182 - val_loss: 30.0525\n",
      "Epoch 1635/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2941 - val_loss: 30.1799\n",
      "Epoch 1636/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0505 - val_loss: 30.2416\n",
      "Epoch 1637/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8101 - val_loss: 29.9109\n",
      "Epoch 1638/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4635 - val_loss: 30.2213\n",
      "Epoch 1639/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4028 - val_loss: 30.1313\n",
      "Epoch 1640/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5696 - val_loss: 29.8859\n",
      "Epoch 1641/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4195 - val_loss: 29.9512\n",
      "Epoch 1642/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1060 - val_loss: 30.2038\n",
      "Epoch 1643/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.6752 - val_loss: 30.4391\n",
      "Epoch 1644/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4290 - val_loss: 29.7165\n",
      "Epoch 1645/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1504 - val_loss: 29.9506\n",
      "Epoch 1646/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2770 - val_loss: 29.5426\n",
      "Epoch 1647/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4420 - val_loss: 30.0868\n",
      "Epoch 1648/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2967 - val_loss: 30.1823\n",
      "Epoch 1649/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7780 - val_loss: 30.2006\n",
      "Epoch 1650/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5432 - val_loss: 30.4501\n",
      "Epoch 1651/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.5958 - val_loss: 30.2361\n",
      "Epoch 1652/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0753 - val_loss: 29.7389\n",
      "Epoch 1653/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2895 - val_loss: 29.4721\n",
      "Epoch 1654/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.6209 - val_loss: 29.9042\n",
      "Epoch 1655/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1254 - val_loss: 30.0591\n",
      "Epoch 1656/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1519 - val_loss: 30.3417\n",
      "Epoch 1657/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2040 - val_loss: 29.3437\n",
      "Epoch 1658/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.2329 - val_loss: 29.9040\n",
      "Epoch 1659/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1580 - val_loss: 29.7362\n",
      "Epoch 1660/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7504 - val_loss: 29.8640\n",
      "Epoch 1661/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1932 - val_loss: 29.7710\n",
      "Epoch 1662/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4696 - val_loss: 29.9572\n",
      "Epoch 1663/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2702 - val_loss: 30.0142\n",
      "Epoch 1664/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1440 - val_loss: 30.2475\n",
      "Epoch 1665/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4998 - val_loss: 29.9306\n",
      "Epoch 1666/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3095 - val_loss: 30.1122\n",
      "Epoch 1667/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0835 - val_loss: 30.4560\n",
      "Epoch 1668/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0663 - val_loss: 30.0663\n",
      "Epoch 1669/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1465 - val_loss: 29.8593\n",
      "Epoch 1670/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2104 - val_loss: 30.1694\n",
      "Epoch 1671/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4515 - val_loss: 29.4470\n",
      "Epoch 1672/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4136 - val_loss: 29.6649\n",
      "Epoch 1673/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0176 - val_loss: 30.1021\n",
      "Epoch 1674/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4082 - val_loss: 30.0410\n",
      "Epoch 1675/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3516 - val_loss: 30.0227\n",
      "Epoch 1676/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.8255 - val_loss: 29.8444\n",
      "Epoch 1677/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2505 - val_loss: 30.3360\n",
      "Epoch 1678/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19.2941 - val_loss: 30.1309\n",
      "Epoch 1679/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1218 - val_loss: 29.5618\n",
      "Epoch 1680/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2958 - val_loss: 30.4789\n",
      "Epoch 1681/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2300 - val_loss: 30.0835\n",
      "Epoch 1682/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4437 - val_loss: 30.2126\n",
      "Epoch 1683/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1349 - val_loss: 30.2143\n",
      "Epoch 1684/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5011 - val_loss: 29.7197\n",
      "Epoch 1685/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3286 - val_loss: 29.5107\n",
      "Epoch 1686/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4180 - val_loss: 29.9425\n",
      "Epoch 1687/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2921 - val_loss: 30.0086\n",
      "Epoch 1688/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3300 - val_loss: 30.1568\n",
      "Epoch 1689/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4198 - val_loss: 30.0585\n",
      "Epoch 1690/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.5933 - val_loss: 30.2930\n",
      "Epoch 1691/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.6269 - val_loss: 30.6278\n",
      "Epoch 1692/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.4612 - val_loss: 29.8201\n",
      "Epoch 1693/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19.6105 - val_loss: 30.0880\n",
      "Epoch 1694/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4398 - val_loss: 30.1989\n",
      "Epoch 1695/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1743 - val_loss: 29.5657\n",
      "Epoch 1696/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4077 - val_loss: 29.9473\n",
      "Epoch 1697/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3543 - val_loss: 30.4487\n",
      "Epoch 1698/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0268 - val_loss: 30.3817\n",
      "Epoch 1699/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.6686 - val_loss: 29.5564\n",
      "Epoch 1700/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.3631 - val_loss: 30.7049\n",
      "Epoch 1701/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0104 - val_loss: 30.1308\n",
      "Epoch 1702/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8075 - val_loss: 29.5268\n",
      "Epoch 1703/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1921 - val_loss: 29.4552\n",
      "Epoch 1704/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9103 - val_loss: 30.1030\n",
      "Epoch 1705/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.7339 - val_loss: 29.8482\n",
      "Epoch 1706/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3351 - val_loss: 29.8876\n",
      "Epoch 1707/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.4238 - val_loss: 30.2480\n",
      "Epoch 1708/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2101 - val_loss: 29.6059\n",
      "Epoch 1709/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9824 - val_loss: 29.2903\n",
      "Epoch 1710/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.9446 - val_loss: 29.8355\n",
      "Epoch 1711/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2529 - val_loss: 29.8041\n",
      "Epoch 1712/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0375 - val_loss: 30.3220\n",
      "Epoch 1713/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8166 - val_loss: 29.7771\n",
      "Epoch 1714/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1642 - val_loss: 29.8158\n",
      "Epoch 1715/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.9412 - val_loss: 29.5764\n",
      "Epoch 1716/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1311 - val_loss: 29.9092\n",
      "Epoch 1717/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1841 - val_loss: 30.1446\n",
      "Epoch 1718/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0041 - val_loss: 29.8516\n",
      "Epoch 1719/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2619 - val_loss: 30.5091\n",
      "Epoch 1720/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.2797 - val_loss: 30.0208\n",
      "Epoch 1721/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0490 - val_loss: 29.9829\n",
      "Epoch 1722/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.2489 - val_loss: 30.4825\n",
      "Epoch 1723/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9973 - val_loss: 30.3187\n",
      "Epoch 1724/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0449 - val_loss: 29.6935\n",
      "Epoch 1725/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1070 - val_loss: 29.7235\n",
      "Epoch 1726/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0069 - val_loss: 30.2982\n",
      "Epoch 1727/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.9780 - val_loss: 29.7707\n",
      "Epoch 1728/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8156 - val_loss: 30.0259\n",
      "Epoch 1729/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9462 - val_loss: 30.1083\n",
      "Epoch 1730/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0310 - val_loss: 29.0709\n",
      "Epoch 1731/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0413 - val_loss: 29.5558\n",
      "Epoch 1732/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1403 - val_loss: 30.1185\n",
      "Epoch 1733/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8939 - val_loss: 30.1363\n",
      "Epoch 1734/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3236 - val_loss: 29.7140\n",
      "Epoch 1735/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.2546 - val_loss: 29.7966\n",
      "Epoch 1736/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8913 - val_loss: 30.3798\n",
      "Epoch 1737/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7553 - val_loss: 30.1137\n",
      "Epoch 1738/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19.2271 - val_loss: 29.7978\n",
      "Epoch 1739/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0182 - val_loss: 29.8566\n",
      "Epoch 1740/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8957 - val_loss: 30.5277\n",
      "Epoch 1741/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2784 - val_loss: 30.2296\n",
      "Epoch 1742/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.3088 - val_loss: 30.1887\n",
      "Epoch 1743/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.3615 - val_loss: 30.4387\n",
      "Epoch 1744/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7518 - val_loss: 29.9032\n",
      "Epoch 1745/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.3688 - val_loss: 29.9374\n",
      "Epoch 1746/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.8941 - val_loss: 30.2070\n",
      "Epoch 1747/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.2970 - val_loss: 29.6974\n",
      "Epoch 1748/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0892 - val_loss: 30.0967\n",
      "Epoch 1749/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8928 - val_loss: 30.2511\n",
      "Epoch 1750/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6800 - val_loss: 29.5529\n",
      "Epoch 1751/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7752 - val_loss: 29.8406\n",
      "Epoch 1752/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1570 - val_loss: 29.3471\n",
      "Epoch 1753/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0908 - val_loss: 29.8246\n",
      "Epoch 1754/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7526 - val_loss: 30.1786\n",
      "Epoch 1755/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7818 - val_loss: 30.2297\n",
      "Epoch 1756/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8912 - val_loss: 30.3433\n",
      "Epoch 1757/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9398 - val_loss: 29.9371\n",
      "Epoch 1758/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0364 - val_loss: 29.8591\n",
      "Epoch 1759/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9331 - val_loss: 29.8491\n",
      "Epoch 1760/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.9908 - val_loss: 30.6858\n",
      "Epoch 1761/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0730 - val_loss: 30.0788\n",
      "Epoch 1762/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7448 - val_loss: 29.7683\n",
      "Epoch 1763/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0146 - val_loss: 30.1299\n",
      "Epoch 1764/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7667 - val_loss: 29.9647\n",
      "Epoch 1765/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1970 - val_loss: 30.1825\n",
      "Epoch 1766/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9516 - val_loss: 29.8001\n",
      "Epoch 1767/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0546 - val_loss: 29.9042\n",
      "Epoch 1768/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7946 - val_loss: 29.5836\n",
      "Epoch 1769/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.5555 - val_loss: 30.1713\n",
      "Epoch 1770/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8879 - val_loss: 30.0008\n",
      "Epoch 1771/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0763 - val_loss: 29.9089\n",
      "Epoch 1772/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6292 - val_loss: 30.5799\n",
      "Epoch 1773/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8732 - val_loss: 29.6674\n",
      "Epoch 1774/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0768 - val_loss: 29.9536\n",
      "Epoch 1775/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6132 - val_loss: 30.1050\n",
      "Epoch 1776/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6628 - val_loss: 29.6190\n",
      "Epoch 1777/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9874 - val_loss: 30.3946\n",
      "Epoch 1778/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.8124 - val_loss: 29.8324\n",
      "Epoch 1779/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.8050 - val_loss: 30.1698\n",
      "Epoch 1780/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9959 - val_loss: 29.8242\n",
      "Epoch 1781/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8451 - val_loss: 29.9877\n",
      "Epoch 1782/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4541 - val_loss: 30.1626\n",
      "Epoch 1783/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7198 - val_loss: 30.4339\n",
      "Epoch 1784/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0140 - val_loss: 29.6738\n",
      "Epoch 1785/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5880 - val_loss: 29.9800\n",
      "Epoch 1786/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1313 - val_loss: 29.9541\n",
      "Epoch 1787/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7844 - val_loss: 30.2174\n",
      "Epoch 1788/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1432 - val_loss: 29.9079\n",
      "Epoch 1789/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7751 - val_loss: 30.1581\n",
      "Epoch 1790/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.8487 - val_loss: 29.9011\n",
      "Epoch 1791/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.1043 - val_loss: 29.6287\n",
      "Epoch 1792/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9975 - val_loss: 29.7925\n",
      "Epoch 1793/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9746 - val_loss: 29.8526\n",
      "Epoch 1794/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9405 - val_loss: 30.5364\n",
      "Epoch 1795/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0925 - val_loss: 29.6208\n",
      "Epoch 1796/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.5688 - val_loss: 29.8920\n",
      "Epoch 1797/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6840 - val_loss: 29.5050\n",
      "Epoch 1798/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6038 - val_loss: 29.9355\n",
      "Epoch 1799/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5991 - val_loss: 29.9782\n",
      "Epoch 1800/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6444 - val_loss: 29.7935\n",
      "Epoch 1801/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.0864 - val_loss: 29.8058\n",
      "Epoch 1802/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9784 - val_loss: 29.9630\n",
      "Epoch 1803/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7882 - val_loss: 30.4796\n",
      "Epoch 1804/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6390 - val_loss: 30.0661\n",
      "Epoch 1805/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4178 - val_loss: 29.4306\n",
      "Epoch 1806/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6381 - val_loss: 29.9255\n",
      "Epoch 1807/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6034 - val_loss: 30.1649\n",
      "Epoch 1808/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9055 - val_loss: 29.7975\n",
      "Epoch 1809/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5372 - val_loss: 29.7613\n",
      "Epoch 1810/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5702 - val_loss: 29.6434\n",
      "Epoch 1811/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.8727 - val_loss: 29.7386\n",
      "Epoch 1812/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8515 - val_loss: 29.8081\n",
      "Epoch 1813/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6748 - val_loss: 29.5264\n",
      "Epoch 1814/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6135 - val_loss: 30.0581\n",
      "Epoch 1815/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.5811 - val_loss: 30.0734\n",
      "Epoch 1816/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6935 - val_loss: 29.5806\n",
      "Epoch 1817/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4674 - val_loss: 29.7928\n",
      "Epoch 1818/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5806 - val_loss: 29.8440\n",
      "Epoch 1819/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.4816 - val_loss: 30.1639\n",
      "Epoch 1820/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8136 - val_loss: 29.7693\n",
      "Epoch 1821/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.1120 - val_loss: 30.1198\n",
      "Epoch 1822/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9338 - val_loss: 29.5453\n",
      "Epoch 1823/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6177 - val_loss: 30.1761\n",
      "Epoch 1824/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7146 - val_loss: 30.4514\n",
      "Epoch 1825/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.6721 - val_loss: 29.5304\n",
      "Epoch 1826/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7318 - val_loss: 29.9511\n",
      "Epoch 1827/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6247 - val_loss: 29.7782\n",
      "Epoch 1828/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9772 - val_loss: 29.4871\n",
      "Epoch 1829/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.9990 - val_loss: 29.8126\n",
      "Epoch 1830/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.6929 - val_loss: 29.8514\n",
      "Epoch 1831/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.9272 - val_loss: 30.4309\n",
      "Epoch 1832/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6479 - val_loss: 29.8628\n",
      "Epoch 1833/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6575 - val_loss: 30.1766\n",
      "Epoch 1834/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9881 - val_loss: 29.9027\n",
      "Epoch 1835/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8111 - val_loss: 29.8209\n",
      "Epoch 1836/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6019 - val_loss: 29.9571\n",
      "Epoch 1837/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6643 - val_loss: 30.4462\n",
      "Epoch 1838/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5440 - val_loss: 30.7785\n",
      "Epoch 1839/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5068 - val_loss: 30.0818\n",
      "Epoch 1840/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6530 - val_loss: 29.7446\n",
      "Epoch 1841/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5928 - val_loss: 30.3335\n",
      "Epoch 1842/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6922 - val_loss: 30.0947\n",
      "Epoch 1843/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6174 - val_loss: 29.7696\n",
      "Epoch 1844/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5485 - val_loss: 30.5666\n",
      "Epoch 1845/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7671 - val_loss: 29.5727\n",
      "Epoch 1846/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6331 - val_loss: 29.9190\n",
      "Epoch 1847/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7792 - val_loss: 30.1022\n",
      "Epoch 1848/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4629 - val_loss: 30.2839\n",
      "Epoch 1849/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3633 - val_loss: 29.8003\n",
      "Epoch 1850/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.6073 - val_loss: 30.4806\n",
      "Epoch 1851/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7085 - val_loss: 29.4235\n",
      "Epoch 1852/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5503 - val_loss: 29.9682\n",
      "Epoch 1853/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.6805 - val_loss: 29.8034\n",
      "Epoch 1854/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4234 - val_loss: 29.6888\n",
      "Epoch 1855/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9772 - val_loss: 28.8644\n",
      "Epoch 1856/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.6351 - val_loss: 30.0115\n",
      "Epoch 1857/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3883 - val_loss: 29.9415\n",
      "Epoch 1858/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7734 - val_loss: 29.6619\n",
      "Epoch 1859/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3712 - val_loss: 30.2294\n",
      "Epoch 1860/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.5719 - val_loss: 29.9494\n",
      "Epoch 1861/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6673 - val_loss: 30.4177\n",
      "Epoch 1862/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2542 - val_loss: 29.7304\n",
      "Epoch 1863/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.5892 - val_loss: 29.5968\n",
      "Epoch 1864/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3723 - val_loss: 30.0298\n",
      "Epoch 1865/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5495 - val_loss: 29.5015\n",
      "Epoch 1866/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5636 - val_loss: 29.8513\n",
      "Epoch 1867/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3865 - val_loss: 29.2339\n",
      "Epoch 1868/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5694 - val_loss: 30.1022\n",
      "Epoch 1869/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2750 - val_loss: 29.5457\n",
      "Epoch 1870/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3927 - val_loss: 29.8790\n",
      "Epoch 1871/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3122 - val_loss: 30.0510\n",
      "Epoch 1872/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.0152 - val_loss: 29.8309\n",
      "Epoch 1873/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.6059 - val_loss: 29.6317\n",
      "Epoch 1874/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4151 - val_loss: 29.6870\n",
      "Epoch 1875/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3739 - val_loss: 30.3222\n",
      "Epoch 1876/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5730 - val_loss: 29.6718\n",
      "Epoch 1877/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1089 - val_loss: 29.9094\n",
      "Epoch 1878/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3459 - val_loss: 29.0937\n",
      "Epoch 1879/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5549 - val_loss: 30.3586\n",
      "Epoch 1880/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3660 - val_loss: 29.4357\n",
      "Epoch 1881/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7023 - val_loss: 29.6180\n",
      "Epoch 1882/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3623 - val_loss: 30.3891\n",
      "Epoch 1883/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6169 - val_loss: 29.7298\n",
      "Epoch 1884/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.4624 - val_loss: 29.9624\n",
      "Epoch 1885/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2954 - val_loss: 29.6379\n",
      "Epoch 1886/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9636 - val_loss: 30.1017\n",
      "Epoch 1887/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.9275 - val_loss: 30.0009\n",
      "Epoch 1888/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4960 - val_loss: 30.5176\n",
      "Epoch 1889/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8846 - val_loss: 29.7740\n",
      "Epoch 1890/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4333 - val_loss: 29.8880\n",
      "Epoch 1891/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8564 - val_loss: 29.7754\n",
      "Epoch 1892/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2976 - val_loss: 29.8151\n",
      "Epoch 1893/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.4635 - val_loss: 29.9738\n",
      "Epoch 1894/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5068 - val_loss: 30.0278\n",
      "Epoch 1895/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1761 - val_loss: 29.4295\n",
      "Epoch 1896/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.4525 - val_loss: 29.3305\n",
      "Epoch 1897/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5463 - val_loss: 29.7827\n",
      "Epoch 1898/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4582 - val_loss: 30.3158\n",
      "Epoch 1899/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4068 - val_loss: 30.2601\n",
      "Epoch 1900/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1936 - val_loss: 29.1192\n",
      "Epoch 1901/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2498 - val_loss: 30.3920\n",
      "Epoch 1902/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3760 - val_loss: 29.7022\n",
      "Epoch 1903/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4226 - val_loss: 29.8804\n",
      "Epoch 1904/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3806 - val_loss: 30.0129\n",
      "Epoch 1905/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6238 - val_loss: 30.5837\n",
      "Epoch 1906/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2673 - val_loss: 30.0617\n",
      "Epoch 1907/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5646 - val_loss: 29.9860\n",
      "Epoch 1908/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3219 - val_loss: 30.3237\n",
      "Epoch 1909/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5238 - val_loss: 29.9081\n",
      "Epoch 1910/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2783 - val_loss: 30.1822\n",
      "Epoch 1911/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3877 - val_loss: 29.6385\n",
      "Epoch 1912/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3132 - val_loss: 30.0780\n",
      "Epoch 1913/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.6498 - val_loss: 29.5249\n",
      "Epoch 1914/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.7403 - val_loss: 30.6864\n",
      "Epoch 1915/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5875 - val_loss: 30.1454\n",
      "Epoch 1916/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3659 - val_loss: 30.6153\n",
      "Epoch 1917/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3789 - val_loss: 30.1865\n",
      "Epoch 1918/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3249 - val_loss: 30.1145\n",
      "Epoch 1919/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2589 - val_loss: 29.6460\n",
      "Epoch 1920/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.4005 - val_loss: 29.9643\n",
      "Epoch 1921/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3499 - val_loss: 29.7464\n",
      "Epoch 1922/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2254 - val_loss: 29.8430\n",
      "Epoch 1923/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0077 - val_loss: 29.4740\n",
      "Epoch 1924/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6301 - val_loss: 29.5860\n",
      "Epoch 1925/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4207 - val_loss: 29.5383\n",
      "Epoch 1926/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3827 - val_loss: 29.3430\n",
      "Epoch 1927/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3505 - val_loss: 30.1299\n",
      "Epoch 1928/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3259 - val_loss: 29.1884\n",
      "Epoch 1929/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9630 - val_loss: 30.3282\n",
      "Epoch 1930/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1611 - val_loss: 29.6240\n",
      "Epoch 1931/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4162 - val_loss: 29.5885\n",
      "Epoch 1932/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1592 - val_loss: 29.6535\n",
      "Epoch 1933/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4128 - val_loss: 30.3012\n",
      "Epoch 1934/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3869 - val_loss: 30.2157\n",
      "Epoch 1935/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4398 - val_loss: 29.8428\n",
      "Epoch 1936/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1894 - val_loss: 29.7224\n",
      "Epoch 1937/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4351 - val_loss: 29.6618\n",
      "Epoch 1938/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3083 - val_loss: 29.5614\n",
      "Epoch 1939/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2389 - val_loss: 30.1968\n",
      "Epoch 1940/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3640 - val_loss: 28.7183\n",
      "Epoch 1941/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3594 - val_loss: 30.0986\n",
      "Epoch 1942/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1438 - val_loss: 29.7027\n",
      "Epoch 1943/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6710 - val_loss: 29.5895\n",
      "Epoch 1944/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4470 - val_loss: 29.6539\n",
      "Epoch 1945/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3202 - val_loss: 29.9129\n",
      "Epoch 1946/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.6623 - val_loss: 29.9550\n",
      "Epoch 1947/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4328 - val_loss: 29.9013\n",
      "Epoch 1948/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4206 - val_loss: 30.6657\n",
      "Epoch 1949/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2789 - val_loss: 30.3466\n",
      "Epoch 1950/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5498 - val_loss: 30.1666\n",
      "Epoch 1951/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5207 - val_loss: 30.6234\n",
      "Epoch 1952/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4282 - val_loss: 30.5020\n",
      "Epoch 1953/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3354 - val_loss: 30.1528\n",
      "Epoch 1954/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3768 - val_loss: 29.7565\n",
      "Epoch 1955/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4923 - val_loss: 28.8109\n",
      "Epoch 1956/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1571 - val_loss: 30.2196\n",
      "Epoch 1957/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.8122 - val_loss: 29.8849\n",
      "Epoch 1958/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0516 - val_loss: 30.6576\n",
      "Epoch 1959/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5446 - val_loss: 30.1006\n",
      "Epoch 1960/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0443 - val_loss: 29.9012\n",
      "Epoch 1961/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1505 - val_loss: 30.3432\n",
      "Epoch 1962/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1709 - val_loss: 29.6903\n",
      "Epoch 1963/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4813 - val_loss: 29.3832\n",
      "Epoch 1964/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0309 - val_loss: 29.9511\n",
      "Epoch 1965/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1364 - val_loss: 29.4561\n",
      "Epoch 1966/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0704 - val_loss: 29.8014\n",
      "Epoch 1967/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3682 - val_loss: 30.8895\n",
      "Epoch 1968/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3301 - val_loss: 29.8369\n",
      "Epoch 1969/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0412 - val_loss: 29.8919\n",
      "Epoch 1970/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9873 - val_loss: 29.7445\n",
      "Epoch 1971/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.3675 - val_loss: 29.5559\n",
      "Epoch 1972/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5308 - val_loss: 30.0458\n",
      "Epoch 1973/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.4191 - val_loss: 29.7838\n",
      "Epoch 1974/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2124 - val_loss: 29.9291\n",
      "Epoch 1975/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.1836 - val_loss: 29.6675\n",
      "Epoch 1976/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.7972 - val_loss: 30.0885\n",
      "Epoch 1977/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2163 - val_loss: 29.4900\n",
      "Epoch 1978/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3186 - val_loss: 29.8176\n",
      "Epoch 1979/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2629 - val_loss: 29.5871\n",
      "Epoch 1980/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3804 - val_loss: 30.5648\n",
      "Epoch 1981/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1165 - val_loss: 30.1302\n",
      "Epoch 1982/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0247 - val_loss: 30.4996\n",
      "Epoch 1983/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3679 - val_loss: 30.0977\n",
      "Epoch 1984/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.0637 - val_loss: 29.3241\n",
      "Epoch 1985/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1913 - val_loss: 29.2125\n",
      "Epoch 1986/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1599 - val_loss: 29.6246\n",
      "Epoch 1987/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.5014 - val_loss: 29.9937\n",
      "Epoch 1988/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2110 - val_loss: 30.0104\n",
      "Epoch 1989/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0648 - val_loss: 30.7018\n",
      "Epoch 1990/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0840 - val_loss: 30.2366\n",
      "Epoch 1991/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1584 - val_loss: 29.5677\n",
      "Epoch 1992/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.1491 - val_loss: 30.0920\n",
      "Epoch 1993/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0789 - val_loss: 29.8304\n",
      "Epoch 1994/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0089 - val_loss: 30.5641\n",
      "Epoch 1995/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.4085 - val_loss: 29.3100\n",
      "Epoch 1996/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0201 - val_loss: 29.3597\n",
      "Epoch 1997/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0954 - val_loss: 29.3670\n",
      "Epoch 1998/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4162 - val_loss: 29.4898\n",
      "Epoch 1999/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9789 - val_loss: 29.8095\n",
      "Epoch 2000/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2891 - val_loss: 29.5451\n",
      "Epoch 2001/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3462 - val_loss: 30.3791\n",
      "Epoch 2002/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1578 - val_loss: 29.8460\n",
      "Epoch 2003/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1017 - val_loss: 29.8441\n",
      "Epoch 2004/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2248 - val_loss: 30.2066\n",
      "Epoch 2005/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2221 - val_loss: 29.8093\n",
      "Epoch 2006/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.3117 - val_loss: 29.8826\n",
      "Epoch 2007/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1505 - val_loss: 30.5319\n",
      "Epoch 2008/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0837 - val_loss: 29.8146\n",
      "Epoch 2009/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2642 - val_loss: 29.6826\n",
      "Epoch 2010/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8226 - val_loss: 31.0929\n",
      "Epoch 2011/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1772 - val_loss: 29.5725\n",
      "Epoch 2012/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9687 - val_loss: 30.0816\n",
      "Epoch 2013/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9229 - val_loss: 29.8651\n",
      "Epoch 2014/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0313 - val_loss: 29.8396\n",
      "Epoch 2015/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0309 - val_loss: 29.3779\n",
      "Epoch 2016/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2208 - val_loss: 29.6324\n",
      "Epoch 2017/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0393 - val_loss: 30.5326\n",
      "Epoch 2018/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9131 - val_loss: 29.9183\n",
      "Epoch 2019/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2167 - val_loss: 29.8552\n",
      "Epoch 2020/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2474 - val_loss: 30.3343\n",
      "Epoch 2021/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8232 - val_loss: 29.4401\n",
      "Epoch 2022/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4702 - val_loss: 30.4588\n",
      "Epoch 2023/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1530 - val_loss: 29.8638\n",
      "Epoch 2024/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9604 - val_loss: 29.8212\n",
      "Epoch 2025/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0305 - val_loss: 29.9340\n",
      "Epoch 2026/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1591 - val_loss: 29.2320\n",
      "Epoch 2027/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2181 - val_loss: 30.0775\n",
      "Epoch 2028/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2557 - val_loss: 29.7676\n",
      "Epoch 2029/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9506 - val_loss: 29.6804\n",
      "Epoch 2030/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2868 - val_loss: 30.3375\n",
      "Epoch 2031/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0175 - val_loss: 30.4416\n",
      "Epoch 2032/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2890 - val_loss: 29.7080\n",
      "Epoch 2033/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1245 - val_loss: 29.9540\n",
      "Epoch 2034/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0378 - val_loss: 30.9946\n",
      "Epoch 2035/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9528 - val_loss: 29.4532\n",
      "Epoch 2036/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2448 - val_loss: 30.6890\n",
      "Epoch 2037/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9305 - val_loss: 29.4203\n",
      "Epoch 2038/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8501 - val_loss: 29.5110\n",
      "Epoch 2039/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0502 - val_loss: 30.3712\n",
      "Epoch 2040/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8682 - val_loss: 29.7616\n",
      "Epoch 2041/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2090 - val_loss: 29.6076\n",
      "Epoch 2042/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8058 - val_loss: 30.1812\n",
      "Epoch 2043/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1607 - val_loss: 29.6623\n",
      "Epoch 2044/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.7571 - val_loss: 29.4689\n",
      "Epoch 2045/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0943 - val_loss: 29.9064\n",
      "Epoch 2046/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9086 - val_loss: 29.9730\n",
      "Epoch 2047/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8898 - val_loss: 30.2546\n",
      "Epoch 2048/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8841 - val_loss: 29.6402\n",
      "Epoch 2049/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4965 - val_loss: 29.7298\n",
      "Epoch 2050/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0578 - val_loss: 30.2994\n",
      "Epoch 2051/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.1198 - val_loss: 29.5183\n",
      "Epoch 2052/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2830 - val_loss: 30.2019\n",
      "Epoch 2053/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.0078 - val_loss: 29.3681\n",
      "Epoch 2054/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8652 - val_loss: 29.8833\n",
      "Epoch 2055/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6704 - val_loss: 29.9462\n",
      "Epoch 2056/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.0388 - val_loss: 30.4332\n",
      "Epoch 2057/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2340 - val_loss: 29.8769\n",
      "Epoch 2058/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2417 - val_loss: 30.2802\n",
      "Epoch 2059/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.7144 - val_loss: 30.0457\n",
      "Epoch 2060/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8442 - val_loss: 29.6975\n",
      "Epoch 2061/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1234 - val_loss: 30.1540\n",
      "Epoch 2062/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.4097 - val_loss: 29.5172\n",
      "Epoch 2063/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8407 - val_loss: 29.1115\n",
      "Epoch 2064/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9996 - val_loss: 29.6537\n",
      "Epoch 2065/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2079 - val_loss: 30.5507\n",
      "Epoch 2066/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.2427 - val_loss: 30.6001\n",
      "Epoch 2067/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7969 - val_loss: 29.3356\n",
      "Epoch 2068/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2357 - val_loss: 29.5890\n",
      "Epoch 2069/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7897 - val_loss: 29.8185\n",
      "Epoch 2070/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1490 - val_loss: 29.8993\n",
      "Epoch 2071/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9317 - val_loss: 29.3313\n",
      "Epoch 2072/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8003 - val_loss: 29.5951\n",
      "Epoch 2073/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9442 - val_loss: 30.0409\n",
      "Epoch 2074/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1184 - val_loss: 30.2449\n",
      "Epoch 2075/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0356 - val_loss: 29.7382\n",
      "Epoch 2076/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9497 - val_loss: 29.2781\n",
      "Epoch 2077/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8975 - val_loss: 30.1663\n",
      "Epoch 2078/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0969 - val_loss: 29.6397\n",
      "Epoch 2079/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8206 - val_loss: 30.5615\n",
      "Epoch 2080/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8782 - val_loss: 29.7977\n",
      "Epoch 2081/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9954 - val_loss: 30.2569\n",
      "Epoch 2082/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.7007 - val_loss: 29.8641\n",
      "Epoch 2083/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8075 - val_loss: 29.5754\n",
      "Epoch 2084/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0317 - val_loss: 30.3421\n",
      "Epoch 2085/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7522 - val_loss: 29.9935\n",
      "Epoch 2086/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.2759 - val_loss: 30.1151\n",
      "Epoch 2087/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8832 - val_loss: 30.0480\n",
      "Epoch 2088/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9440 - val_loss: 29.6624\n",
      "Epoch 2089/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0838 - val_loss: 29.4139\n",
      "Epoch 2090/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0836 - val_loss: 30.0797\n",
      "Epoch 2091/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8352 - val_loss: 29.5787\n",
      "Epoch 2092/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8390 - val_loss: 30.3427\n",
      "Epoch 2093/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0552 - val_loss: 29.8958\n",
      "Epoch 2094/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7738 - val_loss: 29.8049\n",
      "Epoch 2095/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1704 - val_loss: 29.5232\n",
      "Epoch 2096/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7460 - val_loss: 29.1015\n",
      "Epoch 2097/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8528 - val_loss: 30.1695\n",
      "Epoch 2098/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7871 - val_loss: 30.6535\n",
      "Epoch 2099/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0111 - val_loss: 30.1805\n",
      "Epoch 2100/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8056 - val_loss: 30.1642\n",
      "Epoch 2101/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0927 - val_loss: 30.2451\n",
      "Epoch 2102/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.9323 - val_loss: 31.0130\n",
      "Epoch 2103/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8850 - val_loss: 29.7671\n",
      "Epoch 2104/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8655 - val_loss: 30.4527\n",
      "Epoch 2105/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8100 - val_loss: 30.1167\n",
      "Epoch 2106/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6926 - val_loss: 29.5484\n",
      "Epoch 2107/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0502 - val_loss: 29.7642\n",
      "Epoch 2108/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6810 - val_loss: 29.9705\n",
      "Epoch 2109/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1189 - val_loss: 30.4625\n",
      "Epoch 2110/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.1489 - val_loss: 30.3022\n",
      "Epoch 2111/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.9891 - val_loss: 29.1154\n",
      "Epoch 2112/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7757 - val_loss: 29.7089\n",
      "Epoch 2113/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0343 - val_loss: 29.8343\n",
      "Epoch 2114/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0057 - val_loss: 29.5926\n",
      "Epoch 2115/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8784 - val_loss: 29.7998\n",
      "Epoch 2116/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7018 - val_loss: 30.2557\n",
      "Epoch 2117/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7231 - val_loss: 29.1511\n",
      "Epoch 2118/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6303 - val_loss: 29.1191\n",
      "Epoch 2119/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 18.1256 - val_loss: 29.7102\n",
      "Epoch 2120/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.7752 - val_loss: 29.8842\n",
      "Epoch 2121/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.6594 - val_loss: 29.9370\n",
      "Epoch 2122/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1003 - val_loss: 30.4485\n",
      "Epoch 2123/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.1199 - val_loss: 30.3317\n",
      "Epoch 2124/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7850 - val_loss: 30.1810\n",
      "Epoch 2125/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6783 - val_loss: 29.9473\n",
      "Epoch 2126/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0390 - val_loss: 29.9836\n",
      "Epoch 2127/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8480 - val_loss: 29.3709\n",
      "Epoch 2128/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8463 - val_loss: 29.0104\n",
      "Epoch 2129/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8616 - val_loss: 30.0536\n",
      "Epoch 2130/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.8073 - val_loss: 29.7818\n",
      "Epoch 2131/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6747 - val_loss: 29.5119\n",
      "Epoch 2132/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.5952 - val_loss: 30.0166\n",
      "Epoch 2133/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.6954 - val_loss: 29.4026\n",
      "Epoch 2134/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8215 - val_loss: 30.2634\n",
      "Epoch 2135/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0418 - val_loss: 29.8460\n",
      "Epoch 2136/50000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18.1061 - val_loss: 30.4473\n",
      "Epoch 2137/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.8546 - val_loss: 29.5222\n",
      "Epoch 2138/50000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.7028 - val_loss: 29.5154\n",
      "Epoch 2139/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.7224 - val_loss: 29.7329\n",
      "Epoch 2140/50000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.6062 - val_loss: 30.0794\n",
      "CPU times: user 3min 45s, sys: 15.1 s, total: 4min\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp_epistemic = get_probabilistic_mlp(\n",
    "    shape=X_train_prep.shape, \n",
    "    hidden_type=\"variationaldense\", \n",
    "    output_type=\"deterministic\", \n",
    "    hidden_units=[32, 32], \n",
    "    activations=[\"sigmoid\", \"sigmoid\"],\n",
    "    loss=\"mean_squared_error\",\n",
    "    prior=prior,\n",
    "    posterior=posterior_mean_field,\n",
    "    optimizer=Adam(learning_rate=0.001)\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=200)\n",
    "hist_epistemic = mlp_epistemic.fit(\n",
    "    X_train_prep,\n",
    "    y_train, \n",
    "    epochs=50000, \n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "n_preds = 100\n",
    "y_epistemic_train = np.stack([mlp_epistemic(X_train_prep) for _ in range(n_preds)])\n",
    "y_epistemic_train_mean = np.mean(y_epistemic_train, axis=0) \n",
    "y_epistemic_train_std = np.std(y_epistemic_train, axis=0) \n",
    "y_epistemic = np.stack([mlp_epistemic(X_test_prep) for _ in range(n_preds)])\n",
    "y_epistemic_mean = np.mean(y_epistemic, axis=0) \n",
    "y_epistemic_std = np.std(y_epistemic, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "673be9cb-18b1-4625-afdd-1195ca5f5dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deterministic MLP</th>\n",
       "      <td>12.252170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aleatoric MLP</th>\n",
       "      <td>12.585811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epistemic MLP</th>\n",
       "      <td>11.475420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         MSE\n",
       "Deterministic MLP  12.252170\n",
       "Aleatoric MLP      12.585811\n",
       "Epistemic MLP      11.475420"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pd.DataFrame([\n",
    "    mean_squared_error(y_test, y_determ_pred),\n",
    "    mean_squared_error(y_test, y_aleatoric_mean.numpy()),\n",
    "    mean_squared_error(y_test, y_epistemic_mean)\n",
    "], index=[\"Deterministic MLP\", \"Aleatoric MLP\", \"Epistemic MLP\"],\n",
    "columns=[\"MSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-yemen",
   "metadata": {},
   "source": [
    "#### Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5f69a0-1d9f-4d7c-8e3d-79f0006a680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(\n",
    "    history,\n",
    "    plot_val = False,\n",
    "    title = None,\n",
    "    y_scale = \"linear\",\n",
    "    legend = None,\n",
    "    ax = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot loss as function of epochs.\n",
    "    \"\"\"\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    if isinstance(history, list):\n",
    "        lss = [\"-\", \"--\", \"-.\"]\n",
    "        for i, hist in enumerate(history):\n",
    "            ax.plot(hist.history[\"loss\"], label=history[i], ls=lss[i], color=f\"C0\")\n",
    "            if plot_val:\n",
    "                ax.plot(hist.history[\"val_loss\"], label=\"Validation Loss\", color=f\"C1\", ls=lss[i])\n",
    "    else:\n",
    "        ax.plot(history.history[\"loss\"], label=\"Loss\")\n",
    "        if plot_val:\n",
    "            ax.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_yscale(y_scale)\n",
    "    if legend is None:\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "organizational-network",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB/d0lEQVR4nO3dd3xW5fnH8c+VvScJe09BEARxK6h1o7iq/txaV9Vaa1u1ttUOW9tatVardW9xb60Dt6IyZA/ZEHYSsndy//44TyBgAknIk2d9369XXknOc8Z1niRXznXu+9y3OecQERERERGR8BIV6ABERERERESk46nYExERERERCUMq9kRERERERMKQij0REREREZEwpGJPREREREQkDKnYExERERERCUMq9iQomNkDZva7jl53p+36mFmZmUW3PUIR6Qit+Ts0M2dmgzohln6+Y8X4+1htYWa3mtnTgY4jGJjZhWb2RaDjEIHgyl+hzMzeNbML2rltp1zLhVPuUbEXhsxslZlVmlmpmRWZ2VdmdoWZternbWYTzCzP33E25Zy7wjn3p45c1/c+HNVkuzXOuRTnXH1bYvP9wTszu3On5ZN9yx/3fd/ihaPv4q3Wl6AafyYHtiUOkbby/Q3UmFmXnZbP9v2u9vN9/7iZ/bmFfTgzK/f97q4zszv35J/szn+HZvaJmf2kvftTYdSy1hSzvvfPmdkZTZbFNP39EAmECMpftb7rtVIz+97M7jWz7u3dZ0czs5vM7LNmlnfx/Xz2bus+nXPHOeeeaOXxO+RaLpKp2Atfk5xzqUBf4HbgBuCRzjhwsN0l7yDLgTN3Orfzge/bsI/nnXMpQA7wBfCKmVkHxijSnJXA2Y3fmNlIILGN+9jH97t7JPB/wKUdF54EgULgjx1xpzxM878ETiTkr+d912tZwClAN2BmEBV8TwEHmVn/nZafBcxzzs1v7Y7Mo9qjk+kND3POuWLn3BvAmcAFjXdgzCzezO4wszVmtsm8rpGJZpYMvAv08N0JKzOzHmYWZWY3mtlyMyswsxfMLMu3r8a7x5eY2RrgI19r2JdmdpevJWuFmR3kW77WzDZbkyb8pnfmGlsWzex633obzOyiFtbtYmZv+Y5RaGaf+2J9CugDvOk7h1/vfJfbzLLM7DEzW29mW83stV28lRuBecAxjdsCBwFvtONnUgs8gZfQs9u6vUgbPYV3Y6LRBcCT7dmRc24x8Dnwgzu5ZvYHM/u37+tY3930v/u+TzSzKjPLbPp3aGa3AYcC9/r+Tu9tssujzGyp72/zvtbeGPHt+4rmtjWzaF/eyzezFcAJO22bbmaP+HLOOjP7c2MB1CSn/dvMis1ssZkd2YZtv/Ade6uZrTSz45ps29/MPjXvzv4HwM4tGQeY1xugyMzmmNmEJq99YmZ/8sVWambv2/aWkMa78UW+97el3gT/A2qAc1t4T9PN7Ekz22Jmq83st+a7YNsp1xcCt/py9H/M66pV5nu9m5nd7Tv/xWY2psn+G/+3lJrZQjM7pYU4JfJETP5yztU65xbgXa9tAa5vEt+J5rVoNvYMGtXktVVm9kszm+vLTc+bWYLvtWavkXyv9TCzl31/1yvN7GctxJUHfASct9NL5wNP+N6Xt3z72er7uleT+D4xs9vM7EugAhhgTVpEzWygmX1k3rVlvpk9Y2YZvtdacy3Xw8ze8J3fMjO7tMmxbzXvevVJX35ZYGbjmrweEblHxV6EcM59C+ThJSaAvwFDgNHAIKAn8HvnXDlwHLDe10ye4pxbD/wMmAwcDvQAtgL37XSYw4G98BVEwP7AXLyC5llgCrCf73jn4iXIlBZC7gak++K6BLjPzDKbWe9633nlAF2B33in684D1uC1cKY45/7ezLZPAUnACCAXuKuFWBo9yfZ/OmcBrwPVu9nmB8wsHrgQyHPO5bd1e5E2+hpIM7O9zCs+zgTa1e3RzIbj5ZDvmnn5U2CC7+v98G6QHO77/kBgiXNua9MNnHM34118Xe37O726ycsn+vazD/BjtueV1mhp20t9r40BxgGn77TdE0AdXo4aAxwNNO2itT+wAq8YuwWvdT6rDdsu8W37d+CRJheAzwIzfa/9Ce+CFgAz6wm8DfwZ787/L4GXzSynyb7/D7gIL4/F+dYBOMz3OcP3/k5r7s0CHPA74BYzi23m9X/j5eMBeD/T833H2/l9yQVu8y37MfBb3zlVA9OAWb7vXwKadotfjvd7lQ78AXjagqdVQwIr4vKXr3vi675YMbN9gUeBy/Gup/4LvOG7lmj0Y+BYoD8wCu8aA1q4RvIVfG8Cc/Cus44Efm5mLcX5BE2KPTMbinf9+BxeLfEYXk+yPkAlcO9O258HXAakAqt3es2Av+JdW+4F9AZu9b0XrbmWe853jj3wcvpfrMmNOOAkvOvPDLwb9E1ji4jco2IvsqwHsnwXGJcC1znnCp1zpcBf8AqYllwO3Oycy3POVeP9IZ5uO3bZudU5V+6cq/R9v9I595gvcT2P9wf8R+dctXPufbw7yS09xFzrW7fWOfcOUAYMbWG97kBf37qfO+fc7t4I3x/zccAVzrmtvm0/3c1mrwITzCwd72KnrXcXf2xmRcBaYCxe8SzSGRrvjv8IWAysa+P2s8xsK97FwcN4/9h3Ng0YbGbZeEXGI0BP3w2dw/EuptridudckXNuDfAx3oXFnm77Y+Bu59xa51wh3gUGAGbWFS8n/NyXxzbj3QBqmhc3+7avdc49j1e8ndDKbVc75x7y5cMn8PJWVzPrg3dR+DtfbvwM731udC7wjnPuHedcg3PuA2AGcHyTdR5zzn3vy70vtPG9AsDXA2QLOxaoNLnAvsk5V+qcWwX8kx3v8q93zv3bOVfXJP+/6pyb6ZyrwsudVc65J5v8P9jWsuece9E5t953fs8DS4HxbT0HCVuRlr/Ad73m+/pS4L/OuW+cc/W+Z92qgQOarH+P72+oEO88G4/X0jXSfkCOc+6Pzrka59wK4CFavg58FS9fHeT7/nzgXefcFudcgXPuZedche968ja2F8qNHnfOLfDliNqmLzjnljnnPvDlvy14N4J23r5ZZtYbOAS4wTlX5ZybjfczbpqfvvDlz3q836V9mhw7InKP+tZHlp54z2bk4LVozWzSs8CAXT2v0Rd41cwamiyrx7tT1GjtTttsavJ1JYBzbudlLbXsFTjn6pp8X9HCuv/AKzzf953Lg86521vYZ1O9gcKd79TtinOu0szexne32jn3pTXpitUKLzjnmu0mJeJnT+F16etP+7pA7eucW7arFXx/HzPw/kkfhvcPfzRwsG/Zv9t4zI1Nvm7p77+t2/ZgxzzV9A5zXyAW2NAkL0bttP66nW4mrfbtszXbbovJOVfhWy8Fr6Vrq/N6VTTdb+8mcZ1hZpOavB6LdwG5u/Ntq9/iXQg/1WRZF7zWwqbv1Wq8/yeNds798MP832LuN7PzgV8A/XyLGt8XEYi8/AXbr9fAywEXmNk1TV6Pw8s9LR2v8bWWrpH64j2uU9Rku2i8lsof8OWsF4HzzWwacA7e3yxmloR3c+tYoLEHVqqZRbvtg6g0lyPwbZ8L3IPXwpaKlztbe23WA+9arrTJstV4PTca7fzeJJhZjHOuLlJyj4q9CGFm++Eljy+AfLx/tiOcc83dIWuuZWwtcLFz7stm9t1vF9v5le8P/HrgejMbAXxsZtOdc1N3E89avFbODOdcURsO+SRe3/U/tDdmkc7mnFttZivxWoMu8eOhPgWOwGu1me77/hi8O6U/GM2tMTw/xrOzDWwvosDrctRoLd7d8i473WhqqqeZWZOCrw9et6DWbLurmDLNLLlJwdeH7e/LWuAp51x7BpVo03vrnPvAzJYBP22yOB+vdaAvsLBJfE3/d7T7Z2hmffFaFI4Epjnn6s1sNt4NSJGIy1++LpaTgA99i9YCtznnbmt5q+a1dI3k2+dK59zgNuzuCeA14BW8ouwt3/Lr8Xpe7e+c22hmo/G6yjb9G97V+/RX3+ujnHMFZjaZHbta7mrbxh5rqU0Kvp3zU7MiKfeoG2eYM7M0MzsRr7/y0865ec65Brxf8Lt8d1Qws55N+mpvArJ93RUbPQDc5vvjwMxyzOzkzjuT5pn30PIgX9fUErzWxsY7SZvwnjH5AefcBryBaP5j3sPFsWZ2WHPr7uRTvK4ku7rLF29mCU0+9HcmweAS4IidWpCait7p9zauHcf4FK97z0LnXA3wCV63wJW+7jnNafHv1A9eAH5mZr18zwDf2PiCLye8D/zTlzejzBs4oGl3olzf9rHmTVWwF14Xy9Zs2yzn3Gq8bpl/MLM4MzsE70Kv0dPAJDM7xrwBZhLMG8SqV7M73NEWoIG2vb83A79uEl893vt2m5ml+v4H/IJ2PjfVjGS8i7ktAOYNxtXmodwl7IV9/vLllb3wnkHrxvbnWh8CrjCz/c2TbGYnmFlqK/bZ0jXSt0CJmd1g3gA00Wa2t69hoCWfA0XAg8AU33sEXuFXiTcQVBbe88xtkYr3qE6Rec8o/2qn13d1LbcW+Ar4q+/nPgrvd+WZVhw3YnKPLkLD15tmVop39+ZmvKTR9IH6G4BlwNdmVoJ3B2kobBux6jlghXkjOPUA/oV3B/t9336/xnsoP9AG48Vehtfn/j/OuU98r/0V+K3vHH7ZzLbn4d2xXoz3LM7Pd3cw55nq6xffkjK8xNf4cUTrTkXEf5xzy51zM3axyo3s+Hv7UTsO8xXesOiNd8EXAlW0fFccvNxyunmjuN3TjmO2xUPAe3iDEszCu0Pd1Pl43aMW4nUjegnveZdG3+DlnHy8bl6nO+cKWrntrvwfXj4txLtQ2tZVzXcxczLewApb8HL6r2jF/2/nXIUvzi99efCAVmzzJd6FYFPXAOV4g7B8gTegzKO7PatWcM4txHsGcBreRd1I4Ac9SCSyhXn+OtPMyvAKqTeAAmCs8wbHw3fel+K1dm3Fu3a7sJX7bvYayXcTZxJeV9WVeDntYbyBSprl69HwJF4rf9PutHfjvW/5eNeG/2tlbI3+AOwLFOMNRrVzXt7dtdzZeN0w1+M9W3iL855t3qVIyj3mdj+WhYiISEQzswuBnzjnDgl0LCIiIq2llj0REREREZEwpGJPREREREQkDKkbp4iIiIiISBhSy56IiIiIiEgYUrEnIiIiIiIShkJ6UvUuXbq4fv36BToMEelAM2fOzHfO5QQ6jj2h3CQSfsIhN4Hyk0g42lV+Culir1+/fsyYsatpV0Qk1JjZ6kDHsKeUm0TCT6jnJjObBEwaNGiQ8pNImNlVflI3ThEREZEw55x70zl3WXp6i/Nmi0gYUrEnIiIiIiIShlTsiYh0EDObZGYPFhcXBzoUERERkdB+Zk8EoLa2lry8PKqqqgIdirRBQkICvXr1IjY2NtChdBjn3JvAm+PGjbs00LFIcFB+Cj3hmJtEdqbcFJrak59U7EnIy8vLIzU1lX79+mFmgQ5HWsE5R0FBAXl5efTv3z/Q4Yj4jfJTaFFukkih3BR62puf1I1TQl5VVRXZ2dlKViHEzMjOztYdRQl7yk+hRblJIoVyU+hpb34KyWJPz8XIzpSsQo9+ZhIp9LseWvTzkkih3/XQ056fWUgWexo+WIJNSkpKoEMQEWmW8pOIBCPlps4RksWeiIiIiLSeekWJRKaIKPY+XryZ9xdsDHQYEmFmz57NAQccwKhRozjllFPYunUrAPfccw/Dhw9n1KhRnHXWWQB8+umnjB49mtGjRzNmzBhKS0sDGbp0kjUFFTzzzWqKKmoCHYpEGOWnyNPWXlGvzMrj25WFfo5KZEfKTR0vIoq9R75YyX8+WR7oMCTCnH/++fztb39j7ty5jBw5kj/84Q8A3H777Xz33XfMnTuXBx54AIA77riD++67j9mzZ/P555+TmJgYyNClkyxYX8zNr85nQ7EGg5DOpfwku/OXdxbx6nfrAh2GRBjlpo4XEVMvZCXHsXZrRaDDkE7whzcXsHB9SYfuc3iPNG6ZNKJN2xQXF1NUVMThhx8OwAUXXMAZZ5wBwKhRozjnnHOYPHkykydPBuDggw/mF7/4Beeccw6nnnoqvXr16tBzkOAUFeU9aF3f4AIciXQG5ScJJbmxFVC5NdBhSCdQbgpvEdGyl5UcR2GZuklJcHj77be56qqrmDlzJmPHjqWuro4bb7yRhx9+mMrKSg444AAWL14c6DClE0T7RtVqcCr2JDgoP0mj56qu4phNDwU6DBFAuWlPRETLXnZyHKXVdVTX1RMfEx3ocMSP2noXyV/S09PJzMzk888/59BDD+Wpp57i8MMPp6GhgbVr1zJx4kQOOeQQnn32WcrKyigoKGDkyJGMHDmSadOmsXjxYoYNGxbo0xA/i1bLXkRRfpJQUm0JRNepV1QkUG4KbxFR7GUmxwFQVFFL1zQVe9LxKioqdug+8Itf/IInnniCK664goqKCgYMGMBjjz1GfX095557LsXFxTjnuO6668jIyOB3v/sdH3/8MdHR0QwfPpzjjjsugGcjnaWxG6da9sSflJ+kPWqiEomprwx0GBLGlJs6R0QUe9m+Yq+grIauaQkBjkbCUUNDQ7PLv/766x8s++KLL36w7N///neHxyTBr7EbZ33zvz4iHUL5SdqjNiqB2HoNHiX+o9zUOSLmmT2AwnI9tyciwSPKl4HVjVNEgk1ddCKxDWrZEwl1IVnstXVi0OwUX8teebU/wxIRaZMYX7WnYk9Egk1ddCJxTtdNIqEuJIu9tk4MmpnkFXtb1bInIkEkurFlT8/siUiQaYhJIt6pG6dIqAvJYq+tMpLiMFM3ThEJLlGNUy+oZU9E/KytvaIaYhNJULEnEvIiotiLjjIyk+IoULEnIkFEUy+ISGdpa68oF5NEItXUagQpkZAWEcUeeIO0bK1QsSciwaOxZU/dOEUk2Li4ZJKopqKmPtChiMgeiIxir2A5+8Suo6BMxZ50vAkTJvDee+/tsOzuu+/mpz/96S63mTFjBgDHH388RUVFP1jn1ltv5Y477tjlsV977TUWLly47fvf//73fPjhh22IvnmffPIJJ5544h7vR3atsWVP3TjFX5SfpL0sNol4q6WyStdO0vGUmzpPZBR7b17LleX36Zk98Yuzzz6bKVOm7LBsypQpnH322a3a/p133iEjI6Ndx945Yf3xj3/kqKOOate+pPNt68aplj3xE+UnaS+LTwagqrI0wJFIOFJu6jyRUeyl5JLRUKRunOIXp59+Om+99RbV1d4Q1atWrWL9+vUccsghXHnllYwbN44RI0Zwyy23NLt9v379yM/PB+C2225j6NChHHXUUSxZsmTbOg899BD77bcf++yzD6eddhoVFRV89dVXvPHGG/zqV79i9OjRLF++nAsvvJCXXnoJgKlTpzJmzBhGjhzJxRdfvC2+fv36ccstt7DvvvsycuRIFi9e3Opzfe655xg5ciR77703N9xwAwD19fVceOGF7L333owcOZK77roLgHvuuYfhw4czatQozjrrrDa+q5FhWzdOteyJnyg/KT+1V1ScV+xVV5QEOBIJR8pNnZebIqPYS84lra6QrRW16i4lHS47O5vx48fzv//9D/DuTJ155pmYGbfddhszZsxg7ty5fPrpp8ydO7fF/cycOZMpU6bw3Xff8corrzB9+vRtr5166qlMnz6dOXPmsNdee/HII49w0EEHcdJJJ/GPf/yD2bNnM3DgwG3rV1VVceGFF/L8888zb9486urquP/++7e93qVLF2bNmsWVV1652+4OjdavX88NN9zARx99xOzZs5k+fTqvvfYas2fPZt26dcyfP5958+Zx0UUXAXD77bfz3XffMXfuXB544IE2vaeRYls3TrXsiZ8oPyk/tVd0glfs1VSUBTgSCUfKTZ2Xm2I6ZC/BLiWXuIYK4hoqKa6sJTM5LtARib+8eyNsnNex++w2Eo67fZerNHZHOPnkk5kyZQqPPvooAC+88AIPPvggdXV1bNiwgYULFzJq1Khm9/H5559zyimnkJSUBMBJJ5207bX58+fz29/+lqKiIsrKyjjmmGN2Gc+SJUvo378/Q4YMAeCCCy7gvvvu4+c//zngJUCAsWPH8sorr+z+PQCmT5/OhAkTyMnJAeCcc87hs88+43e/+x0rVqzgmmuu4YQTTuDoo48GYNSoUZxzzjlMnjyZyZMnt+oYkSa6vpocttJQVxvoUKQzKD8Byk+hIiYhBYCaShV7YU+5CQjf3BQZLXspuQB0sWJNvyB+MXnyZKZOncqsWbOorKxk3333ZeXKldxxxx1MnTqVuXPncsIJJ1BVtes5i8zXrW9nF154Iffeey/z5s3jlltu2e1+3G5aiuLj4wGIjo6mrq5ul+vubp+ZmZnMmTOHCRMmcN999/GTn/wEgLfffpurrrqKmTNnMnbs2FYfJ5Ikr5nK9ISrSC5ZHuhQJIwpPyk/tUdjsVerYk/8RLmpc3JThLTsdQUgh2I9txfudnMXyV9SUlKYMGECF1988baHi0tKSkhOTiY9PZ1Nmzbx7rvvMmHChBb3cdhhh3HhhRdy4403UldXx5tvvsnll18OQGlpKd27d6e2tpZnnnmGnj17ApCamkpp6Q8fnh82bBirVq1i2bJlDBo0iKeeeorDDz98j85x//3359prryU/P5/MzEyee+45rrnmGvLz84mLi+O0005j4MCBXHjhhTQ0NLB27VomTpzIIYccwrPPPktZWVm7H6YOV1FR0QC4eg1tHhGUnwDlp1ARl+gVe/XV5QGORPxOuQkI39wUGcVestd02sWKKSirDnAwEq7OPvtsTj311G2jS+2zzz6MGTOGESNGMGDAAA4++OBdbr/vvvty5plnMnr0aPr27cuhhx667bU//elP7L///vTt25eRI0duS1JnnXUWl156Kffcc8+2h4sBEhISeOyxxzjjjDOoq6tjv/3244orrmjT+UydOpVevXpt+/7FF1/kr3/9KxMnTsQ5x/HHH8/JJ5/MnDlzuOiii2ho8Cbe/etf/0p9fT3nnnsuxcXFOOe47rrrdCHVDIv2UnCDU7En/qX8pPzUVnGJqQDUV6tlT/xHucn/ucl212QZzMaNG+ca59vYpZL1cOde3Fx7MUNPvJbzD+zn99ik8yxatIi99tor0GFIOzT3szOzmc65cQEKqUO0NjeVzHuXtJfP4u3xT3HC8Sftdn0JPcpPoSlccxO0Pj+VrV9EyoMH8NHw2zjix1d3QmTSmZSbQldb81NIPrNnZpPM7MHi4uLWbeBr2cuxYjaV7Lq/rohIZ4mK9rpx0qDnhUTEv9p67ZSUlAZAfZVa9kRCWUgWe865N51zl6Wnp7dug+hYSMyiT1wZm0rUjVNEgkNjN06nYk9E/Kyt105RCV43zoZqTaouEsoi45k9gJSudK8vVcueiASNqOhY74t6FXsiEmTiUqgnCqvWpOoioSwkW/baJSWHXCtis1r2wlIoP3saqfQz296N0zkVe+FMv+uhRT8vn6goKiyR6BoVe+FKv+uhpz0/swgq9rqS6YrYqJa9sJOQkEBBQYGSVghxzlFQUEBCQkKgQwmoqKjGlj2NxhmulJ9Ci3LTjiqjUoipUTfOcKTcFHram58ipxtnci6pdVsprqylqraehNjoQEckHaRXr17k5eWxZcuWQIcibZCQkLDD8MSRKDpGz+yFO+Wn0KPctF1VdCrxdSr2wpFyU2hqT36KnGIvJZfYhkqSqGJzSTV9spMCHZF0kNjYWPr37x/oMETabNszew1q2QtXyk8SympiUkmo1Gic4Ui5KXJEUDfOXMCbWH1TqbpyikjrmdlkM3vIzF43s6M7bMdRmnpBRIJXbVwqSQ0q9kRCWcQVezkUaUROEcHMHjWzzWY2f6flx5rZEjNbZmY3AjjnXnPOXQpcCJzZYUFENXbjVMueiASfhrg0kimnvkHPdYmEqsgp9pJ9xZ4Va649EQF4HDi26QIziwbuA44DhgNnm9nwJqv81vd6x/C17JlTsSciwcfFp5NGBWVV6n0gEqoip9hL7Q5Az+giNqtlTyTiOec+Awp3WjweWOacW+GcqwGmACeb52/Au865Wc3tz8wuM7MZZjaj1Q+8m7pxikjwssR0Uq2S4vLKQIciIu0UOcVeUjZExdI/vkTdOEWkJT2BtU2+z/MtuwY4CjjdzK5obkPn3IPOuXHOuXE5OTmtO5qvG6eKPREJRtFJGQCUFW8NbCAi0m6RMxpnVBSkdqN3dTFvqdgTkeZZM8ucc+4e4J4OP1pjsadunCIShOJTsgAoKykA+gY2GBFpl8hp2QNI7U5X26pn9kSkJXlA7ybf9wLW++1ovmLPNECLiAShhFSv2KsoKQhwJCLSXhFW7HWjiytgY3EVzmlkKRH5genAYDPrb2ZxwFnAG347WpSXgk3dOEUkCCWne8VeVenOjzeLSKiIrGIvrQdptQVU1tZTXFkb6GhEJIDM7DlgGjDUzPLM7BLnXB1wNfAesAh4wTm3wG9BaOoFEekkZjbJzB4sLi5u9TbJ6d7zx7VlatkTCVWR88weQGo34urLSKKKDcVVZCTFBToiEQkQ59zZLSx/B3inPfs0s0nApEGDBrVug8ZunHpmT0T8zDn3JvDmuHHjLm3tNtEpXbxty1XsiYSqyGrZS+0BQFfbyoZiDSMsIh3LOfemc+6y9PT01m3gm3pB3ThFJCglet04rVLdOEVCVWQVe2neXHvdrJD1RRqRU0QCbNtonA2BjUNEpDkxcVRaIjHVmnpBJFSFZLHXnn7nwLaJ1btFFbGxWMWeiARYVBQNGObUsiciwaksOp3YmqJAhyEi7RSSxV6bu0o1Su0GwKD4EtarG6eIBIF6ojX1gogEraqYdJLq2nhzXUSCRkgWe+0WnwpxqfSLK2GDunGKSBBoIEoteyIStGrjMkiuL9aUVSIhKrKKPYC07nSPLmJjiYo9EQm8eqIxPbMnIkGqLiGLdFdGZa16IIiEosgr9lK7kesKWF9UqbtUItKh2vM8cYOpZU9EglhSJllWytYKzU8sEooisNjrQXp9AdV1DUpcItKh2vM8cQPRRGmePREJUlFJ2aRZBVtLKwIdioi0QwQWe91Irs7HaNBceyIScPUWDRqgRUSCVGyqN7F66dYtAY5ERNoj8oq9tB5EuVoyKdMgLSIScA1EY2rZE5EgFZ+WA0Bl0aYARyIi7RF5xZ5v+oVuVqiWPREJOGdRKvZEJGglZXjFXlVJfoAjEZH2iMBirwcAPWOKyduqYk9EAqvBorEGDdAiIsEpKT0XgLqyggBHIiLtEYHFnteyNyypjLVb9bCxiARWg2nqBREJXjEp2QA0lKtlTyQURWyx1z+hlLWFatkTkcByFq2pF0QkeCV5xR6VWwMbh4i0S+QVe9GxkJxD7+itatkTkQ7Vnnn2vGJPz+yJSJCKS6KaOGKrCgMdiYi0Q+QVewCp3cm1rRRV1FJSpbn2RKRjtGeePRV7IhLsyqPTiK0pCnQYItIOkVnspfUgo8570HhtoVr3RCRwGixGk6qLSFCrjM0goa71PRZEJHhEZrGX2o2kam9yUD23JyIBFRWlYk9EglpNbDop9Sr2REJRhBZ7PYityieWOvL03J6IBJCzGKI0QIuI+Fl7niluVJ+QSborpbJGN6ZEQk2EFnveiJx948vUjVNEAqohKo4YFXsi4mfteaZ427aJ2WRYGVsravwQmYj4U2QWe2nexOojU8tZq4nVRSSAXHQsMdThnAt0KCIizbKkLDIoo7CsKtChiEgbRWax52vZG5Kklj0RCayGqDjiqKWuQcWeiASn2NQcos1RWqSJ1UVCTYQWe17L3oC4ItZurdAddRHpEO2aZy86jjjqqK1v8GNkIiLtF5/mTaxeUbwlwJGISFtFZrGXlAWxyfSJyqeqtoFNJdWBjkhEwkC75tmLjiPeaqmt000nEQlOiem5AFSr2BMJOZFZ7JlBZl9yGzYBsGJLWYADEpGIFR3vtew1qGVPRIJTcqZX7NWUqhunSKiJzGIPILMfaVXrAFiRXx7gYEQkUnndOGvVjVNEglZMsteNs6G8IMCRiEhbRW6xl9GXmOI1JMQaK1XsiUigNLbsqRuniASrpCwArLIwwIGISFtFbrGX2RerLWd0VoO6cYpI4MTEei176sYpIsEqPo06oomu2hroSESkjSK32MvoC8C+acVq2RORwImOJ8YaqK2tDXQkIiLNM6M8Ko3YmqJARyIibRS5xV6mV+ztlVDI2q2V1NTprrqIdD6LiQegrqYmwJGIiLSsMjadhNqiQIchIm0UucWer2Wvf0w+9Q2ONZpcXUQCoLHYq6+tDHAkIiItq4nLJKm+WHMTi4SYoCn2zGyymT1kZq+b2dF+P2B8CiR1oVu9N/2CunKKSCBsb9mrCnAkIiItq0/IJMOVUlpdF+hQRKQN/FrsmdmjZrbZzObvtPxYM1tiZsvM7EYA59xrzrlLgQuBM/0Z1zaZfUmvXg9orj0RCQyL9Yq9hlp14xSRIJaURaaVUVCmXCUSSvzdsvc4cGzTBWYWDdwHHAcMB842s+FNVvmt73X/y+hLbMlqspPj1LInInvMzCaZ2YPFxcWt3iaqsRtnnVr2RCR4RSdnk0Ep+aXKVSKhxK/FnnPuM2DnSVnGA8uccyucczXAFOBk8/wNeNc5N8ufcW2T2Q+K8xiUHa+J1UVkjznn3nTOXZaent7qbaJ8LXv16sYpIkEsLrULcVZPUZHm2hMJJYF4Zq8nsLbJ93m+ZdcARwGnm9kVLW1sZpeZ2Qwzm7Fly5Y9iyR7EDTUMTa9hBVbVOyJSOeLjUsAoFbFnogEsaSMXADKtm4OcCQi0haBKPasmWXOOXePc26sc+4K59wDLW3snHvQOTfOOTcuJydnzyLpMhiAveM3k19WTUmV5rkSkc4VE9fYslcd4EhERFqWlOFdc1UW7+GNdhHpVIEo9vKA3k2+7wWsD0AcXsseMMA2ALBKXTlFpJPFxScCUFerlj0RCV4xyV0AqC3ND3AkItIWgSj2pgODzay/mcUBZwFvBCAOSMqCpC50r/N6laorp4h0tlhfsadn9kQkqCVlA1BfXhDgQESkLfw99cJzwDRgqJnlmdklzrk64GrgPWAR8IJzboE/49ilLoNJLVuFGRqkRUQ6XVy898xefa26cYpIEEvKAsAqNECLSCiJ8efOnXNnt7D8HeCd9u7XzCYBkwYNGtTeXWyXPYio7/9Hr8xETb8gIp0uJj4ZAFdTEeBIRER2ISGdBozoKhV7IqEkEN0491h7hjdvUZfBUL6FvbOcJlYXkc4X63XjpLYysHGIiOxKVDSV0WnE1RYFOhIRaYOQLPY6VLY3IufY5HxW5pfjnAtwQCISUWK9lj0VeyIS7Gri0kmuL6G6rj7QoYhIK6nY6zIEgL1iN1FRU8/6Yg2SICKdyNeyF1WrbpwiEtzqE7LIpJTNJXrGWCRUqNjL7AtRsQwkD4CF60sCHJCIRJQYb4AWq1fLnogEuaQsMq2MTSW6MS4SKlTsRcdC91HkFM/DDBasLw50RCISosxskpk9WFzchjwSFUUV8UTVqdgTEf9pV37aSUxKNplWykYVeyIhIySLvY5IWDvocyDRG2YxJDuOBWrZE5F2au/gUdUWT3S9Lp5ExH86YnC7hPRuZFPCxiLdnBIJFSFZ7HXoaJwAfQ6AuiqOydrEgnVq2RORzlUblUCMunGKSJCLz+xOvNVRvHVzoEMRkVYKyWKvw/XeH4CDYr9nfXEVW8trAhyQiESSmqgEYtWyJyJBzlK7AVC9dUOAIxGR1lKxB5CSC1kDGVy9AEBdOUWkU9VFJRDToGJPRIJcilfs1Zeo2BMJFSr2GvU5kMyCWRgNGqRFRDpVXXQCcSr2RCTY+Vr2oso2BTgQEWktFXuN+h1MVGUhR6Rt4Ls1RYGORkQiSH1MErFOxZ6IBLmUrgDEVW7BORfgYESkNUKy2Ovw0TgBhhwLUTGcl/YdXyzLp6auoeP2LSKyCy4mkfiGal08iUhwi0+hJjqJbFdISWVdoKMRkVYIyWKvw0fjBEjKggET2b/yM8qqa/l2ZWHH7VtEZBdcbBKJVFFZWx/oUEREdqkmIYdcK9JceyIhIiSLPb8ZMZnE8jzGxqxi6mL1RxeRThKfQopVUlatO+UiEtwaUrqSo2JPJGSo2Gtq2AkQFctlmTOZumizulSJSOeITyOFSsoqawMdiYjILsWkdSeXrWws1tygIqFAxV5TiZkw4hSOLH+b+sLVLNygKRhExP+iEtKIs3oqKioCHYqIyC7FZ/Yg14pYV6SWPZFQoGJvZ0fdQnRUFDfHT+HRL1YFOhoRiQDRiWkAVJZtDXAkIiK7Fp3WjWSrJj+/INChiEgrqNjbWXov7OBrOd6mUTbndTaom4KI+FlsUgYANeWa41NEglx6LwCqCtcEOBARaQ0Ve8055DpqckdxR8x/eOX9jwMdjYiEudhkb2Th2vKiwAYiIrI7vmLPStYGOBARaY2QLPb8Ms9eU7EJxJ3zHBYTz1HzfsW079f55zgiIkB8Y7FXqZY9EQlyvmIvoXwD9Q0ayE4k2IVkseeXefZ2lt6LmNP+y9CoPBY991t15xQRv0lIzQSgvlKDQolIkEvpRoNF0418Nmn6BZGgF5LFXmdJGH4sxcPO5PyG1/jDf5+hoKw60CGJSBBrb6+DhOQMAJxa9kQk2EXHUJPYlR6Wz7oi3QgXCXYq9nYj/eS/05CUzVXl93HeQ1+Rr4JPRFrQ3l4HluCt76pL/RGWiEiHcum96GkFrNuqYk8k2KnY253EDOKOv52RtoIDt77Gj/87jY3F6rYgIh0oLgWAqBp14xSR4Beb1YceqGVPJBSo2GuNvU+DARO5OfppDi9+k588OZ2KmrpARyUi4SImjmriiKopC3QkIiK7FZPZm+5RW1lXqJwlEuxU7LWGGZzxOFEDJ3JL1MOM3fgiv3xxDg0ahUpEOkhFVDLRtbpwEpEQkN6LWOooLVgf6EhEZDdU7LVWYgb83/Mw+Gh+F/88C+bP5l9TlwY6KhEJE9VRScTU6pk9EQkB6b0BqNPE6iJBT8VeW0RFw6R/ER0bxxMZj/LA1AW8NVd3tURkz9XGpBBXp5Y9EQkBvrn2YsrWUVvfEOBgRGRXQrLY8/uk6ruS1gObdDf9KufzdNr93PjiTOblabh0Edkz1XHpJNWrZU9EQoCvZa+H20KeRuQUCWohWex1yqTqu7L3aXD8HexX8w3/iv0Plz/xtSYWFZE9Uh+fSbor0V1yEQl+CWnUxmfR1zaxKr880NGIyC7EBDqAkDX+Uqir4sj3f0tZfTSXPZHE81ccREJsdKAjE5EQ1JCYRaaVUlxZS5eU+ECHIyKya1n96Vuxie8LVOyJBLOQbNkLGgddAxN+w8n2OSM2vspvX5sf6IhEJERZUhbpVkFRaUWgQxER2a2YLgPpF7VZLXsiQU7F3p467FfQ/zBujX+Or2d9x5tzNGCLiLRddEoXAMqKNgc4EhGR3bOs/nS3fNbmFwU6FBHZBRV7eyoqCk6+j9iYaO5PeYTfvjpHz++JSJvFpeYAUFmUH+BIRERaIWsAUThq8lcFOhIR2QUVex0how927F8YWTuX0+vf5fZ3Fwc6IhEJMQlpXrFXXbolwJGIiLRCZn8A4ktWUV1XH+BgRKQlKvY6ypjzYPDR3Bg7hW+/m83M1VsDHZGIhJCkzFwAakvVsiciISBrAAC92cSKLXpuTyRYtarYM7NkM4vyfT3EzE4ys1j/hhZizOCEO4mhgeuS3uEPby6gocEFOiqRsBcu+Sk53WvZaygvCHAkItIRwiU3tSi5C/WxKfS3DSzZqDlCRYJVa1v2PgMSzKwnMBW4CHjcX0GFrIze2JhzOIWP2JS3kpdm5gU6IpFIEBb5KSo5GwBXoWJPJEyERW5qkRnWbQQjotawWMWeSNBqbbFnzrkK4FTg3865U4Dh/gtrN8GYTTKzB4uLiwMVQssOuY4o18Dvsj7g7+8tpqSqNtARiYS7oMpP7RaXRBVxRFWq2BMJE+GRm3YhqscY9o5axfcb9OiKSLBqdbFnZgcC5wBv+5YFbEJ259ybzrnL0tPTAxVCyzL7YfucxfHV/4OyLZqKQcT/gio/7YmS6Cziq/TMnkiYCJvc1KLuo0mgmuoNGphOJFi1ttj7OXAT8KpzboGZDQA+9ltUoe6QX2ANtVyf+h4fLNwU6GhEwt3PCZP8VBaXQ2qtij2RMPFzwiQ3tajHGAC6lqsnk0iwatUdJufcp8CnAL6HjfOdcz/zZ2AhrcsgbMSpnLbwbe5edjxl1fuSEh9eN/NEgkU45afqxFwyKhbinMPMAh2OiOyBcMpNLeoymLqYJEbWrWTJxlL265cV6IhEZCetHY3zWTNLM7NkYCGwxMx+5d/QQtxhvyK2oYqL7E0++17zZon4Szjlp/rkruSylZLKukCHIiJ7KJxyU4uiomnI3ZuRUSuZvy4Ix1EQkVZ34xzunCsBJgPvAH2A8/wVVFjIHYYbeQYXxvyPb+YsCHQ0IuEsbPKTpXUnxarIL1RXTpEwEDa5aVfieu/LiKjVzFtbGOhQRKQZrS32Yn1zw0wGXnfO1QKaRG43oib+hlgaGLn0P1TV1gc6HJFwFTT5aU9HCo7N6AFA8ea1HRmWiARG0OQmv+oxhkSqKVqjG9siwai1xd5/gVVAMvCZmfUFSvwVVNjI6s/GYRdwuk1lybv3BToakXAVNPlpT0cKTs7uBUBlgeboFAkDQZOb/Kr7aAAyixdQqkFaRIJOq4o959w9zrmezrnjnWc1MNHPsYWFbqf9ja9tNHvPugU+/TtUhV+eFwmkcMpPabl9AKjeui7AkYjIngqn3LRLvkFa9raVzF+naxyRYNPaAVrSzexOM5vh+/gn3p0q2Y3o2Di+GncXHzSMg49vg/sPggr1axfpKOGUn1K69ASgrnhDgCMRkT3VGbnJzCab2UNm9rqZHd2R+261qGhc15GMjFrJvHVFAQlBRFrW2m6cjwKlwI99HyXAY/4KKtyctN9grqj5OW/t+zCUboQ3fwYu/LrtiwRI2OQni0+jkgSiSjcGOhQR2XPtyk1m9qiZbTaz+TstP9bMlpjZMjO7EcA595pz7lLgQuDMjj6B1ort5Q3SMl+DtIgEndYWewOdc7c451b4Pv4ADPBnYOFkUG4q+/RK576V3eDI38GiN2H2s4EOSyRchE9+MqM4Jpv4qk2BjkRE9lx7c9PjwLFNF5hZNHAfcBwwHDjbzIY3WeW3vtcDo8doEqmmeK0GaREJNq0t9irN7JDGb8zsYKDSPyGFp1P37cWiDSUs7Hs+9DsU3v01FK4MdFgi4SCs8lN5QjfSa1TsiYSBduUm59xnwM5NZOOBZb6isQaYApxsnr8B7zrnZnVg7G3TYwwAXUoWsbG4KmBhiMgPtbbYuwK4z8xWmdkq4F7gcr9FFYYm7dODmCjj1TkbYPL9YNHwymVQG7LXpCLBIqzyU1VKb7q7TVTUaGJ1kRDXkbmpJ9B0TpY837JrgKOA083sipY2NrPLGp8d3LJlSztD2IXsQdTHJDEqajnTVmieUJFg0trROOc45/YBRgGjnHNjgCP8Gtku7OlcVoGQlRzHxGG5vDZ7PXWpPeGkf0HedHj6dI3QKbIHgi0/7SnL7EuOlbBhi559EQllHZybrPlDuHucc2Odc1c45x7YRSwPOufGOefG5eTktDOEXYiKJqrP/hwSs4hpyws6fv8i0m6tbdkDwDlX4pxrrEx+4Yd4WhvHHs1lFSin7duTLaXVfL4sH0acAqc9DGu/hmdOh5qKQIcnEtKCJT/tqficgQAUrlsa4EhEpCN0UG7KA3o3+b4XsH6PAutgNnAiA8ljwZIlNDRoEDqRYNGmYm8nzd1lkl2YOCyXjKRYXpnlm0Nr5Olw2iOw9lt46WKoV7ctkQ4SsvkptfsgACo2LQ9wJCLiB+3NTdOBwWbW38zigLOANzourA4wwJtCcFj5TOauC52eVyLhbk+KPd22aaP4mGgmjerB+ws2UlJV6y0cMRmO/wd8/y58eEtA4xMJIyGbn7J6esVeXcGqwAYiIv6w29xkZs8B04ChZpZnZpc45+qAq4H3gEXAC8654Br6sttIGpJzOSJ6Nu8t0PQxIsFil8WemZWaWUkzH6VAj06KMaycum9PqusaeHtuk0mTx18K4y+HaffCnOcDF5xICAnX/BSTmksFCVjRqkCHIiLtsKe5yTl3tnOuu3Mu1jnXyzn3iG/5O865Ic65gc652/x+Im1lRtSQY5gYM5d3vltNvbpyigSFXRZ7zrlU51xaMx+pzrmYzgoynIzuncGwbqk8/uUqXNOJ1Y+5DfoeDG9fDyVB1Q1fJCiFbX4yozC2G4nleYGORETaIWxzU2sMO5EkV0Gf0ll8vtQPo36KSJvtSTdOaQcz4yeHDmDJplI++b5JIoyOhZPvg4Y6r+BzuiMmEqnKk3uTXbNOgxyISGgZcDguNpmT42fx7DdrAh2NiKBiLyBO2qcH3dISePDTFTu+kNUfJv4GlrwDf+sL7/82MAGKSEDVZw6kLxvZUFQW6FBEJEx0yrRVsYnY4B9xXPR0Plm8gU0lmmBdJNBU7AVAXEwUFx3cj2krCpiXt1PSPfAqmPwA9DkQvvo3rJ4WmCBFJGDiug8n3upYv3JxoEMRkTDRadNWjTyd5LqtHMwcXpyxdvfri4hfqdgLkLP370NKfAz//Wyn4dWjomH02XD6Y5DSDT68VV06RSJMVt+9AShdOz/AkYiItNHgYyClG79MfZ/nvl2rgVpEAkzFXoCkJcTyf/v34Z15G1hb2MyE6nFJMOEGb9L1L/+lgk8kgmT6ir36TWrZE5EQExMHB1zJiOo5JBUv5TMN1CISUCr2Auiig/sRZcYjX6xsfoUx58GwE735916+RAWfSISwhHTyo7JJKF4W6FBERNpuzLm42CR+k/AST01bHehoRCKair0A6p6eyEmje/D89LVsLa/54QrRsXDm03D4jTD/Ze9DRCJCfkJ/ulS2cCNIRCSYJXfBDvsVE923xCx9h9UF5YGOSCRiqdgLsMsOG0BlbT3PfNPCnS8zOPzX0H0fb3TOT/4Gr1wGddWdG6iIdKrqzMH0bcijuEJ/6yISgg68mtqcEdwW8wgvfD4v0NGIRCwVewE2rFsaE4bm8PhXq6iqrW9+pahoOO4fULoBPvkLzH0eZjzauYGKSKeK77UPSVbNisVzAx2KiISBTpl6oamYOGJPvZ8cK2by7J9QXlXbOccVkR2o2AsCVxw+kPyyml1PQNpnfzj/dbhqOvQ/DD77B1SVdF6QItKpcoeMB2Dr8ukBjkREwkGnTb3QVPd9KBhwMoNZy8x3H+u844rINir2gsABA7I5aGA2//lkORU1dS2vOGAC5AyBo26FigL4301Qv4v1RSRkZfUbRQ0xsGFOoEMREWm3rDPvA6D3vHtxDQ0BjkYk8qjYCxLXHz2E/LJqnviqFaNW9RwLh/wCZj8Nz5wG1WX+D1BEOld0LOviBpBRvCjQkYiItJvFp/Lt3r+nf8NqVs7+ONDhiEQcFXtBYmzfLI4Ylst/PllGQVkrBmQ46hY4+T5Y+Rm8eCHUqy+8SLgpyRzBgLplVO2qxV9EJMgNmngBpS6Ryq8fCXQoIhFHxV4Q+c3xw6ioqeeuD79v3QZjzoUT7oRlH8Bjx8P0h9WtUySMxPTchwwrZ/kyTa4uIqErK7sLM5IOoc+WT6C2MtDhiESUkCz2On1EqU4yKDeV8w7oy7PfrGHJxtLWbTTuIq/gqyqCt6/3Bm4RkbDQZfD+AGz5/usARyIismcq9zqDVFdO/rcvBDoUkYgSksVeQEaU6iQ/P2owqQmx/OmthTjnWrfRfpfA1dNh5I/h83/CpgX+DVJEOkXuoH2pIYaGNRqRU0RC28iDT2R1Qy7V058MdCgiESUki71wlpEUx3VHDeaLZflMXbS5bRsfezskpMPLl0JFIeTNgHkv+SdQEfE7i01gbcJQcopmBzoUEZE90js7mU+TfkTPohmwdVWgwxGJGCr2gtA5B/RlYE4yt72ziJq6NgxTnJwNpz0EBcvgv4fDIz+Cly+B+S97rxevgynnwOzn/BO4iHS48txxDKlfxubC8Oq2LiKRp2jw6TQ4o27WM4EORSRiqNgLQrHRUfz2xOGszC/nyWmr2rbxwCPgrGe9efhGnQW9xsMbP4O3fwkPHg6L34Iv7vLWffUKb7mIBK2UwQcRb3Usn/tFoEMRkRAWDOMdjByxN583jMR98yDUVgUsDpFIomIvSE0cmsvhQ3L419SlrZuKoanBR8GNa+CU++GMxyElF+a+ANmDYP8rIX8JLH4b5jwH0x+CZVP9cg4isud6jZoIQPmyLwMciYiEsmAY72B8/yweaziB2Joi+O6pgMUhEklU7AWx3524F5U19fz13XYMux4d431O7wnXzIKb1sDF/4ODrwUMXvspRMVARl9vFM/qUijdCK9dBRvnd+h5iEj7xaV3ZUN0D1I2zwx0KCIieyQ5PobafoezNKo/TH8EWjsQnYi0m4q9IDYoN5VLDxvASzPz+Gp5fvt3ZLb967Tu0OcAb6qGYSd6E7MXrYaHjoBHj4XZT8NzZ0H5HhxPJMyY2QAze8TMAjLiUX72fuxVPZfiMnV7EpHQduRe3Xi0+gjYsghWfBzocETCnoq9IHftkYPpk5XEb16ZR1l1B02YPuIU7/O4i6H/oXD+61C5FSoL4cS7oWwzTPk/KNuyfZt3fg2f/kOTtkvYMLNHzWyzmc3fafmxZrbEzJaZ2Y0AzrkVzrlLAhMpJO51FOlWwcKZnwQqBBGRDjFxWC4v1R9OZVyW17onIn6lYi/IJcRG8/fTR7GmsIKbXpnX+rn3dmXsRXD+GzDgcO/7/od58/RdNd2bpP3U/8L62fDAIV6Xzi1L4Nv/wsd/hsePh9rKPY9BJPAeB45tusDMooH7gOOA4cDZZja880PbUd9xx9PgjPJFHwQ6FBGRPdK/SzL9u2bwUcxhsORdKNkQ6JBEwpqKvRBwwIBsrj96KG/OWc9z367d8x3GxG0v9BolZkJqV+/rEafApVOhoQ4++B3MfwUwOPIWWPsNLHzDW69k/Z7HIhIgzrnPgMKdFo8Hlvla8mqAKcDJnR7cTmJTu7Aqfgi5mzVIi4iEvmP37s4/th6GM4O3rgt0OCJhTcVeiLjy8IEcOrgLf357IWsKKvx/wG4j4aCrYflH3oid/Q6BQ66DzP7eCFqzn4M794JvHty+TckGWKdBJCSk9QSa3lHJA3qaWbaZPQCMMbObmtvQzC4zsxlmNmPLli3NrbJHSnocyvD6JeRt2NTh+xYR6UzHjujGKteNvJzD4Pt3YevqQIckErZU7IWIqCjjb6eNItqMX740h7r6Nky23l7jLob4NG/Ovr1P8wZ6GX0OrPoc/ncjWBS8fzOsmwUVhfDYsfDIMZC/bMf91Nd563Skxu6szsGsJ6FUF8DSIayZZc45V+Ccu8I5N9A599fmNnTOPeicG+ecG5eTk9PhgeWOOY4Ya+D7r9/q8H2LiHSmvbqn0jc7iX/Zed6CmY8FNiCRMKZiL4T0yEjk1pNG8O3KQm57Z5H/D5iQDuMvg9gk2Oskb9noswGDqmI49xVIzoXHjoNHfuR164yJh3d/veNwyh/9ER6aCBvmdExc+cvgr728vv7LP4I3roFv7u+YfUukywN6N/m+FxAU/ZV7jDiMchKxZe8HOhQRkT1iZhy7dzdeW5NA7YCjvF5CBcsDHZZIWFKxF2JOG9uLiw/uz2NfruKZbzqh28PE38DPvoPkbO/79F6w/xUw4SYYOBEuehtG/dhrWTvxbph4Myyf6hV/r14Byz+Gaf/xtv3ume37rSmH6jLf1xVte/5vxiNQUwbv/QY+/6e3bNVOzzI5B/Negm/+C4UrvWWlm+DR42DTwja/DRIxpgODzay/mcUBZwFvBDgmT0wcq7MPYVTZVxSXawoGEWkbM5tkZg8WFxcHOhQAjtu7O3UNjg/6/gJqy70bxyLS4VTshaCbT9iLiUNz+P3rC/hymZ/nw4uKhtRuOy477naYcIP3dWY/OOnfcNNaGHOO1xI4/nKISYCFr8NTkyE2EQZMgHkvQFUJfHI7/HMvb16/hnp48UK4b//WdcWsrYTZz0LWAChcAau/hNTusH7W9uKxoQHe/y28fInXynjvOMib4T1ruOar7QWiRDQzew6YBgw1szwzu8Q5VwdcDbwHLAJecM4tCGScTSWMPJlsK2HutPcCHYqIhBjn3JvOucvS09MDHQoA+/RKp09WEs8sjYauI6FsE6z9NtBhiYQdFXshKDrKuOfsMQzMSebKp2cyf10Q3KVrnLg9OgaO/ztc+BZc+SXsNQlOuBMOvMaby+++8fDJXyF7IGyaBx/eAkvfg+oS+PDW5vfdtEvowte9CeEn/Qv6HeqNInrc37yRQ9d+480N+NxZMO1er+i8eqb33OFnd8DsZwCDha9B8Tpvf1uWwIxHdzxGXTXU13b8e7QrVSVeC2hNeecet6MtfANeu6rjuuz6kXPubOdcd+dcrHOul3PuEd/yd5xzQ3zP590W6Dib6rf/SdQQQ/W84GhsFBFpLzPj1H178tXyAjae9Ky38LUrvZvAItJhVOyFqNSEWB65YD9SE2I5+8GvmbFq5xHkg0DWADjzaRh1htflM62nV8yc9Rz85EPIGQZf/dt7NnC/n8CcZ+HNa2HGY9uTfVUJPHQEvHABVBZ5RVv2IK/QO/MpuOwTGHgkWDTMfQEePBxWfALH/d0rArsMgv0v90b7KlzhdT91DfDtg94xXrrYG/Z53ove8eqq4f6D4fY+8OxZXoFatgWeP9e/o4VNfxjeuwlevKh9haZzsPgdb/vGQrapguUt77eyyHvPG1tGm27z73Hw0Z93LIbB63pbvM77ePUK7z2sKIQ3fwazn4b/Hra9+65zP9w+TPm7m1RUYjqr0vZjWNGnlFV18g0JEZEOdsqYnjgHryytgdMfg4JlvhuzItJRYgIdgLRf76wkXrziQM59+Bsuenw6L15xIMO6pQU6rOZFRcOFb3sDuKT18JZNuNHrwrn/FXDQz7ziYsFrMPNxWPwWHH4DfH4nrP/O66a59lso2wjnv+61JCZmeh8APfeFuVO8VrxL3oMeY7Yfe/xl8OW/vILwoKth80L4+j9QkQ+b5kNKV3jnV97k8vNehIKlMPIM75m/L//lFYCL3vSK0yN+C3U18Pkd3n5OfQii46A4DzL7tnz+VcXw7JlQX+NNY3HUH7wCqGQdZPSGJe94Re/S97ziafL93nyIrVFb5b2P37/rfR+TAKc0GbBm9nPe3dJxF8GJd3mFWky89zPJmwEvXQRFa7xi+ZjbvEFvknPgi7u88/rsH7BpAaTkwuBjIGeo92xFma/brUWDq4eVn3mF44Vvw1f3wge/h/Se3rOaw46HsRe27nxCmHPuTeDNcePGXeqvY8TufRK9vrqJT77+hAkTfuSvw4iI+F3f7GTG9c3klVnruPLak7Ae+3qDrmX2h/6HBjo8kbCgYi/E9chI5Kmf7M+p//mSCx+dzmtXHUy39IRAh9W8rP47fj98Mpz1rNcyF5sA57/mFUAzH4N3fg3LPvTWO/4OyF8K3/4XjrrVK8p2NvAIr+vgWc/sWOgBJGXBCf/0WvTikr2CZ+sq+O5p6DnOK6z+eyj893DvmcBBR8FpD3vbfvNfbzvwupAech08fqJXfIL3TGB5vles5Y7wWhJjk+HoP3uD2tRWes8sfvsgrJnmHe/Lf0Gv8d75zXoSzp4CedNh4m+9AmzqH7xC6qxnvZbQVy/zCqW9T/OO+fUD3iA13UdDj9FecbbsQ++YJevh6/vhoGsgdy/49iEvxrgUmPkEDD3BK/ySsmDocV7LamoP79if/NUbNbVRTCJc9A58/54XP3iFeFyKVywefZvXpXb0OfDp32DOc7DP/3nFbO5wr4X0hfMhLtU7lnSIvgefRe1Xv6Nm1hRQsSciIe7UfXvxm1fnMW9DGaPOfBruGg5PnAg3rNp+Q1dE2s1cCHevGjdunJsxY0agwwgKizaUcNr9X7F3j3SevXR/YqJDvIfu1lWw5XuIS4K+B3sF18Z50H2f7c8HNlVX7RVd6T1bt//KIvj4Nhh7EXQd7s0D+NZ1Xmvd5Z95hVL+MrhvP8DggCu95wBHnAoLXoHTH/W2mXavt7/9LvXiq9wKW1d63UwHH+2NGHrIdV4B23OcV8Ddf6DX0tfYMhab7I1EduVX0HUEzHkeXv8p9D3IG2xm9RdeDAdf653nN/dDt1FQuhHKN3v7OPFur+WuohD+NRoSM7wWy7xvvda44/8O/znIO05iJsSneq15w06Ek+/1li390GvVHHGqN9ppXPKOg/PU13rdaBe86hXD3Udtf622yisER/3YKyQB8mbC/Je9wjOte+t+LoCZzXTOjWv1BkHI37lp8d2TyNo6l9hfLiYzNdFvxxGR7cIhN0HwXTsVV9ay/18+ZPLontx+2ihY+gE8c7r34o1rvF4vIrJLu8pPKvbCyKvf5XHd83O44vCB3HjcsECHE3oa6r0isHGaCfCKm8bJ5P85DHAw4hQ443GvO+e7vu6fja1u4A348tZ13tdpvaAkz/v6kg+g93hY/DZM+T+vm8r4S72CMKMvXDtneyE7Zwq8ern39Yl3wbKpXtdWgJE/9lojo6K94rKuesdiavHbXute2WavABx/OURFed0xP78LznsVuo30WkL7HNB88RxA4XBB5e/ctPaLKfT+8HLeH/sAR08622/HEZHtwiE3QXBeO/36pTm8OWcD39x8JGkJsfDujd6NzdwR3mBvQfZ/SiTY7Co/qRtnGDllTC+mr9rKA58up3t6Ahcc1C/QIYWWqOgdCz2Aw365/es+B8K6md7zduA9UzfpXz/cz9iLvMFgGuq9dT/5izfQTO/x3utDj4dj/uJNR5EzzLuLOXDijv/M9jnL275sE4y72NtnRaHXwpmSs329xla0poad4H3s7LBfwQFXea2lAH0P3O1bIsGp9/6TKZv6C6LmvQAq9kQkxJ13QD9emJHHKzPzuPDg/nD0n7xib/MC77GF/X4S6BBFQpaKvTDzx5NGsKW0mlveWMDWihqumjiI2FDv0hksTrzLGyBmVwOxgFe0Hf3n7d8fdesPXz/wqu3fn/9a8/sZc86O2+xciLZHY6EnfmFmk4BJgwYN8u+BYhNY3+NoDsx7h0WrN7JX326730ZEJEiN7JXOPr3SefqbNVxwUD8sOhZ+sRjuHAZvXw8DJnpTNolIm6kKCDMx0VH8++wxnDKmJ3d/uJTT7/+KzaVVgQ4rPOQO81rjRFrQmZMWdzvsYpKtmu+nPu73Y4mI+Nu5B/Rl2eYyvl7hm0oqrTtc5Btl+t/7eo8miEibqdgLQwmx0dx15mjuP2dfvt9Uxmn3f8Wq/BCfrFtEdpA25FDWx/Vn8JoplGvOPREJcZP26UF6YiyPf7Vy+8K+B3nz5gLcMTgwgYmEOBV7Yey4kd2ZctkBlFfXc87D37CxWC18ImHDjLqxFzOclXz68buBjkZEgpyZTTKzB4uLiwMdSrMSYqM5/8C+vLdgE0s2lm5/Yf/LId7XW+KJkwITnEgIU7EX5vbpncETF42nuLKWcx7+mvnrgjPJi0jb9ZlwEZWWSPTMR2loCN2RlUXE/zqzm3l7XXxwf5Ljorn342U7vvDrFd7nlZ96c8aKSKup2IsAI3ul8/AF4yiurOOke7/gsS9X7n4jEQl+8als7DeZCbVf8NXcxYGORkRkj2Qmx3Hegf14a+56lm8p2/5CdAxcPdP7+s2fefPwikirBE2xZ2YDzOwRM3sp0LGEowMGZDP1+sM5YlhX/vTWQl6emce1U77joc9WBDo0EdkDPY/5ObFWx5ap9wQ6FBGRPfaTQ/sTHxPFfR/t1LrXZRCc+4r39X37edMRichu+bXYM7NHzWyzmc3fafmxZrbEzJaZ2Y0AzrkVzrlL/BlPpEtPjOVfZ41mUG4K1784h9dnr+fOD76nuEKDO4iEqrhuw1idM5EjSl5j1verAx2OiMge6ZISz3kH9OW12etYtrlsxxcHHQn7X+F9/cplnR+cSAjyd8ve48CxTReYWTRwH3AcMBw428yG+zkO8UmOj+Hh8/fjkkP688C5Y6msrefFmWsDHZZIWAjUAAjdT7iJdKtgydtq3ROR0Hf54QNJiI3mH+810z39uL9B/8Ng2QfwwKHg9LyyyK74tdhzzn0G7NzOPh5Y5mvJqwGmACf7Mw7ZUZ/sJH534nCO3bsb+/XL5Mlpq6nX4A4ieyxQAyAk9BtPXuZ4jix6ie9WbOjUY4uIdLQuKfFcNXEQ7y3YxIcLN/1whdMe8T5vnAtf6SaXyK4E4pm9nkDTpqQ8oKeZZZvZA8AYM7uppY3N7DIzm2FmM7Zs2eLvWMPeRQf3Z01hBT99ZiaLN5awbHOZRvUTCUHZx95IrhUx/617Ax2KiMgeu/TQAQzpmsLvX59PeXXdji+m5MJV072vP/g93JoONZpPWKQ5gSj2rJllzjlX4Jy7wjk30Dn315Y2ds496Jwb55wbl5OT48cwI8Nxe3fjpuOG8fHiLRx79+ccdeenHPevz5m6qJk7aSIStBKHHMH69H05tuApvl6sZ/dEJLTFxUTx11NHsr64in++38zomzlDIL339u//0gMaGjovQJEQEYhiLw9o8tdJL2B9AOIQwMy4/PCB/O/nh/Kvs0bz58l7U9fQwKVPzmDGKo10JRIyzMie/BdyrJglr/1dXbNFJOSN7ZvFOfv34fGvVjI3r+iHK1w3H361fPv3f8zUM3wiOwlEsTcdGGxm/c0sDjgLeCMAcUgTA3JSOHl0T849oC+vXXUwvTKTuHbKbI3UKRJC4vsfyMbuR3Jq5cu8MW1uoMMREdljvz52GF1S4rnx5XnU1TfTcpfcBX7b5LGeP2TA5/9U0Sfi4++pF54DpgFDzSzPzC5xztUBVwPvAYuAF5xzC/wZh7RNakIs95w9hk0lVZz7yDdsLq0KdEgi0kpdT7mNJKum4sO/U7bzcy4iIiEmPTGWW08awcINJTz25armV4qJg99v3f791D/Cq5er4BPB/6Nxnu2c6+6ci3XO9XLOPeJb/o5zbojv+bzb2rrfQA1vHklG987gwfPHsmxzGafc9xXLNpcGOiQRaQXL3YuiwadzRsO7PPfuR4EOR0Rkjx23dzeOHJbLnR98z/ebWrgeiYqCW4vhrOe87+c+Dy+cD7WVnReoSBAKRDfOPRao4c0jzRHDuvL85QdQXdfAqf/5im9WFAQ6JBFpheyT/kRDdDxDZt3G2gKNUCcioc3M+MupI0mOj+GqZ2ZRWVPf8srDjodf+ObnW/QG3NYN/j4Q6tXTQSJTSBZ70nlG9crg1Z8eRE5qPOc98i1PfLWK575dw/x1alUV2VnQ9DpI7Ub1Ib/m8KjZvPjcwzh1ZRKRENc1LYG7ztyHpZvL+NmU73Y9TVRad7jw7e3fV+TDn7Jh3Sz/ByoSZFTsyW71zkrilSsPZnSfDG55YwE3vTKPix6frsFbRHYSTL0O0g+/mqLkAZy++d+8+u3SQIcjIgEWNDej9sChg3P43YnD+WDhJv41dTd5rd8h8MulMOTY7csemujNyVdX499ARYKIij1plfSkWJ6+ZH9euPxAHr9oPwrLa/j9G/N55IuVPPHVKqpqd9GlQkQ6X3QsaafdQ5+oLZS++wc2lWigJZFIFkw3o/bExQf34/SxvfjX1KW8PnvdrldOyYX/ex4u+t+Oy/+cA/Ne8l+QIkEkJIu9cLg7FYriYqIY3z+LCUNz+cmh/Xl99nr+9NZCbnljARPv+IQ7P/ieeXnF1DY3NLKIdLqoAYdSMuI8znVv8/CUl9SdU0RCnpnxl1NGMr5fFr96aS7TWzMncN8DvcFbzn15+7KXL/Fa+abdp+f5JKxZKP/zHzdunJsxY0agw4hIVbX1vD57Hfv1y2JjSRX/nrqMr1cW4BzEx0Tx2xP24rwD+wU6TAlBZjbTOTcu0HHsiaDKTVXFlN01jnWVcSya9AaT9xsY6IhEQlI45CYIsvy0BwrLazj9/q/YXFrNU5eMZ0yfzFZuuBLmTIFPb99x+cgfwwn/hIS0jg9WxM92lZ9CsmVPAi8hNpoz9+vDgJwUDhrYhecuO4BvfnMk95w9hvH9s/jd6wt47bvddK8QEf9LSCfxtP8wNCqPkrduZvmWskBHJCKyx7KS43j20gPITonj/Ee/ZfbaolZu2B8m3gSXfrzj8nkvwO294fM7NT+fhBUVe9JhclMTOGmfHjx0/jjG98/i58/P5scPTGPacv9M2fD016v51Ytz/LJvkXASPeRHlI++hPPtXR59/GE9YysiYaFbegLPXnoAaQmxTL7vS2a0pktno577el07r5274/Kpf4A/ZHhdPD/+K9TqeWcJbSr2pMMlxEbz+EX7cfPxe7GuqJKzH/qa378+n7WFFR16nBdnrOWV79bpwlWkFZJPuI3y9MFcW3YXd7z6ZaDDERHpED0zEnnqkvEAXPT4dGau3tq2HWT29Yq+W4vh7Ck7vvbp7XBbV6/w+/YhmP4wrJsJNR17PSPiTyr2xC+S4mK49LABfPCLw7jwoH489fVqDvvHx5z78De8OWc99buaH6cVqmrrWbC+hPoGx5KNpR0UtUgYi00k+ezHyIoq5/B5N/HqjFWBjkhEpEMMyElh6vWHk5kUx7kPf8MnSza3b0dDj/MVfc//8LV3fglvXw8PHQF/6e4VgIUrvMFdZj0FddV7dhIifqJiT/wqKS6GW08awee/nsjPjxzCyvxyrnnuO8544CumfLuGf324lIXrS9q833nriqnzFYwLN7R9e5GI1G0kduKdHBo9n8LXf8O3K9vQ5UlEJIgNzEnh5SsPYkBOMj95YgYvzFjb/p0NPdYr+m7eBMf9A2ISml/vnjHeZO1vXA1Pn9b+44n4UUiOxmlmk4BJgwYNunTpUk0WHEoaGhyvzV7Hn95ayNYmk7Lv3z+Lod1Sqa5toLa+gYG5KZy0Tw96ZyU1u58HPl3O7e8uJj4mijPG9eLPk0d21imIn4XyiHehkpuq3/gF8bMe4Wa7mot/ehMDc1ICHZJI0Avl3NRUuIzG2ZLSqloueWIG364s5GdHDOLao4YQHWV7vuOacqgqhvzvvRa9t65red3R53jPBHYdCX323/Nji+zGrvJTSBZ7jcI9YYWz0qpa8stqSE+M5clpq5i6aDOrCspJjI0mJspYX1xFanwMfz99FMeN7P6D7S97cgZLNpXSNS2BuvoGXvnpwQE4C/GHcLigCvrcVF9L1aMnEb3uW34VezO/uupKemYkBjoqkaAWDrkJQiA/dYCq2npueHkur89ez/DuaTx20X50TWuhdW5POAfLPoR3f+0VgC058GoYOBEaGmDI0R0fh0Q8FXsSctYWVnD1c98xZ20RFx7Uj5uOH0Z8TDQAzjn2u20qhw3uQnpSLFO+Xcv8PxzTMXfuJODC4YIqJHJTZRGVDx2LK1zBz+P/zB9+eh7d01XwibQkHHIThEh+6gDOOR78bAV/fXcxAE9dMp5DB+f474Crp8GLF0LZxtatf/C1cMTvoKIAUrv5Ly6JCJpnT0JO76wkXrz8QC45pD+Pf7WKQ/72Mbe+sYAtpdV8+v0W8suqGdM3k+Hd06isrWdVQXmgQxYJLYkZJF70GtEpufyt6o/85oHn2VSiIcZFJDyYGZcfPpBHLxxHclw05z3yLRP+8TFFFTX+OWDfA+GXS7xn/W5aB7/dAvuc3fL6X/4L/tQF/jl0+2ifBcuhod7rMlpf5584JeKoZU+C3udLt/DsN2uYumgzSfHRVFTX079LMs9ffgDri6o4/p7Pue6oIVxzxCCi1LoX8sLh7nlI5aaC5dQ8chwV5eVcn3grN19yNgP0DJ/ID4RDboIQy08dpLy6jp8/P5sPFm4C4LGL9mPi0NzODaJwBRTnwRs/g60rW7fNMX+FA670vjbf9U3Bcsge6J8YJWSpG6eEhaWbSrnplXlERxn/PW8sGUlx1NU38H8PfcO3qwoZ1zeTZy7df1t3TwlN4XBBFXK5qXAFNY9OoqaskKvtJq658DzG9s0MdFQiQSUcchOEYH7qIM45bnplHlOme6N0/mh4V37xoyHs1T0tUAFB3nR4/rzWd/2MTYLaCui6Nxx4FfQcBxYFXQb5N1YJeir2JKw1NDiem76Gm1+dz3VHDeHaowYHOiTZA+FwQRWSuak4j9rHJlFXtI4b66/ksMmXctrYXoGOSiRohENughDNTx2ouq6ehz5bwQOfrqCsuo7E2GieuHg84/tnBTawyiKY/hB89Oc928/+V3hFYEMtrPwMhhzjFYnZg6BsM/Q5YHsrYaP6OijfDGk99uzYEjBhV+yFyvDm0rmuee473pu/kf/9/FB1Qwth4XBBFbIXU2WbqX32bGLXz+DfdZPZMOYX/P6kvUmIVWu5SDjkJgjh/NTBiitqefTLlfxrqncd2ScriT+ePIIJnd29c1dK1sPyj2DzIph2r/+Pd/SfYcUn3gijP/kIakphzTdQkQ/7nAXpfSC5C9TXQEy8t82S/0FdFcSnwKCjtu+rrhqiYiAqwv9/VJeCa4CEdL8eJuyKvUZKWNLU5tIqjvrnp/TJTuKlKw7SBWqICocLqpDOTXXVNLx1PVGzn+Kj+tH8J/16bj37cPbu6d9/VCLBLhxyE4R4fvKD5VvKuOqZWSzeWArAYUNyOGmfHpw6pmdwjgPQUA9Fq73WuhfOh7XfBDqi3csaANmD4ZDr4LFjofs+XhE0YILX4pg9CDYtgKUfwOmPQEpX+PAW6DIU5r/s7WPSv6C+Fha9AaP/zxvBdM3XkDscYhMhOvaHxy3bAlsWQZ+DIDpmx9cKV0B8GiRl/7ClEyBvJtRVQr9DfvhaQ4P33GVDHeQM9Zatnubt55sH4Lh/QPkWSMmFO4dDfTVcMwv+vS+c+7JXFNdVg0V7cZVu9AbqOele2Pe8dr3FKvYkYkxdtIlLnpjB5NE9uP20USr4QlA4XFCFfG5yDqY/TMP/bqKwIZlf1V7B0ENO4WdHDiIpLmb324uEoXDITRAG+clPtpRW85tX5zE3r4hNJdX0zU7iwoP6ceKoHuSkxgc6vJbV1wHOK3ac8wrBqhL46E+wcR4MPhpmPeGt2+dAWDMtoOH6XY99vZbQusq2bxsdBz/9Gh75kTclRqOe47wC8+1f/HCbfc6GuGSY/nD7Y26qyxCvgK0ogAvfavVmKvYkotwzdSl3fvA9Wclx3HjcMH48rnegQ5I2CIcLqrDJTRvnUf/iJUQXLOGN+gN5KPESLjvhYE4Y2T0473iL+FE45CYIo/zkJ9V19fzprYV8u7KQ7zeVkRIfw2n79uTao4aQlRwX6PD2XEMDbF4AlVshdwR8dY836Mvep8E7v/Janupr4a7h27exaBhzDiz/BIrXBCz0iHP8HTD+0latqmJPIopzjm9XFnLnB9/zzcpC/nbaSM7cr0+gw5JWCocLqrDKTbVV8MVdNHx+J5UNMdxdO5kZOadyzbGjmDg0F2uu+4tIGAr13KTxDtrGOccnS7Zw78fLmLl6K8lx0Uzapwc3HDuMzHAo+nbHuea7Nzaqr/We1YtL2b5edZn3PF99DSRmevuYdi9k9oPM/l7r438P9SaT/+hPMPpcmP20t21yjtf1UbY78W4Yd1GrVlWxJxGpuq6ey56cyWdLt/DSFQdpKPkQEeoXVBCmualgOe6dX2PLP6SADO6rncR3uZM5/7BhnDCyB3ExUYGOUMSvwiE3QZjmJz+bv66YW95YwMzVWwH4/YnDufCgfurh0BE2L4L872Gvk7zn2GIToKLQm1IiMQMKV8I9o711D/ip98zi4KO9IjE6Ho66xetG+d7N8N1TO+47d4TXitmSYSfChjkw4hSvhbOpQT+ClZ96hWug3JQH8amtWlXFnkSs8uo6Jt7xCb2zknjpigPVChECQvmCKiLunK+eRsPHfyFq1WcUWgZP1R7B+4nHcewBYzh9XC+6pycGOkIRvwjl3NSUrp3axznH3/63hAc+Xb5t2Q3HDuOywwYQraIvONRWecVZwk5zJ67/DrqPhlev8EYV7XOAVzTGt2Lk9lvTvcFwjvgdlKzzBpl5+3pvwJioGPjwVm/KjEY3rfNGIJ3/ijcQTdcRXkyrPveeJ0zK8orZt6+HgRO9onLFJ96ANYvf8mKtLoEbVnmto62kYk8i2pRv13DjK/P4w0kjOGRwFwZ0SVbRF8TC4YIqInLTqi9xX9wNyz6gnij+Vz+OF+qPIHrg4Zw4ujdH7dWV9KRmRkcTCVHhkJsgQvKTH9U3OP790VLu/tC7oZeaEMOTF49nTB/1HgpLhSsgqcsPC8imvrgL+h/mdWMdcHjnxdaEij2JaHX1DZz47y+2DavcLzuJa44YrAmjg1Q4XFBFVG4qXAEzHqV+5lNEVxdRRCr/qxvL+25/3IDD+dHevZk4LEctfhLywiE3QYTlJz8qqarl6Ds/Y2NJFQDnH9iXa48cTHZKEI/cKWEr7Iq9iOgqJR2qtKqW79YUsa6okme+Wc2SjaV8ccMRdE1LCHRospNwuKCKyIup2kpYNhW38HUaFr9DdG0Z5SQyvX4I3zYMY23aGLIHH8D+g7sxpk8m3dL1tyehJRxyE0RofvKjlfnl/PHNBXy8xBtc5NojB3P54QM0TY10qrAr9hopYUl7rC4oZ8Idn3DVhEH88pihgQ5HdhIOF1QRn5vqqmH5x7il71Oz/Avity4BoNLFsdD1ZUFDP/LiB2Hd9qZrv+EMG9CHkT3TSU1Qt08JXuGQm0D5yV8+WryJBz9bwdcrCklNiAEHH/1yQnDP0SdhY1f5SbcdJOL0zU7mR3t15ZlvVnP1EYM08bpIR4uJh6HHYkOPJR6gPB/WTCNu5ZcMWT2TkflfEVf/AawD1kHxF0msdF3ZHNOT2pTuxKXlkpLdgy5de5LbrRcpWd2w5BxvlDYRkSB0xLCuHDGsKx8u3MTPn59NWXUd+932IQDz/3AMKfG65JbA0G+eRKSLD+nP+ws3cezdn/Gj4V356YRBkTFvjkggJHeBvSYRvdckUsGb1HfrStiymIqNyyhbt4SM/OX0KFtBWsk3xJXUQt4Pd1NlidTGJNMQl0JUfCrRCanEJqcTk5CKxSVBbDLEJXkjp8Ule59jE7d/ve2zb53GjyhNGyEiHeOo4V2Zd+vRPP31ah74dAXriirZ+5b3yE2N5/WrD9bzy9LpVOxJRNq/fxZ/P20U78zfwKNfruLFmXlcNWEQ5xzQR/3sRfwtKgqyB0L2QJKGQVLT15yjvqqU9evXsn7dGorzN1CxdSO1JZuhooCG6lKSqypJppJkKyCFdaRYJSlRNSRSTbyrIoo2Pp4Qk+grABuLxUTv68QML8703t4Q2ImZ3rDZiZne6GytGbZbRCKOmXHegf0494C+3P3hUp79dg2bS6s58K8fAfDylZr7VzqPntmTiLdkYyl/fnshny/Np0tKPE9ePJ7hPXYxxK74VTg8F6Pc5D/1DY5NJVWsLaxgU2k1m4qr2FRS5X1dUsWm4kqKSkux2kqSqCbRqkmi2vd1FRnRtXRJqCcrro7MmFoyY2pJi6klJaqGZKsmyWpIoIr4hiriaoqILlqJtTSpbkIGZPSGjL6Q1hNSu0FGH+/rtB6Q2h1i1GMgXIRDbgLlp0BwznH9i3N4Zda6bcviYqK444x9OHFkd03OLntMA7SItMLM1YVc/ex3VNXW89Ql+7N3z/RAhxSRwuGCSrkpsJxzlFTWUVBeTWF5DYXlNWytqKGgvIat5TUUltfu8P3W8hpKq+ua3VeM1dMvsZo+idX0TKikR1wlOTGV5FoxOQ1byKzdSFrVRhIqNxBVU/rDHSTneIVfWk+vhTCjt1cQpvs+J2WD5v0MCeGQm0D5KdAe/nwFf3570Q7LhnVL5emf7E8XTdsg7aRiT6SVVheUc/aDX5NfVsP1Rw/hgoP6aQCXThYOF1TKTaGnuq6eoopaCsq2F4aFZV6xWOArGBs/NxaPO//7TKKKwQlFDEsqZWB8MX1iiuhuBWQ3FJBes4mkyvVE15bvuFFsMmQP8LUMdofMvtBlCGQN8FoM45KQ4BAOuQmUn4LF5pIqLnxsOgs3lOywfMLQHO77v31J1oAu0gYq9kTaoKCsmptemcf7CzeRmhDDpH16MHl0TxJio+iTlURGkrpl+VM4XFApN4W/+gZHcWUtheXVbC6pZmNJFZtKvK6kG4ur2FRaxabiKjaXVlPX0Ph/1pFOOcMSihiZWsLQhCL6R22mR8MGMurzSazcjFUW7Higxq6i2YO8IjCjj/fMYJchkDVQg8t0onDITaD8FGwaGhxfLMvn5tfmsbawcofXemUmcvLoHvziR0OJVldP2QUVeyJt5Jzj6xWFvDhjLe/M30BVbQMAXVLi+fAXh6ng86NwuKBSbpJGDQ2OgvIaNpVUsa6okjUFFawp9D7WFlawdmsFtfXb/w8PSW/g0MxCRqcWMTxhK71iiokvXQsFS2Hramg6+ExcCuQM87qBxqV4o54mdYHkbK97aGp36Lo3pPdSV9EOEA65CZSfgllNXQOPfbmSv767uNnX9+mdwb1nj6FXZiKmv2lpQsWeyB4oqarly6X5lFbXcdMr8zhjbC9uP21Us+vW1jewfEsZw7ppgJf2CocLKuUmaa36Bkfe1gqWbCzl+02lfL+pjO83lbJ0cxn1vhbBgTnJjOubxWEDUjmkax3plMDmxbBhDmxZDBYF1aVQUeB9VO/YLYzYJO8ZwbQekJDmfd33YOi5rzeojLRKOOQmUH4KJV8tz+cv7yxi/rqSZl+/auJArjlisB43kfAr9sxsEjBp0KBBly5dujTQ4UgE+es7i/jvZys4bEgOA3OSueaIwWT55uebuXorN70yl+83lfHC5Qcyvn9Wi/upqKkjISZaI3A1IxwuqHQxJXuqoqaOuXnFzFy9lVmrt/LtqkJKq+owg1E90zl0cA6HDclhTJ8MYqN36spZV+0VfcV5sHEuFCyHojVQuAI2L9xx3ahY7znBrIGQ1R+6joARp3jLY+LVIthEOOQmUH4KRc45tpRWc87D37B0c1mz6wzpmsJp+/biiGG5DO6a2skRSqCFXbHXSAlLOltFTR2/eWUeK/LLWbi+hLTEWK45YhBxMVHc8voCclPjKamq4+jhXbnzzNEt7uOQv33M5YcN4PLDB3buCYSAcLigUm6SjlZX38DcdcV89v0WPl+az+y1RdQ3OFLiYzhsSBeO2qsrE4fmkpncii7m1WWwcR6s/NQrCLeuglWfN79uUjYcfgMMOQbS+0T0M4LhkJtA+SlcrCmo4OlvVvPpki0s2dTMSMDAuQf04YID+6n4iwAq9kT8YMnGUn73+ny+XVkIwKGDu3DfOfvyt3cX8/KsPL69+SjSEmJ/sN278zZw5TOzGNs3k5evPKizww56oXxBpV4H0lmKK2uZtryAT7/fzNRFm9lcWk2Uwdi+mUwclssRw3IZ2jW19c/11NVASR5sWggvXwKZ/WHLoh+ul5AOE2/2ngPse5A3WEyECOXc1JSuncLT0k2l3P/p8h3m8mvODccO46KDNdJ4uFGxJ+JHs9ZsZcG6Ys4a34fY6Cjm5hVx0r1f8qfJe3PeAX1/sP7PnvuON+asJzrK+O73P2q2IIxk4XBBpdwknamhwTF3XTEfLdrE1MWbWbDee76nZ0YiE4bmcMSwXA4a2IXEuDZe3FUVQ3QczHsRNi+C+a9AZSE0nWQ+awBkD4ZN872pIsZeCGu/gd7jYcAE75lA58KiO2g45CZQfooUeVsreGFGHk9NW8XWitpm18lIiuWQQV345dFD6dcluZMjlI6kYk+kEznnOPHfX7BkYymT9ulBj4wE9uqexgkju1Nd18DYP31A94xElm0u48HzxnL0CA2Q0FQ4XFApN0kgbSyu4uMlm/lo8Wa+XJZPRU098TFRHDgwmwlDcjh0SA4DuiS3bzS/FZ/AkydDci6Ub979+um9oXitNyro5P9ATIJXHIJXAIZQERgOuQmUnyJVcWUtXy7L54FPl7PJN1VMS352xCBOH9ubPtma5zNUqNgT6WSbSqq4/5PlvDhjLZW19TQ4OG3fXvTOSuTuD5fy0Pnj+Nlz33HGuF788eS9KSir5oOFmyipqmX//tns0zsj0KcQMOFwQaXcJMGiuq6eb1YU8tHizXyyZDOrCioA6JOVxBHDcjl8aA4HDshuW5eu2iqITYDidRAVA9GxUFsB67/z5gWMjoNXL4eSdd5ALztPJN/UPmd7cwbudRI01EFad7BoiE/ZsxP3g3DITaD8JJ6GBseawgr+88kyXpiRR2ZSbIstgABDu6Zy7VGDOWZEN835F4RU7IkEUH2D419Tl3LPVO8Zri4p8Xx14xFc9tQMlmws5ai9uvLKrDzKa+oBr+vVp7+aQMzOI+xFiHC4oFJukmC1trCCT77fwseLN/PV8nyqahuIi4li//5ZHD4khwlDcxmY085Wv+ZUFXsDwix6E1Z8DOX5kJIL+Uu9KSLKNjW/3T7/57UI5gyFnuMgKhpyh3uFYUw75jktXAmuAb59yHvOMCEdvn8X4tPg9Ee9gnU3wiE3gfKTtKy+wbEyv4zfv76Ar5YXtLjej4Z35YOF3t/u308bxRnjemnevwBTsScSBNYWVlBZW0/XtATSE2N55pvV3PzqfBJiozhyr65cNWEQK/PLuerZWdxz9hhO2qdHu45TVl1HVW09XVLiO/gMOkc4XFApN0koqKqt55uVhXy6ZAuffL+ZFVu8FrieGYkcNiSHw4fkcOjgLiTHx/gviJoK+OJO+Owfbdtu8DHb5xdM6wH9DobSjd4oo7FJULkVCpZBl8HetBNbmp+kmtzh8NNprTpkOOQmUH6StmlocDz19WrueG8JpdV1JMRGUVXb0OL6A3KSufbIwUwYkkt6ksYk6Cwq9kSCkHOO/LIaspPjts2319DgOOrOT0mOj+GNqw9u852ywvIaTvnPlxjw0fUTQnIev3C4oFJuklC0trCCz5Zu4dMlW/hqeQFl1XXExUQxvl8WBw7M5sCB2Yzqmd45vQ6qS6FkPVQWQekGWPKut7xwBeR92/J2calQ02QY+qwBUF8HxWtg79Oh51ivCEzvCXufBpn9Wh1SOOQmUH6SPeec44OFm/jLO4u2dQ3flbP26011XQMXHdyPwbmpbR8sSnZrV/nJj7frRGRXzIyc1B1b36KijJ8cOoDfvDqPp79Zwxlje/HF0nzG9MkgezctddV19Vz+1AxW+xLvF8vyOWxIjt/iF5Hw0jsriXP278s5+/eltr6BGau2MnXRJr5Yls8/3lsCQHJcNOP7e8XfQQO7sFf3NP88vxOf6nXhbDRi8o6vVxR63TyzB8H0R7znAw/6mVfEbZznTSyflO0Vc+peJtKhzIyjR3TbYYC5+gbH8i1lTFtewC1vLNhh/SnT1wLw6nc7TgvRNzuJsX0yqW1w/O7EvchNTfB/8BFILXsiQaamroErnp7JR4s30yUljvyyGrKS47j1pBFMGtW92dY+5xzXvzCHV75bxz/P2Ic/v72QAwdm859zxgbgDPZMONw9V26ScFNQVs03Kwv5ank+05YXsNzX5TMtIYYDBmRvK/6GdE0J22d3wiE3gfKTdB7nHA0OVuaXce2U2SzeWEp9w67rji4p8XRPTyAjKZY/nbw3PTMTiY3QMQzaQi17IiEkLiaK/543lt+8Mo+V+eX87sThPPrlKn723He8/t06ctMSmL22iLzCCg4YmM0Nxw7j6a9X88p367j+R0M4bWwvFm4o4clpq8gvq9727N7qgnKmLtrMRQf3C9uLMRHxj+yUeI4f2Z3jR3YHvBGHv15RwFfLCpi2ooD3fYM1ZCfHccCAbMb0yWBUrwyGdE0hI6kdA6pIhzOzScCkQYMGBToUiRBmRrTBoNxU3v7ZoTu8VlxRyyNfrmT6ykKmrdg+GEx+WTX5Zd60EBPu+GSHbfp3SeaQQV1Iiovm7PF9NDdgK6llTyQE1Dc4Hv1iJf/8YAmxUVGM6ZtJt7R4Xpu9npo670Hpc/bvw58n742ZsWxzGUff9SmjemXw0PnjyEmN57rnZ/Pqd+t4+PxxHDW8a4DPqGXhcPdcuUkiTd7WCqYtL2Da8gK+XlHA+uKqba8N6ZrCqF4Z9O+SzN4909mrWyo5qfEhd9MpHHITKD9JcFtbWMHnS/P5zavz2rztmD4ZXHRwf44YlktKfAx19Q0RM7K5BmgRCRNVtfXERkdte0ZmycZS3p2/gWNGdGOv7mk7rPu/+Rv4+fOz6ZGRyEtXHMTBt39EZW09w7ql8s7PDg3awVvC4YJKuUki3ebSKmavKWLxxlJmrdnKvLxiCsprtr2emhBDj/REfjS8K8O6pzI4N5UBOclB3V0rHHITKD9J6KmoqaOgrIZlm8uYMn0N7y1oYcqWXYiLieLSQ/uzd490fjS8a9gVgWFX7DXpinDp0qVLAx2OSND69PstXPDot+zTK505ecWcf2Bfnpy2mr+fNoof79d7h3Ubc0Gg77aHwwWVLqZEfqi4spZFG0pYtKGEOWuL+G5tEXlbK7c9wxMbbQzMSWFI11SGdkv1PndNpVdmYlDcnAqH3ATKTxJeCsqqeeabNYzpk8HvX1/AyvzyVm/bIz2BtMRYvt9UysCcFK4/eij9uyQH/Y2n5oRdsddICUtk9y5/agbvLdhE76xEPvnlRM787zRmry3ixuOGUVFTzxfL8pm9poia+gaGdUvlrjNH/6CVsDOFwwWVcpNI61TV1rN8SxnLNpexaEMp328qZcnGUtYVVW5bJykumsFdUxnadXshOLRr53cFDYfcBMpPElkKy2uYtXors9Zs5T+fLN+jfWUkxdIvO5k7zhhFv+xkoqMs4DfIG6nYE4lgawoqOObuz7hq4kCuPmIwpVW1XPrkDL5eUYgZjOiRxvh+2STHRzNl+lqKK2q54bhhXHRQPworakhLiCUupu13uLaUVvPCjLWsyi/nwIHZnLpvr1ZtFw4XVMpNInumtKqWpZvL+H5jKUs2NRaBZdsGbgDvwqux9a9/l2R6ZSYyICeZ7umJfpkIPhxyEyg/iYDXNbSuwVFb18B7Czbx5LRVLN5YuvsNdyM22qitdzxw7lj27ZuxbTqJ8uo6v+SlRir2RCJcQVk16Ymx2/qoV9fVM3tNEUO6ppKZHLfDeje8PJcPF20mLSGGkipvUuUDB2Tzzx/vs21kT+ccj3+1ivs+XsZPDh3ApYcOoKKmjhtf9kYQffTC/bj8qRnMySsmNzWe8w/sy9VHDG5VrOFwQaXcJOIfBWXVfL+pzCv+NpVuKwZLq+q2rRMbbQzvkc6ALskM6ZpKn6wkemQk0DMzkZyU9rcGhkNuAuUnkbZwzvHJki18uGgTb8xeT25a/LapZ/bUuQf04fLDBpKeFMvq/AriY6PompZASnxMm+cvVbEnIq3mnOP56Wv5dmUhw3uksbG4iqe/WU3PjEQG5qTw+dJ80hNj2VhSRZ+sJNYUVmwrArdW1BATZcRGR1FWXcf95+zLcb6h2lsrHC6olJtEOo9zji2l1awprGDxRq8b6LLNZawqKGdDk1FBwRukYUCXZA4YkE3/Lsn075LMQQOzWzVYQzjkJlB+EukoNXUNzFtXzPDuaWwpreaPby3gw0WbO2z/c35/NOlJsa1aV/PsiUirmRlnje/DWeP7bFv2o+FdueSJGRSW13DKvj0prapj3z4ZXHBgP96Zv4FPlmyhtKqWiw/uT0VNPZc+OYNz9u/T5kJPRKStzIzctARy0xIY1y9rh9dKqmpZt7XS+yjyPr5ZUcCLM9ZSXlNPXEwUi/94bIAiF5FQFhcTxdi+mQD0yU7i4Qv2a3Hd4spaNhZX8fnSLby/cBOr8ss5YlguU6avbXGbl2blcckh/fc4TrXsiUirbC2vITEumoTY6N2uW1BWTVZyXLu6S4XD3XPlJpHg5pxjS1k1G4qq2Kd3Rqu2CYfcBMpPIsGuuKKWZVtKGdM7s9UjEatlT0T2WNNn+3Yn29etU0QkGJkZuakJ2wZPEBEJFulJsYztm7X7FVsptCaREBERERERkVZRsSciIiIiIhKGVOyJiIiIiIiEIRV7IiIdxMwmmdmDxcXFgQ5FRERERMWeiEhHcc696Zy7LD09PdChiIiIiKjYExERERERCUcq9kRERERERMKQij0REREREZEwpGJPREREREQkDKnYExERERERCUPmnAt0DO1mZluA1a1cvQuQ78dwdGwdOxiOHejjd8Sx+zrncjoimEAJodzUWcL9HMP9/CD8z7E15xfyuQkiPj/pfIJfuJ1TZ51Pi/kppIu9tjCzGc65cTq2jh3Oxw708QN97qEoEt6zcD/HcD8/CP9zDPfza69we190PsEv3M4pGM5H3ThFRERERETCkIo9ERERERGRMBRJxd6DOraOHQHHDvTxA33uoSgS3rNwP8dwPz8I/3MM9/Nrr3B7X3Q+wS/czing5xMxz+yJiIiIiIhEkkhq2RMREREREYkYYV/smdmxZrbEzJaZ2Y1+PlZvM/vYzBaZ2QIzu9a3PMvMPjCzpb7PmX6MIdrMvjOztwJw7Awze8nMFvvegwM76/hmdp3vPZ9vZs+ZWYK/jm1mj5rZZjOb32RZi8cys5t8v39LzOwYPxz7H773fK6ZvWpmGZ117Cav/dLMnJl18cexw1Vn5id/aU/eC8Xfjbbk1hA9vzbl7xA9xzb9nwjFc+wooZqbzGyVmc0zs9lmNsO3LKR+xh11jWFmY33vxTIzu8fMrLPPxRdHc+dzq5mt8/2cZpvZ8U1eC/bz6bD/eZ12Ts65sP0AooHlwAAgDpgDDPfj8boD+/q+TgW+B4YDfwdu9C2/EfibH2P4BfAs8Jbv+8489hPAT3xfxwEZnXF8oCewEkj0ff8CcKG/jg0cBuwLzG+yrNlj+X7+c4B4oL/v9zG6g499NBDj+/pvnXls3/LewHt48zZ18cexw/Gjs/OTH8+jTXkvVH83WptbQ/j8Wp2/Q/Ec2/p/IhTPsQPfq5DNTcCqxv9DTZaF1M+4uf+17TkH4FvgQMCAd4Hjguh8bgV+2cy6oXA+HfY/r7POKdxb9sYDy5xzK5xzNcAU4GR/Hcw5t8E5N8v3dSmwCO8fzMl4/0jxfZ7sj+ObWS/gBODhJos769hpeH/QjwA452qcc0WddXwgBkg0sxggCVjvr2M75z4DCnda3NKxTgamOOeqnXMrgWV4v5cddmzn3PvOuTrft18DvTrr2D53Ab8Gmj4A3KHHDlOdmp/8pR15L+R+N9qYW0Px/Nqav0PuHH3a8n8iVM+xI4RFbmoipH7GHXGNYWbdgTTn3DTnVRVP4r/rr13axbVDc0LhfDrkf15nnlO4F3s9gbVNvs/zLfM7M+sHjAG+Abo65zaA90sC5PrpsHfjXXQ3NFnWWcceAGwBHvN1dXrYzJI74/jOuXXAHcAaYANQ7Jx7vzOO3URLx+rs38GL8e4OdcqxzewkYJ1zbs5OLwXsby+EhN171Mq8F4rnfTetz62heH5tzd8hd47t+D8RcufYgUL53B3wvpnNNLPLfMvC4Wfc1nPo6ft65+XB5GrzHj95tEmXx5A6nz38n9dp5xTuxV5zfV/9PvyomaUALwM/d86V+Pt4vmOeCGx2zs3sjOM1Iwavmf5+59wYoByvGdvvfEniZLzm8R5Aspmd2xnHboVO+x00s5uBOuCZzji2mSUBNwO/b+5lfx47TITVe9SGvBdS592O3BpS5+fT1vwdcufYjv8TIXeOHSiUz/1g59y+wHHAVWZ22C7WDeXzbNTSOQT7ud0PDARG4918+advecicTwf8z+u0cwr3Yi8P73miRr3wum34jZnF4v3wn3HOveJbvMnXXIvv82Y/HPpg4CQzW4XX5eIIM3u6k44N3nud55z7xvf9S3gXD51x/KOAlc65Lc65WuAV4KBOOnajlo7VKb+DZnYBcCJwjq87QGcceyDehdMc3+9dL2CWmXXrhGOHg7B5j9qY90LtvNuaW0Pt/KDt+TsUz7Gt/ydC8Rw7Ssieu3Nuve/zZuBVvG6Z4fAzbus55LH9kY6my4OCc26Tc67eOdcAPMT27rMhcT4d9D+v084p3Iu96cBgM+tvZnHAWcAb/jqYbxSdR4BFzrk7m7z0BnCB7+sLgNc7+tjOuZucc72cc/3wzvMj59y5nXFs3/E3AmvNbKhv0ZHAwk46/hrgADNL8v0MjsTrQ90p5+7T0rHeAM4ys3gz6w8Mxnsgt8OY2bHADcBJzrmKnWLy27Gdc/Occ7nOuX6+37s8vIeWN/r72GGiU/OTv7Qj74XU70Y7cmtInR+0K3+H3DnS9v8ToXiOHSUkc5OZJZtZauPXeIOXzSc8fsZtOgdfN8JSMzvA9/t+Pv69BmqTxqLI5xS8nxOEwPl01P+8Tj0nF4CRbDrzAzgeb6Sc5cDNfj7WIXhNsHOB2b6P44FsYCqw1Pc5y89xTGD7iHGddmy85vgZvvN/DcjsrOMDfwAW4yWMp/BGPfLLsYHn8Lod1OIVOJfs6lh4XR2XA0vYw5GWWjj2Mrz+4I2/cw901rF3en0VTUZB68hjh+tHZ+YnP55Dm/NeqP5utDa3huL5tTV/h+g5tun/RCieYwe+VyGXm/CePZ3j+1jQGHeo/Yxb+D/f5nMAxvl+15cD9wIWROfzFDDPl2/eALqH0Pl02P+8zjon8x1MREREREREwki4d+MUERERERGJSCr2REREREREwpCKPRERERERkTCkYk9ERERERCQMqdgTEREREREJQyr2xO/MrN7MZjf5uLED993PzObvfk0RkR9SfhKRYKTcJB0lJtABSESodM6NDnQQIiLNUH4SkWCk3CQdQi17EjBmtsrM/mZm3/o+BvmW9zWzqWY21/e5j295VzN71czm+D4O8u0q2sweMrMFZva+mSX61v+ZmS307WdKgE5TREKQ8pOIBCPlJmkrFXvSGRJ36opwZpPXSpxz44F7gbt9y+4FnnTOjQKeAe7xLb8H+NQ5tw+wL7DAt3wwcJ9zbgRQBJzmW34jMMa3nyv8c2oiEuKUn0QkGCk3SYcw51ygY5AwZ2ZlzrmUZpavAo5wzq0ws1hgo3Mu28zyge7OuVrf8g3OuS5mtgXo5ZyrbrKPfsAHzrnBvu9vAGKdc382s/8BZcBrwGvOuTI/n6qIhBjlJxEJRspN0lHUsieB5lr4uqV1mlPd5Ot6tj+LegJwHzAWmGlmekZVRNpC+UlEgpFyk7Saij0JtDObfJ7m+/or4Czf1+cAX/i+ngpcCWBm0WaW1tJOzSwK6O2c+xj4NZAB/OAOmYjILig/iUgwUm6SVlO1Lp0h0cxmN/n+f865xiGE483sG7wbD2f7lv0MeNTMfgVsAS7yLb8WeNDMLsG7C3UlsKGFY0YDT5tZOmDAXc65og46HxEJH8pPIhKMlJukQ+iZPQkYX7/zcc65/EDHIiLSlPKTiAQj5SZpK3XjFBERERERCUNq2RMREREREQlDatkTEREREREJQyr2REREREREwpCKPRERERERkTCkYk9ERERERCQMqdgTEREREREJQyr2REREREREwtD/A8jjztc3hKX8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharex=False, sharey=False)\n",
    "titles = [\n",
    "    \"Deterministic MLP\",\n",
    "    'MLP with Independent Normal',\n",
    "    'MLP with Dense Variational'\n",
    "]\n",
    "hists = [hist_determ, hist_aleatoric, hist_epistemic]\n",
    "for i, hist in enumerate(hists):\n",
    "    plot_loss_history(hist, plot_val=True, title=titles[i], y_scale='log', ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d724d1c-d282-48cb-a352-457c085c0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ytrue_vs_ypred(\n",
    "    y_train,\n",
    "    y_train_pred_mean,\n",
    "    y_train_pred_std,\n",
    "    y_test,\n",
    "    y_pred_mean,\n",
    "    y_pred_std,\n",
    "    ax\n",
    "):\n",
    "    ax.errorbar(x=y_train, y=y_train_pred_mean, yerr=y_train_pred_std, alpha=0.8, label=\"train\", fmt=\".\")\n",
    "    ax.errorbar(x=y_test, y=y_pred_mean, yerr=y_pred_std, alpha=0.8, label=\"test\", fmt=\".\")\n",
    "    ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], color=\"gray\", alpha=0.5)\n",
    "    ax.set_xlabel(\"True values\", fontsize=12)\n",
    "    ax.set_ylabel(\"Predicted values\", fontsize=12)\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6316f6e-09f6-49e7-b1f7-81ede9b1250a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
    "y_train_means = [y_determ_train.ravel(), y_aleatoric_train_mean.numpy().ravel(), y_epistemic_train_mean.ravel()]\n",
    "y_train_stds = [np.zeros_like(y_determ_train.ravel()), y_aleatoric_train_std.numpy().ravel(), y_epistemic_train_std.ravel()]\n",
    "y_test_means = [y_determ_pred.ravel(), y_aleatoric_mean.numpy().ravel(), y_epistemic_mean.ravel()]\n",
    "y_test_stds = [np.zeros_like(y_determ_pred.ravel()), y_aleatoric_std.numpy().ravel(), y_epistemic_std.ravel()]\n",
    "for i, title in enumerate(['deterministic', 'aleatoric', 'epistemic']):\n",
    "    plot_ytrue_vs_ypred(\n",
    "        y_train.to_numpy().ravel(),\n",
    "        y_train_means[i],\n",
    "        1.96*y_train_stds[i],\n",
    "        y_test.to_numpy().ravel(),\n",
    "        y_test_means[i],\n",
    "        1.96*y_test_stds[i],\n",
    "        axs[i]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "bbl-proba-dl",
   "language": "python",
   "name": "bbl-proba-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
